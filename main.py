import os
import socket
# 1. é¡¶çº§è¡¥ä¸ï¼šå¼ºåˆ¶ IPv4
orig_getaddrinfo = socket.getaddrinfo
def patched_getaddrinfo(*args, **kwargs):
    res = orig_getaddrinfo(*args, **kwargs)
    return [r for r in res if r[0] == socket.AF_INET]
socket.getaddrinfo = patched_getaddrinfo

import time
from contextlib import asynccontextmanager
import datetime
import asyncio
import re
import json
import pandas as pd
import numpy as np
import akshare as ak
from typing import Optional, List
from sqlalchemy import create_engine, Column, String, Float, DateTime, Integer, desc, func, Boolean, Date
from sqlalchemy.orm import sessionmaker, Session, declarative_base
from starlette.background import BackgroundTasks
from fastapi import FastAPI, Depends, HTTPException
from fastapi.responses import FileResponse
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import urllib3
import random
import efinance as ef
import requests
from requests.sessions import Session as RequestSession

# ============================================================
# ç½‘ç»œé…ç½®
# ============================================================
_orig_request = RequestSession.request
def my_request(self, method, url, **kwargs):
    kwargs['proxies'] = {'http': None, 'https': None}
    if 'headers' not in kwargs or not kwargs['headers']:
        kwargs['headers'] = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Connection': 'keep-alive'
        }
    if 'timeout' not in kwargs:
        kwargs['timeout'] = 30
    return _orig_request(self, method, url, **kwargs)

RequestSession.request = my_request
os.environ['NO_PROXY'] = '*'
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============================================================
# æ•°æ®åº“é…ç½®
# ============================================================
SQLALCHEMY_DATABASE_URL = "sqlite:///./stock_advanced_system.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# --- æ•°æ®æ¨¡å‹ ---
class User(Base):
    __tablename__ = "users"
    user_id = Column(String, primary_key=True)
    username = Column(String, unique=True)
    created_at = Column(DateTime, default=datetime.datetime.now)

class UserStockWatch(Base):
    __tablename__ = "user_stock_watch"
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_id = Column(String, index=True)
    stock_code = Column(String, index=True)
    added_at = Column(DateTime, default=datetime.datetime.now)

class DailyMarketData(Base):
    __tablename__ = "daily_market_data"
    id = Column(Integer, primary_key=True, autoincrement=True)
    date = Column(Date, index=True)
    code = Column(String, index=True)
    name = Column(String)
    latest_price = Column(Float)
    change_pct = Column(Float)
    change_amount = Column(Float)
    volume = Column(Float)
    amount = Column(Float)
    amplitude = Column(Float)
    high = Column(Float)
    low = Column(Float)
    open = Column(Float)
    close_prev = Column(Float)
    volume_ratio = Column(Float)
    turnover_rate = Column(Float)
    pe_dynamic = Column(Float)
    pb = Column(Float)
    total_market_cap = Column(Float)
    circulating_market_cap = Column(Float)
    rise_speed = Column(Float)
    change_5min = Column(Float)
    updated_at = Column(DateTime, default=datetime.datetime.now)

class HistoricalData(Base):
    __tablename__ = "historical_data"
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String, index=True)
    date = Column(Date, index=True)
    open = Column(Float)
    close = Column(Float)
    high = Column(Float)
    low = Column(Float)
    volume = Column(Integer)
    amount = Column(Float)
    amplitude = Column(Float)
    change_pct = Column(Float)
    change_amount = Column(Float)
    turnover_rate = Column(Float)
    created_at = Column(DateTime, default=datetime.datetime.now)

class DividendData(Base):
    __tablename__ = "dividend_data"
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String, index=True)
    stock_name = Column(String)
    ex_dividend_date = Column(Date, index=True)
    dividend = Column(String)
    bonus_share = Column(String)
    capitalization = Column(String)
    physical = Column(String)
    exchange = Column(String)
    report_period = Column(String)
    created_at = Column(DateTime, default=datetime.datetime.now)

class StockAnalysisResult(Base):
    __tablename__ = "stock_analysis_results"
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String, index=True)
    stock_name = Column(String)
    analysis_date = Column(Date, index=True)
    latest_price = Column(Float)
    pe_ratio = Column(Float)
    pb_ratio = Column(Float)
    volatility_30d = Column(Float)
    volatility_60d = Column(Float)
    dividend_yield = Column(Float)
    roe = Column(Float)
    profit_growth = Column(Float)
    volatility_score = Column(Integer)
    dividend_score = Column(Integer)
    growth_score = Column(Integer)
    total_score = Column(Integer)
    suggestion = Column(String)
    data_source = Column(String)
    created_at = Column(DateTime, default=datetime.datetime.now)

Base.metadata.create_all(bind=engine)

# ============================================================
# æ ¸å¿ƒæ•°æ®æœåŠ¡å±‚ - å¢å¼ºå­—æ®µæ˜ å°„
# ============================================================
class StockDataService:
    def __init__(self):
        self.target_ut = "fa5fd1943c7b386f172d6893dbfba10b"
        self.target_cookies = {
            "qgqp_b_id": "9fb8c26c0a40e0e20ffd551bb6a52cdf",
            "st_nvi": "4U97b8QAwVvKIFT5nsAGl367a",
            "st_si": "69103863020676",
            "nid18": "03c4e656b6d9f1dfd8b102df6f142ef1",
            "st_sn": "23"
        }
        
        # âœ… å¢å¼ºç‰ˆå­—æ®µæ˜ å°„ - åŒ…å«æ‰€æœ‰å¯ç”¨å­—æ®µ
        self.em_fields_map = {
            # åŸºç¡€ä¿¡æ¯
            'f12': 'code',           # ä»£ç 
            'f14': 'name',           # åç§°
            
            # ä»·æ ¼ç›¸å…³
            'f2': 'latest_price',    # æœ€æ–°ä»·
            'f3': 'change_pct',      # æ¶¨è·Œå¹…
            'f4': 'change_amount',   # æ¶¨è·Œé¢
            'f15': 'high',           # æœ€é«˜
            'f16': 'low',            # æœ€ä½
            'f17': 'open',           # ä»Šå¼€
            'f18': 'close_prev',     # æ˜¨æ”¶
            
            # æˆäº¤ç›¸å…³
            'f5': 'volume',          # æˆäº¤é‡(æ‰‹)
            'f6': 'amount',          # æˆäº¤é¢(å…ƒ)
            'f7': 'amplitude',       # æŒ¯å¹…
            'f8': 'turnover_rate',   # æ¢æ‰‹ç‡
            'f10': 'volume_ratio',   # é‡æ¯”
            
            # ä¼°å€¼ç›¸å…³
            'f9': 'pe_dynamic',      # å¸‚ç›ˆç‡-åŠ¨æ€
            'f23': 'pb',             # å¸‚å‡€ç‡
            
            # å¸‚å€¼ç›¸å…³
            'f20': 'total_market_cap',        # æ€»å¸‚å€¼
            'f21': 'circulating_market_cap',  # æµé€šå¸‚å€¼
            
            # å…¶ä»–
            'f11': 'rise_speed',     # æ¶¨é€Ÿ
            'f22': 'change_5min',    # 5åˆ†é’Ÿæ¶¨è·Œ
        }

    def get_db(self) -> Session:
        db = SessionLocal()
        return db

    def _safe_float(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return None
            # å¤„ç†ç™¾åˆ†æ¯”
            if isinstance(val, str) and '%' in val:
                return float(val.replace('%', ''))
            return float(val)
        except:
            return None
    
    def _safe_int(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•°"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return None
            return int(float(val))
        except:
            return None

    def refresh_ut(self):
        """è‡ªåŠ¨åˆ·æ–° ut å‚æ•°"""
        print("ğŸ”„ æ­£åœ¨åˆ·æ–° ut å‚æ•°...")
        try:
            url = "https://quote.eastmoney.com/center/gridlist.html"
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/121.0 Safari/537.36"
            }
            response = requests.get(url, headers=headers, timeout=10, verify=False, proxies={"http": None, "https": None})
            match = re.search(r'ut:\s*"([a-z0-9]+)"', response.text)
            if match:
                new_ut = match.group(1)
                self.target_ut = new_ut
                print(f"âœ… æˆåŠŸåˆ·æ–° ut: {new_ut}")
                return True
            else:
                print("âŒ æœªèƒ½æå–åˆ° ut")
                return False
        except Exception as e:
            print("âŒ åˆ·æ–° ut å¤±è´¥:", e)
            return False

    async def fetch_em_data_via_web_api(self, page_size: int = 100) -> pd.DataFrame:
        """å¢å¼ºç‰ˆæ•°æ®æŠ“å– - å®Œæ•´å­—æ®µæ˜ å°„"""
        all_dfs = []
        current_page = 1
        total_pages = 999

        url = "https://push2.eastmoney.com/api/qt/clist/get"

        headers = {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Connection": "keep-alive",
            "Referer": "https://quote.eastmoney.com/center/gridlist.html",
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1"
        }

        print(f"\nğŸŒ å¯åŠ¨å¢å¼ºç‰ˆæ•°æ®æŠ“å– (æ¯é¡µ {page_size} æ¡)")
        print(f"   å­—æ®µæ•°é‡: {len(self.em_fields_map)} ä¸ª\n")

        session = requests.Session()
        session.trust_env = False
        session.proxies = {"http": None, "https": None}
        session.cookies.update(self.target_cookies)

        while current_page <= total_pages:
            params = {
                "np": "1",
                "fltt": "1",
                "invt": "2",
                "cb": f"jQuery37109323508735388775_{int(time.time()*1000)}",
                "fs": "m:0+t:6+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:81+s:262144+f:!2",
                "fields": ",".join(self.em_fields_map.keys()),  # è¯·æ±‚æ‰€æœ‰å­—æ®µ
                "fid": "f3",
                "pn": str(current_page),
                "pz": str(page_size),
                "po": "1",
                "dect": "1",
                "ut": self.target_ut,
                "wbp2u": "|0|0|0|web",
                "_": str(int(time.time() * 1000))
            }

            try:
                print(f"   â¤ æŠ“å–ç¬¬ {current_page}/{total_pages if total_pages != 999 else '?'} é¡µ...")

                response = await asyncio.to_thread(
                    session.get, url, params=params, headers=headers, timeout=20, verify=False
                )

                if response.status_code != 200:
                    print(f"   âš ï¸ çŠ¶æ€ç å¼‚å¸¸: {response.status_code}")
                    break

                raw_text = response.text
                json_match = re.search(r'jQuery.*?\((.*)\)', raw_text)
                
                if not json_match:
                    print("   âš ï¸ JSONP è§£æå¤±è´¥")
                    break

                json_str = json_match.group(1)
                res_json = json.loads(json_str)

                if not res_json or not res_json.get("data"):
                    print("âš ï¸ æ•°æ®ä¸ºç©ºï¼Œå°è¯•åˆ·æ–° ut...")
                    if self.refresh_ut():
                        print("ğŸ” ä½¿ç”¨æ–° ut é‡è¯•...")
                        params["ut"] = self.target_ut
                        response = await asyncio.to_thread(
                            session.get, url, params=params, headers=headers, timeout=20, verify=False
                        )
                        raw_text = response.text
                        json_match = re.search(r'jQuery.*?\((.*)\)', raw_text)
                        if json_match:
                            json_str = json_match.group(1)
                            res_json = json.loads(json_str)
                            if not res_json or not res_json.get("data"):
                                print("âŒ åˆ·æ–°åä»å¤±è´¥")
                                break
                        else:
                            break
                    else:
                        break

                if current_page == 1:
                    total_records = res_json["data"]["total"]
                    total_pages = (total_records + page_size - 1) // page_size
                    print(f"   ğŸ“Š å…¨å¸‚åœºå…± {total_records} åªè‚¡ç¥¨ï¼Œé¢„è®¡ {total_pages} é¡µ")

                batch_df = pd.DataFrame(res_json["data"]["diff"])
                all_dfs.append(batch_df)

                if current_page >= total_pages:
                    break

                wait_time = random.uniform(10, 50)
                print(f"   ğŸ’¤ éšæœºç­‰å¾… {wait_time:.1f} ç§’...")
                await asyncio.sleep(wait_time)

                current_page += 1

            except Exception as e:
                print(f"   âŒ ç¬¬ {current_page} é¡µå¤±è´¥: {str(e)[:100]}")
                break

        session.close()

        if not all_dfs:
            return pd.DataFrame()

        final_df = pd.concat(all_dfs, ignore_index=True)
        
        # å­—æ®µé‡å‘½å
        final_df = final_df.rename(columns=self.em_fields_map)

        print(f"\nâœ… æ€»è®¡è·å– {len(final_df)} æ¡æ•°æ®")
        
        # æ˜¾ç¤ºå­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
        print(f"\nğŸ“Š å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
        for col in ['code', 'name', 'latest_price', 'pe_dynamic', 'pb', 'volume', 'amount', 'turnover_rate', 'amplitude']:
            if col in final_df.columns:
                non_null = final_df[col].notna().sum()
                pct = (non_null / len(final_df)) * 100
                status = "âœ…" if pct > 90 else ("âš ï¸" if pct > 50 else "âŒ")
                print(f"   {status} {col:20s}: {non_null:5d}/{len(final_df)} ({pct:5.1f}%)")

        return final_df

    async def fetch_daily_market_data(self, force: bool = False) -> dict:
        """å¢å¼ºç‰ˆå¸‚åœºæ•°æ®è·å– - å®Œæ•´å­—æ®µä¿å­˜"""
        db = self.get_db()
        today = datetime.date.today()
        
        try:
            if not force and db.query(DailyMarketData).filter(DailyMarketData.date == today).first():
                db.close()
                return {"status": "skip", "message": "ä»Šæ—¥æ•°æ®å·²å­˜åœ¨"}

            # æ–¹æ¡ˆ1: ä½¿ç”¨å¢å¼ºçš„Web API
            df = await self.fetch_em_data_via_web_api(page_size=100)
            
            # æ–¹æ¡ˆ2: å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ efinance ä¿åº•
            if df.empty:
                print("âš ï¸ Web API å¤±è´¥ï¼Œå¯åŠ¨ efinance ä¿åº•...")
                df = await asyncio.to_thread(ef.stock.get_realtime_quotes)
                # efinance å­—æ®µæ˜ å°„
                df = df.rename(columns={
                    'è‚¡ç¥¨ä»£ç ': 'code',
                    'è‚¡ç¥¨åç§°': 'name',
                    'æœ€æ–°ä»·': 'latest_price',
                    'æ¶¨è·Œå¹…': 'change_pct',
                    'æ¶¨è·Œé¢': 'change_amount',
                    'æˆäº¤é‡': 'volume',
                    'æˆäº¤é¢': 'amount',
                    'æŒ¯å¹…': 'amplitude',
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'ä»Šå¼€': 'open',
                    'æ˜¨æ”¶': 'close_prev',
                    'é‡æ¯”': 'volume_ratio',
                    'æ¢æ‰‹ç‡': 'turnover_rate',
                    'åŠ¨æ€å¸‚ç›ˆç‡': 'pe_dynamic',
                    'å¸‚å‡€ç‡': 'pb',
                    'æ€»å¸‚å€¼': 'total_market_cap',
                    'æµé€šå¸‚å€¼': 'circulating_market_cap'
                })
            
            if df.empty:
                db.close()
                return {"status": "error", "message": "æ— æ³•è·å–è¡Œæƒ…"}

            # åˆ é™¤ä»Šæ—¥æ—§æ•°æ®
            db.query(DailyMarketData).filter(DailyMarketData.date == today).delete()
            db.commit()

            print(f"\nğŸ’¾ å­˜å…¥æ•°æ®åº“: {len(df)} æ¡è®°å½•")
            
            batch = []
            field_stats = {}  # ç»Ÿè®¡å„å­—æ®µçš„éç©ºæ•°é‡
            
            for _, row in df.iterrows():
                # æå–ä»£ç ï¼ˆä¼˜å…ˆä»æ˜ å°„åçš„å­—æ®µè·å–ï¼‰
                code = str(row.get('code') or row.get('f12', ''))
                code = re.sub(r'\D', '', code)  # åªä¿ç•™æ•°å­—
                
                if not code:
                    continue
                
                # åˆ›å»ºè®°å½• - ä½¿ç”¨å¢å¼ºçš„å­—æ®µæ˜ å°„
                m = DailyMarketData(
                    date=today,
                    code=code,
                    name=str(row.get('name') or row.get('f14', '')),
                    
                    # ä»·æ ¼ç›¸å…³
                    latest_price=self._safe_float(row.get('latest_price') or row.get('f2')),
                    change_pct=self._safe_float(row.get('change_pct') or row.get('f3')),
                    change_amount=self._safe_float(row.get('change_amount') or row.get('f4')),
                    high=self._safe_float(row.get('high') or row.get('f15')),
                    low=self._safe_float(row.get('low') or row.get('f16')),
                    open=self._safe_float(row.get('open') or row.get('f17')),
                    close_prev=self._safe_float(row.get('close_prev') or row.get('f18')),
                    
                    # æˆäº¤ç›¸å…³
                    volume=self._safe_float(row.get('volume') or row.get('f5')),
                    amount=self._safe_float(row.get('amount') or row.get('f6')),
                    amplitude=self._safe_float(row.get('amplitude') or row.get('f7')),
                    turnover_rate=self._safe_float(row.get('turnover_rate') or row.get('f8')),
                    volume_ratio=self._safe_float(row.get('volume_ratio') or row.get('f10')),
                    
                    # ä¼°å€¼ç›¸å…³
                    pe_dynamic=self._safe_float(row.get('pe_dynamic') or row.get('f9')),
                    pb=self._safe_float(row.get('pb') or row.get('f23')),
                    
                    # å¸‚å€¼ç›¸å…³
                    total_market_cap=self._safe_float(row.get('total_market_cap') or row.get('f20')),
                    circulating_market_cap=self._safe_float(row.get('circulating_market_cap') or row.get('f21')),
                    
                    # å…¶ä»–
                    rise_speed=self._safe_float(row.get('rise_speed') or row.get('f11')),
                    change_5min=self._safe_float(row.get('change_5min') or row.get('f22')),
                    
                    updated_at=datetime.datetime.now()
                )
                
                # ç»Ÿè®¡å­—æ®µ
                for field in ['latest_price', 'pe_dynamic', 'pb', 'volume', 'amount', 'turnover_rate']:
                    val = getattr(m, field)
                    if val is not None:
                        field_stats[field] = field_stats.get(field, 0) + 1
                
                batch.append(m)
                
                # æ‰¹é‡æäº¤
                if len(batch) >= 500:
                    db.bulk_save_objects(batch)
                    db.commit()
                    batch = []
                    print(f"\nâœ… æ•°æ®ä¿å­˜å®Œæˆï¼Œå…± {saved_count} æ¡")
            
            # æäº¤å‰©ä½™æ•°æ®
            if batch:
                db.bulk_save_objects(batch)
                db.commit()
                saved_count += len(batch)
            
            # æ˜¾ç¤ºä¿å­˜ç»Ÿè®¡
            print(f"\nâœ… æ•°æ®ä¿å­˜å®Œæˆ!")
            print(f"\nğŸ“Š å­—æ®µä¿å­˜ç»Ÿè®¡:")
            total = len(df)
            for field, count in sorted(field_stats.items()):
                pct = (count / total) * 100
                status = "âœ…" if pct > 90 else ("âš ï¸" if pct > 50 else "âŒ")
                print(f"   {status} {field:20s}: {count:5d}/{total} ({pct:5.1f}%)")
            
            db.close()
            return {"status": "success", "count": len(df), "field_stats": field_stats}
            
        except Exception as e:
            db.close()
            raise e

    async def fetch_financial_metrics(self, stock_code: str):
        """ä¸ªè‚¡è´¢åŠ¡æ•°æ®è¡¥å¿æŠ“å–"""
        try:
            df = await asyncio.to_thread(ef.stock.get_base_info, stock_code)
            if df is None or df.empty:
                return 0.0, 0.0
            row = df.iloc[0]
            roe = self._safe_float(row.get('å‡€èµ„äº§æ”¶ç›Šç‡(%)', 0))
            growth = self._safe_float(row.get('å‡€åˆ©æ¶¦åŒæ¯”(%)', 0))
            return roe if roe else 0.0, growth if growth else 0.0
        except:
            return 0.0, 0.0

    async def fetch_historical_data(self, stock_code: str, start_date=None, end_date=None):
        """è·å–å†å²æ•°æ®"""
        db = self.get_db()
        try:
            if not end_date:
                end_date = datetime.date.today().strftime("%Y%m%d")
            if not start_date:
                start_date = (datetime.date.today() - datetime.timedelta(days=180)).strftime("%Y%m%d")
            
            # ä¼˜å…ˆ efinance
            try:
                df = await asyncio.to_thread(ef.stock.get_quote_history, stock_code)
                if not df.empty:
                    df = df.rename(columns={'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open', 
                                           'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume',
                                           'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude', 
                                           'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount',
                                           'æ¢æ‰‹ç‡': 'turnover_rate'})
            except:
                df = await asyncio.to_thread(ak.stock_zh_a_hist, symbol=stock_code, 
                                            period="daily", start_date=start_date, 
                                            end_date=end_date, adjust="qfq")
                if not df.empty:
                    df = df.rename(columns={'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open',
                                           'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume',
                                           'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
                                           'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount',
                                           'æ¢æ‰‹ç‡': 'turnover_rate'})

            if df.empty:
                db.close()
                return {"status": "error"}

            # åˆ é™¤æ—§æ•°æ®
            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
            
            # ä¿å­˜æ–°æ•°æ®
            for _, row in df.iterrows():
                h = HistoricalData(
                    stock_code=stock_code,
                    date=pd.to_datetime(row['date']).date(),
                    close=self._safe_float(row.get('close')),
                    open=self._safe_float(row.get('open')),
                    high=self._safe_float(row.get('high')),
                    low=self._safe_float(row.get('low')),
                    volume=self._safe_int(row.get('volume')),
                    amount=self._safe_float(row.get('amount')),
                    amplitude=self._safe_float(row.get('amplitude')),
                    change_pct=self._safe_float(row.get('change_pct')),
                    change_amount=self._safe_float(row.get('change_amount')),
                    turnover_rate=self._safe_float(row.get('turnover_rate'))
                )
                db.add(h)
                
            db.commit()
            db.close()
            return {"status": "success", "count": len(df)}
            
        except Exception as e:
            db.close()
            return {"status": "error", "message": str(e)}

    async def fetch_dividend_data(self, date_str: str = None) -> dict:
        """è·å–åˆ†çº¢æ•°æ®"""
        db = self.get_db()
        try:
            if not date_str:
                date_str = datetime.date.today().strftime("%Y%m%d")
            
            print(f"ğŸ’° è·å– {date_str} åˆ†çº¢æ•°æ®...")
            
            df = ak.news_trade_notify_dividend_baidu(date=date_str)
            
            if df.empty:
                db.close()
                return {"status": "success", "message": f"{date_str} æ— åˆ†çº¢æ•°æ®", "count": 0}
            
            target_date = datetime.datetime.strptime(date_str, "%Y%m%d").date()
            db.query(DividendData).filter(DividendData.ex_dividend_date == target_date).delete()
            
            count = 0
            for _, row in df.iterrows():
                dividend_data = DividendData(
                    stock_code=str(row['è‚¡ç¥¨ä»£ç ']),
                    stock_name=str(row['è‚¡ç¥¨ç®€ç§°']),
                    ex_dividend_date=datetime.datetime.strptime(str(row['é™¤æƒæ—¥']), "%Y-%m-%d").date(),
                    dividend=str(row['åˆ†çº¢']),
                    bonus_share=str(row['é€è‚¡']),
                    capitalization=str(row['è½¬å¢']),
                    physical=str(row['å®ç‰©']),
                    exchange=str(row['äº¤æ˜“æ‰€']),
                    report_period=str(row['æŠ¥å‘ŠæœŸ']),
                )
                db.add(dividend_data)
                count += 1
            
            db.commit()
            db.close()
            
            print(f"   âœ“ ä¿å­˜ {count} æ¡åˆ†çº¢æ•°æ®")
            
            return {"status": "success", "count": count}
            
        except Exception as e:
            db.close()
            return {"status": "error", "message": str(e)}

    async def analyze_stock(self, stock_code: str, db: Session = None) -> dict:
        """åˆ†æå•åªè‚¡ç¥¨"""
        is_internal = db is None
        if is_internal:
            db = self.get_db()
            
        try:
            today = datetime.date.today()
            market_data = db.query(DailyMarketData).filter(
                DailyMarketData.code == stock_code
            ).order_by(desc(DailyMarketData.date)).first()
            
            if not market_data:
                return {"status": "error", "message": "æ— å®æ—¶æ•°æ®"}

            # 1. è·å– ROE å’Œå¢é•¿ç‡
            roe, profit_growth = await self.fetch_financial_metrics(stock_code)
            
            # 2. è®¡ç®—æ³¢åŠ¨ç‡
            vol_30d = 0
            vol_60d = 0
            trend_score = 0
            
            hist = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).order_by(desc(HistoricalData.date)).limit(65).all()
            
            if len(hist) >= 30:
                closes = [h.close for h in reversed(hist) if h.close]
                if len(closes) >= 30:
                    series = pd.Series(closes)
                    
                    # 30æ—¥æ³¢åŠ¨ç‡
                    series_30 = pd.Series(closes[-30:])
                    log_ret_30 = np.log(series_30 / series_30.shift(1)).dropna()
                    vol_30d = log_ret_30.std() * np.sqrt(252) * 100 if len(log_ret_30) > 0 else 0
                    
                    # 60æ—¥æ³¢åŠ¨ç‡
                    if len(closes) >= 60:
                        series_60 = pd.Series(closes[-60:])
                        log_ret_60 = np.log(series_60 / series_60.shift(1)).dropna()
                        vol_60d = log_ret_60.std() * np.sqrt(252) * 100 if len(log_ret_60) > 0 else 0
                        
                        ma60 = series.rolling(60).mean().iloc[-1]
                        trend_score = 10 if closes[-1] > ma60 else 0

            # 3. è‚¡æ¯ç‡è®¡ç®—
            dividend_yield = 0
            one_year_ago = today - datetime.timedelta(days=365)
            dividends = db.query(DividendData).filter(
                DividendData.stock_code == stock_code,
                DividendData.ex_dividend_date >= one_year_ago
            ).all()
            
            if dividends and market_data.latest_price:
                total_dividend = 0
                for div in dividends:
                    div_str = str(div.dividend)
                    match = re.search(r'(\d+\.?\d*)', div_str)
                    if match:
                        total_dividend += float(match.group(1))
                
                if total_dividend > 0:
                    dividend_yield = (total_dividend / market_data.latest_price) * 100

            # 4. è¯„åˆ†ç³»ç»Ÿ
            volatility_score = 0
            if vol_30d > 0:
                if vol_30d < 20:
                    volatility_score = 40
                elif vol_30d < 30:
                    volatility_score = 30
                elif vol_30d < 40:
                    volatility_score = 20
                elif vol_30d < 50:
                    volatility_score = 10
            
            dividend_score = 0
            if dividend_yield >= 5:
                dividend_score = 30
            elif dividend_yield >= 4:
                dividend_score = 25
            elif dividend_yield >= 3:
                dividend_score = 20
            elif dividend_yield >= 2:
                dividend_score = 15
            elif dividend_yield >= 1:
                dividend_score = 10
            
            growth_score = 0
            if roe > 15:
                growth_score = 30
            elif roe > 12:
                growth_score = 25
            elif roe > 10:
                growth_score = 20
            elif roe > 8:
                growth_score = 15
            elif roe > 5:
                growth_score = 10
            
            total = volatility_score + dividend_score + growth_score
            
            if total >= 70:
                suggestion = "å¼ºçƒˆæ¨è"
            elif total >= 60:
                suggestion = "æ¨è"
            elif total >= 50:
                suggestion = "å¯ä»¥å…³æ³¨"
            elif total >= 40:
                suggestion = "è§‚æœ›"
            else:
                suggestion = "ä¸æ¨è"
            
            res = StockAnalysisResult(
                stock_code=stock_code,
                stock_name=market_data.name,
                analysis_date=today,
                latest_price=market_data.latest_price,
                pe_ratio=market_data.pe_dynamic,
                pb_ratio=market_data.pb,
                volatility_30d=round(vol_30d, 2),
                volatility_60d=round(vol_60d, 2),
                dividend_yield=round(dividend_yield, 2),
                roe=round(roe, 2) if roe else 0,
                profit_growth=round(profit_growth, 2) if profit_growth else 0,
                volatility_score=volatility_score,
                dividend_score=dividend_score,
                growth_score=growth_score,
                total_score=total,
                suggestion=suggestion,
                data_source="enhanced"
            )
            
            db.merge(res)
            db.commit()
            
            return {"status": "success", "score": total, "suggestion": suggestion}
            
        except Exception as e:
            return {"status": "error", "message": str(e)}
        finally:
            if is_internal:
                db.close()

    async def analyze_all_watched_stocks(self):
        """åˆ†ææ‰€æœ‰å…³æ³¨è‚¡ç¥¨"""
        db = self.get_db()
        try:
            watched = db.query(UserStockWatch.stock_code).distinct().all()
            
            print(f"\nğŸ“Š å¼€å§‹åˆ†æ {len(watched)} åªå…³æ³¨è‚¡ç¥¨...")
            
            success = 0
            failed = 0
            
            for i, row in enumerate(watched, 1):
                code = row[0]
                print(f"[{i}/{len(watched)}] åˆ†æ {code}...")
                
                # å…ˆç¡®ä¿æœ‰å†å²æ•°æ®
                hist_result = await self.fetch_historical_data(code)
                if hist_result.get("status") == "success":
                    print(f"   âœ“ å†å²æ•°æ®: {hist_result.get('count', 0)} æ¡")
                
                # åˆ†æ
                result = await self.analyze_stock(code, db)
                
                if result["status"] == "success":
                    print(f"   âœ“ è¯„åˆ†: {result.get('score', 0)} - {result.get('suggestion', '')}")
                    success += 1
                else:
                    print(f"   âœ— {result.get('message', '')}")
                    failed += 1
                    
                await asyncio.sleep(0.5)
                
            print(f"\nâœ… åˆ†æå®Œæˆ! æˆåŠŸ: {success}, å¤±è´¥: {failed}\n")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
        finally:
            db.close()

# --- FastAPI åº”ç”¨ ---
stock_service = StockDataService()
scheduler = AsyncIOScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨å¢å¼ºç‰ˆä»·å€¼åˆ†æç³»ç»Ÿ...\n")

    scheduler.add_job(
        stock_service.fetch_daily_market_data,
        CronTrigger(hour=15, minute=30),
        id="daily_market_fetch",
        replace_existing=True
    )

    scheduler.add_job(
        stock_service.analyze_all_watched_stocks,
        CronTrigger(hour=16, minute=0),
        id="daily_analysis",
        replace_existing=True
    )

    scheduler.start()

    print("âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨:")
    print("   - æ¯æ—¥15:30è·å–å…¨å¸‚åœºæ•°æ®")
    print("   - æ¯æ—¥16:00åˆ†ææ‰€æœ‰å…³æ³¨è‚¡ç¥¨\n")

    yield

    print("\nğŸ›‘ æ­£åœ¨å…³é—­ç³»ç»Ÿ...")
    if scheduler and scheduler.running:
        scheduler.shutdown()
    print("âœ… ç³»ç»Ÿå·²åœæ­¢\n")

app = FastAPI(
    title="ä»·å€¼åˆ†æç³»ç»Ÿ",
    version="2.3",
    lifespan=lifespan
)

# --- APIæ¥å£ (ä¿æŒä¸å˜,æ­¤å¤„çœç•¥é‡å¤ä»£ç ) ---
@app.post("/users/create")
def create_user(user_id: str, username: str):
    db = SessionLocal()
    try:
        existing = db.query(User).filter(User.user_id == user_id).first()
        if existing:
            db.close()
            raise HTTPException(status_code=400, detail="ç”¨æˆ·IDå·²å­˜åœ¨")
        user = User(user_id=user_id, username=username)
        db.add(user)
        db.commit()
        db.close()
        return {"status": "success", "message": f"ç”¨æˆ· {username} åˆ›å»ºæˆåŠŸ"}
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/watch/add")
def add_watch_stock(user_id: str, stock_codes: str):
    db = SessionLocal()
    try:
        user = db.query(User).filter(User.user_id == user_id).first()
        if not user:
            db.close()
            raise HTTPException(status_code=404, detail="ç”¨æˆ·ä¸å­˜åœ¨")
        codes = re.findall(r'\d{6}', stock_codes)
        added = 0
        for code in set(codes):
            existing = db.query(UserStockWatch).filter(
                UserStockWatch.user_id == user_id,
                UserStockWatch.stock_code == code
            ).first()
            if not existing:
                watch = UserStockWatch(user_id=user_id, stock_code=code)
                db.add(watch)
                added += 1
        db.commit()
        db.close()
        return {"status": "success", "message": f"æˆåŠŸæ·»åŠ  {added} åªè‚¡ç¥¨åˆ°å…³æ³¨åˆ—è¡¨"}
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/watch/remove")
def remove_watch_stock(user_id: str, stock_code: str):
    db = SessionLocal()
    try:
        result = db.query(UserStockWatch).filter(
            UserStockWatch.user_id == user_id,
            UserStockWatch.stock_code == stock_code
        ).delete()
        db.commit()
        db.close()
        if result > 0:
            return {"status": "success", "message": f"å·²ç§»é™¤è‚¡ç¥¨ {stock_code}"}
        else:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥å…³æ³¨è®°å½•")
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/watch/list")
def list_watch_stocks(user_id: str):
    db = SessionLocal()
    try:
        watches = db.query(UserStockWatch).filter(UserStockWatch.user_id == user_id).all()
        db.close()
        return {
            "user_id": user_id,
            "watched_stocks": [{"code": w.stock_code, "added_at": str(w.added_at)} for w in watches],
            "count": len(watches)
        }
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/data/market/fetch")
async def fetch_market_data(force: bool = False):
    result = await stock_service.fetch_daily_market_data(force=force)
    return result

@app.post("/data/history/fetch")
async def fetch_history_data(stock_code: str, start_date: str = None, end_date: str = None):
    result = await stock_service.fetch_historical_data(stock_code, start_date, end_date)
    return result

@app.post("/data/dividend/fetch")
async def fetch_dividend_data(date_str: str = None):
    result = await stock_service.fetch_dividend_data(date_str)
    return result

@app.post("/analyze/manual")
async def manual_analyze(background_tasks: BackgroundTasks):
    background_tasks.add_task(stock_service.analyze_all_watched_stocks)
    return {"status": "success", "message": "åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨"}

@app.post("/analyze/stock")
async def analyze_single_stock(stock_code: str):
    result = await stock_service.analyze_stock(stock_code)
    return result

@app.get("/export/global")
def export_global_csv():
    db = SessionLocal()
    try:
        subquery = db.query(
            StockAnalysisResult.stock_code,
            func.max(StockAnalysisResult.analysis_date).label('max_date')
        ).group_by(StockAnalysisResult.stock_code).subquery()
        
        results = db.query(StockAnalysisResult).join(
            subquery,
            (StockAnalysisResult.stock_code == subquery.c.stock_code) &
            (StockAnalysisResult.analysis_date == subquery.c.max_date)
        ).order_by(desc(StockAnalysisResult.total_score)).all()
        
        data = []
        for r in results:
            data.append({
                "è‚¡ç¥¨ä»£ç ": r.stock_code,
                "è‚¡ç¥¨åç§°": r.stock_name,
                "åˆ†ææ—¥æœŸ": str(r.analysis_date),
                "æœ€æ–°ä»·": r.latest_price,
                "å¸‚ç›ˆç‡": r.pe_ratio,
                "å¸‚å‡€ç‡": r.pb_ratio,
                "30æ—¥æ³¢åŠ¨ç‡%": r.volatility_30d,
                "60æ—¥æ³¢åŠ¨ç‡%": r.volatility_60d,
                "è‚¡æ¯ç‡%": r.dividend_yield,
                "ROE%": r.roe,
                "åˆ©æ¶¦å¢é•¿%": r.profit_growth,
                "æ³¢åŠ¨ç‡è¯„åˆ†": r.volatility_score,
                "è‚¡æ¯ç‡è¯„åˆ†": r.dividend_score,
                "æˆé•¿æ€§è¯„åˆ†": r.growth_score,
                "ç»¼åˆè¯„åˆ†": r.total_score,
                "æŠ•èµ„å»ºè®®": r.suggestion,
                "æ•°æ®æ¥æº": r.data_source
            })
        
        out_dir = "outputs"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        
        df = pd.DataFrame(data)
        output_file = os.path.join(out_dir, "å…¨å±€è‚¡ç¥¨åˆ†æç»“æœ.csv")
        df.to_csv(output_file, index=False, encoding="utf_8_sig")
        
        db.close()
        return FileResponse(output_file, filename="å…¨å±€è‚¡ç¥¨åˆ†æç»“æœ.csv")
        
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/export/user")
def export_user_csv(user_id: str):
    db = SessionLocal()
    try:
        watched = db.query(UserStockWatch.stock_code).filter(UserStockWatch.user_id == user_id).all()
        watched_codes = [w[0] for w in watched]
        
        if not watched_codes:
            db.close()
            raise HTTPException(status_code=404, detail="ç”¨æˆ·æœªå…³æ³¨ä»»ä½•è‚¡ç¥¨")
        
        subquery = db.query(
            StockAnalysisResult.stock_code,
            func.max(StockAnalysisResult.analysis_date).label('max_date')
        ).filter(
            StockAnalysisResult.stock_code.in_(watched_codes)
        ).group_by(StockAnalysisResult.stock_code).subquery()
        
        results = db.query(StockAnalysisResult).join(
            subquery,
            (StockAnalysisResult.stock_code == subquery.c.stock_code) &
            (StockAnalysisResult.analysis_date == subquery.c.max_date)
        ).order_by(desc(StockAnalysisResult.total_score)).all()
        
        data = []
        for r in results:
            data.append({
                "è‚¡ç¥¨ä»£ç ": r.stock_code,
                "è‚¡ç¥¨åç§°": r.stock_name,
                "åˆ†ææ—¥æœŸ": str(r.analysis_date),
                "æœ€æ–°ä»·": r.latest_price,
                "å¸‚ç›ˆç‡": r.pe_ratio,
                "å¸‚å‡€ç‡": r.pb_ratio,
                "30æ—¥æ³¢åŠ¨ç‡%": r.volatility_30d,
                "60æ—¥æ³¢åŠ¨ç‡%": r.volatility_60d,
                "è‚¡æ¯ç‡%": r.dividend_yield,
                "ROE%": r.roe,
                "åˆ©æ¶¦å¢é•¿%": r.profit_growth,
                "æ³¢åŠ¨ç‡è¯„åˆ†": r.volatility_score,
                "è‚¡æ¯ç‡è¯„åˆ†": r.dividend_score,
                "æˆé•¿æ€§è¯„åˆ†": r.growth_score,
                "ç»¼åˆè¯„åˆ†": r.total_score,
                "æŠ•èµ„å»ºè®®": r.suggestion,
                "æ•°æ®æ¥æº": r.data_source
            })
        
        out_dir = "outputs"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        
        df = pd.DataFrame(data)
        output_file = os.path.join(out_dir, f"ç”¨æˆ·{user_id}_è‚¡ç¥¨åˆ†æç»“æœ.csv")
        df.to_csv(output_file, index=False, encoding="utf_8_sig")
        
        db.close()
        return FileResponse(output_file, filename=f"ç”¨æˆ·{user_id}_è‚¡ç¥¨åˆ†æç»“æœ.csv")
        
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
def get_status():
    db = SessionLocal()
    try:
        user_count = db.query(User).count()
        watch_count = db.query(UserStockWatch).count()
        market_data_count = db.query(DailyMarketData).count()
        historical_data_count = db.query(HistoricalData).count()
        dividend_data_count = db.query(DividendData).count()
        analysis_count = db.query(StockAnalysisResult).count()
        
        latest_market = db.query(func.max(DailyMarketData.date)).scalar()
        latest_analysis = db.query(func.max(StockAnalysisResult.analysis_date)).scalar()
        
        db.close()
        
        return {
            "system": "ä»·å€¼åˆ†æç³»ç»Ÿ",
            "users": user_count,
            "watched_stocks": watch_count,
            "market_data_records": market_data_count,
            "historical_data_records": historical_data_count,
            "dividend_data_records": dividend_data_count,
            "analysis_records": analysis_count,
            "latest_market_date": str(latest_market) if latest_market else None,
            "latest_analysis_date": str(latest_analysis) if latest_analysis else None,
            "scheduler_running": scheduler.running
        }
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    print("\n" + "="*60)
    print("ğŸš€ ä»·å€¼åˆ†æç³»ç»Ÿ")
    print("="*60)
    print("\nâœ¨ æ–°å¢ä¼˜åŒ–:")
    print("  â€¢ å®Œæ•´å­—æ®µæ˜ å°„ (22ä¸ªå­—æ®µ)")
    print("  â€¢ å®æ—¶å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡")
    print("  â€¢ å¢å¼ºçš„æ•°æ®ä¿å­˜é€»è¾‘")
    print("  â€¢ æ”¹è¿›çš„å¼‚å¸¸å€¼å¤„ç†")
    print("  â€¢ å†å²æ•°æ®å®Œæ•´ä¿å­˜")
    print("\nğŸ“š æ ¸å¿ƒåŠŸèƒ½:")
    print("  âœ“ å¤šç”¨æˆ·æ”¯æŒ")
    print("  âœ“ ä¸‰æ•°æ®æºç‹¬ç«‹å­˜å‚¨")
    print("  âœ“ è‡ªåŠ¨å®šæ—¶ä»»åŠ¡")
    print("  âœ“ æ™ºèƒ½è¯„åˆ†ç³»ç»Ÿ")
    print("\nğŸ”— è®¿é—®:")
    print("  APIæ–‡æ¡£: http://localhost:8000/docs")
    print("  ç³»ç»ŸçŠ¶æ€: http://localhost:8000/status")
    print("="*60 + "\n")
    
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)