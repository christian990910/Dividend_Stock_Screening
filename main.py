import os
import socket
# 1. é¡¶çº§è¡¥ä¸ï¼šå¼ºåˆ¶ IPv4
orig_getaddrinfo = socket.getaddrinfo
def patched_getaddrinfo(*args, **kwargs):
    res = orig_getaddrinfo(*args, **kwargs)
    return [r for r in res if r[0] == socket.AF_INET]
socket.getaddrinfo = patched_getaddrinfo

import time
from contextlib import asynccontextmanager
import datetime
import asyncio
import re
import json
import pandas as pd
import numpy as np
import akshare as ak
from typing import Optional, List
from sqlalchemy import create_engine, Column, String, Float, DateTime, Integer, desc, func, Text, Boolean, Date
from sqlalchemy.orm import sessionmaker, Session, declarative_base
from starlette.background import BackgroundTasks
from fastapi import FastAPI, Depends, HTTPException
from fastapi.responses import FileResponse
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import urllib3
import random
import efinance as ef
import requests
from requests.sessions import Session as RequestSession
import email_service

# ============================================================
# ç½‘ç»œé…ç½®
# ============================================================
_orig_request = RequestSession.request
def my_request(self, method, url, **kwargs):
    kwargs['proxies'] = {'http': None, 'https': None}
    if 'headers' not in kwargs or not kwargs['headers']:
        kwargs['headers'] = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Connection': 'keep-alive'
        }
    if 'timeout' not in kwargs:
        kwargs['timeout'] = 30
    return _orig_request(self, method, url, **kwargs)

RequestSession.request = my_request
os.environ['NO_PROXY'] = '*'
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============================================================
# æ•°æ®åº“é…ç½®
# ============================================================
SQLALCHEMY_DATABASE_URL = "sqlite:///./stock_advanced_system.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()
class User(Base):
    """
    ç”¨æˆ·è¡¨ - å­˜å‚¨ç³»ç»Ÿç”¨æˆ·ä¿¡æ¯
    
    ç”¨é€”: ç®¡ç†ç³»ç»Ÿç”¨æˆ·,å®ç°å¤šç”¨æˆ·éš”ç¦»
    """
    __tablename__ = "users"
    
    # ç³»ç»Ÿå­—æ®µ
    user_id = Column(Integer, primary_key=True, autoincrement=True, comment="ç”¨æˆ·ID - ç³»ç»Ÿè‡ªå¢")
    
    # ç™»å½•ä¿¡æ¯
    account = Column(String, unique=True, nullable=False, comment="ç™»å½•è´¦å· - ç”¨æˆ·å,å”¯ä¸€,ç”¨äºç™»å½•")
    nickname = Column(String, nullable=False, comment="ç”¨æˆ·æ˜µç§° - æ˜¾ç¤ºåç§°")
    password_hash = Column(String, nullable=False, comment="å¯†ç å“ˆå¸Œ - ä½¿ç”¨bcryptåŠ å¯†å­˜å‚¨")
    
    # é€šçŸ¥è®¾ç½®
    email = Column(String, nullable=False, comment="é€šçŸ¥é‚®ç®± - ç”¨äºæ¥æ”¶åˆ†ææŠ¥å‘Š")
    email_verified = Column(Boolean, default=False, comment="é‚®ç®±éªŒè¯çŠ¶æ€ - True:å·²éªŒè¯, False:æœªéªŒè¯")
    enable_daily_report = Column(Boolean, default=True, comment="å¯ç”¨æ¯æ—¥æŠ¥å‘Š - True:å‘é€, False:ä¸å‘é€")
    
    # å…¶ä»–ä¿¡æ¯
    avatar_url = Column(String, comment="å¤´åƒURL - ç”¨æˆ·å¤´åƒåœ°å€")
    phone = Column(String, comment="æ‰‹æœºå· - å¯é€‰")
    
    # çŠ¶æ€ä¿¡æ¯
    is_active = Column(Boolean, default=True, comment="è´¦å·çŠ¶æ€ - True:æ­£å¸¸, False:ç¦ç”¨")
    last_login_at = Column(DateTime, comment="æœ€åç™»å½•æ—¶é—´")
    
    # æ—¶é—´æˆ³
    created_at = Column(DateTime, default=datetime.datetime.now, comment="æ³¨å†Œæ—¶é—´")
    updated_at = Column(DateTime, default=datetime.datetime.now, onupdate=datetime.datetime.now, comment="æ›´æ–°æ—¶é—´")

class UserStockWatch(Base):
    """
    ç”¨æˆ·è‚¡ç¥¨å…³æ³¨è¡¨ - å­˜å‚¨ç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨åˆ—è¡¨
    
    ç”¨é€”: è®°å½•æ¯ä¸ªç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨,æ”¯æŒä¸ªæ€§åŒ–åˆ†æ
    """
    __tablename__ = "user_stock_watch"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID - è‡ªå¢")
    user_id = Column(String, index=True, comment="ç”¨æˆ·ID - å¤–é”®å…³è”usersè¡¨")
    stock_code = Column(String, index=True, comment="è‚¡ç¥¨ä»£ç  - 6ä½æ•°å­—,å¦‚600036")
    added_at = Column(DateTime, default=datetime.datetime.now, comment="æ·»åŠ æ—¶é—´ - ç”¨æˆ·æ·»åŠ å…³æ³¨çš„æ—¶é—´")

# ============================================================
# æŒä»“è®°å½•è¡¨ 
# ============================================================

class UserStockHolding(Base):
    """
    ç”¨æˆ·æŒä»“è¡¨ - è®°å½•ç”¨æˆ·è´­ä¹°çš„è‚¡ç¥¨
    
    åŠŸèƒ½:
    - è®°å½•è´­ä¹°æ•°é‡å’Œä»·æ ¼
    - è®¡ç®—æŒä»“æˆæœ¬å’Œç›ˆäº
    - æ”¯æŒå¤šæ¬¡ä¹°å…¥(ä¸åŒæ‰¹æ¬¡)
    """
    __tablename__ = "user_stock_holdings"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID")
    
    # å…³è”ä¿¡æ¯
    user_id = Column(Integer, index=True, nullable=False, comment="ç”¨æˆ·ID - å¤–é”®å…³è”users.user_id")
    stock_code = Column(String, index=True, nullable=False, comment="è‚¡ç¥¨ä»£ç  - 6ä½æ•°å­—")
    stock_name = Column(String, comment="è‚¡ç¥¨åç§° - å†—ä½™å­—æ®µ,æ–¹ä¾¿æŸ¥è¯¢")
    
    # è´­ä¹°ä¿¡æ¯
    purchase_quantity = Column(Integer, nullable=False, comment="è´­ä¹°æ•°é‡ - è‚¡æ•°(è‚¡)")
    purchase_price = Column(Float, nullable=False, comment="è´­ä¹°å•ä»· - ä¹°å…¥ä»·æ ¼(å…ƒ/è‚¡)")
    purchase_amount = Column(Float, comment="è´­ä¹°é‡‘é¢ - æ•°é‡*å•ä»·(å…ƒ)")
    purchase_date = Column(Date, nullable=False, comment="è´­ä¹°æ—¥æœŸ - å®é™…ä¹°å…¥æ—¥æœŸ")
    
    # æˆæœ¬ä¿¡æ¯
    commission = Column(Float, default=0, comment="æ‰‹ç»­è´¹ - äº¤æ˜“æ‰‹ç»­è´¹(å…ƒ)")
    total_cost = Column(Float, comment="æ€»æˆæœ¬ - è´­ä¹°é‡‘é¢+æ‰‹ç»­è´¹(å…ƒ)")
    cost_price = Column(Float, comment="æˆæœ¬ä»· - æ€»æˆæœ¬/æ•°é‡(å…ƒ/è‚¡)")
    
    # å½“å‰çŠ¶æ€
    current_quantity = Column(Integer, comment="å½“å‰æŒæœ‰æ•°é‡ - å¯èƒ½å› å–å‡ºè€Œå‡å°‘(è‚¡)")
    current_price = Column(Float, comment="å½“å‰ä»·æ ¼ - æœ€æ–°å¸‚ä»·(å…ƒ/è‚¡,è‡ªåŠ¨æ›´æ–°)")
    current_value = Column(Float, comment="å½“å‰å¸‚å€¼ - å½“å‰æ•°é‡*å½“å‰ä»·æ ¼(å…ƒ)")
    
    # ç›ˆäºä¿¡æ¯
    profit_loss = Column(Float, comment="æµ®åŠ¨ç›ˆäº - å½“å‰å¸‚å€¼-æ€»æˆæœ¬(å…ƒ)")
    profit_loss_pct = Column(Float, comment="ç›ˆäºæ¯”ä¾‹ - (å½“å‰ä»·-æˆæœ¬ä»·)/æˆæœ¬ä»·*100(%)")
    
    # äº¤æ˜“è®°å½•
    trade_type = Column(String, default='buy', comment="äº¤æ˜“ç±»å‹ - buy:ä¹°å…¥, sell:å–å‡º, dividend:åˆ†çº¢")
    trade_note = Column(Text, comment="äº¤æ˜“å¤‡æ³¨ - ç”¨æˆ·è‡ªå®šä¹‰å¤‡æ³¨")
    
    # çŠ¶æ€æ ‡è®°
    is_active = Column(Boolean, default=True, comment="æ˜¯å¦æŒæœ‰ - True:æŒæœ‰ä¸­, False:å·²å–å‡º")
    
    # æ—¶é—´æˆ³
    created_at = Column(DateTime, default=datetime.datetime.now, comment="åˆ›å»ºæ—¶é—´")
    updated_at = Column(DateTime, default=datetime.datetime.now, onupdate=datetime.datetime.now, comment="æ›´æ–°æ—¶é—´")


# ============================================================
# é‚®ä»¶é€šçŸ¥è®°å½•è¡¨
# ============================================================

class EmailNotification(Base):
    """
    é‚®ä»¶é€šçŸ¥è®°å½•è¡¨ - è®°å½•æ¯æ¬¡å‘é€çš„é‚®ä»¶
    
    åŠŸèƒ½:
    - è·Ÿè¸ªé‚®ä»¶å‘é€çŠ¶æ€
    - è®°å½•å¤±è´¥åŸå› 
    - æ”¯æŒé‡å‘æœºåˆ¶
    """
    __tablename__ = "email_notifications"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID")
    
    # æ”¶ä»¶ä¿¡æ¯
    user_id = Column(Integer, index=True, nullable=False, comment="ç”¨æˆ·ID")
    recipient_email = Column(String, nullable=False, comment="æ”¶ä»¶äººé‚®ç®±")
    
    # é‚®ä»¶å†…å®¹
    email_type = Column(String, nullable=False, comment="é‚®ä»¶ç±»å‹ - daily_report:æ¯æ—¥æŠ¥å‘Š, verify:éªŒè¯é‚®ä»¶, alert:é¢„è­¦")
    subject = Column(String, nullable=False, comment="é‚®ä»¶ä¸»é¢˜")
    content = Column(Text, comment="é‚®ä»¶å†…å®¹ - HTMLæ ¼å¼")
    
    # é™„ä»¶ä¿¡æ¯
    has_attachment = Column(Boolean, default=False, comment="æ˜¯å¦æœ‰é™„ä»¶")
    attachment_path = Column(String, comment="é™„ä»¶è·¯å¾„ - CSVæ–‡ä»¶è·¯å¾„")
    attachment_name = Column(String, comment="é™„ä»¶åç§° - æ˜¾ç¤ºçš„æ–‡ä»¶å")
    
    # å‘é€çŠ¶æ€
    status = Column(String, default='pending', comment="å‘é€çŠ¶æ€ - pending:å¾…å‘é€, sent:å·²å‘é€, failed:å¤±è´¥")
    send_time = Column(DateTime, comment="å‘é€æ—¶é—´ - å®é™…å‘é€æ—¶é—´")
    error_message = Column(Text, comment="é”™è¯¯ä¿¡æ¯ - å‘é€å¤±è´¥æ—¶çš„é”™è¯¯è¯¦æƒ…")
    retry_count = Column(Integer, default=0, comment="é‡è¯•æ¬¡æ•°")
    
    # æ—¶é—´æˆ³
    created_at = Column(DateTime, default=datetime.datetime.now, comment="åˆ›å»ºæ—¶é—´")
    updated_at = Column(DateTime, default=datetime.datetime.now, onupdate=datetime.datetime.now, comment="æ›´æ–°æ—¶é—´")

# ============================================================
# å¸‚åœºæ•°æ®è¡¨
# ============================================================

class DailyMarketData(Base):
    """
    æ¯æ—¥å¸‚åœºæ•°æ®è¡¨ - å­˜å‚¨å…¨å¸‚åœºè‚¡ç¥¨çš„æ¯æ—¥å®æ—¶è¡Œæƒ…
    
    æ•°æ®æº: ä¸œæ–¹è´¢å¯Œç½‘API (stock_zh_a_spot_em)
    æ›´æ–°é¢‘ç‡: æ¯æ—¥15:30è‡ªåŠ¨æ›´æ–°
    ç”¨é€”: è·å–æœ€æ–°ä»·æ ¼ã€ä¼°å€¼ã€æˆäº¤ç­‰å®æ—¶æ•°æ®
    """
    __tablename__ = "daily_market_data"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID - è‡ªå¢")
    date = Column(Date, index=True, comment="æ•°æ®æ—¥æœŸ - äº¤æ˜“æ—¥æœŸ")
    code = Column(String, index=True, comment="è‚¡ç¥¨ä»£ç  - 6ä½æ•°å­—")
    name = Column(String, comment="è‚¡ç¥¨åç§° - ä¸­æ–‡ç®€ç§°,å¦‚'æ‹›å•†é“¶è¡Œ'")
    
    # ä»·æ ¼ç›¸å…³å­—æ®µ
    latest_price = Column(Float, comment="æœ€æ–°ä»· - å½“å‰äº¤æ˜“ä»·æ ¼(å…ƒ)")
    change_pct = Column(Float, comment="æ¶¨è·Œå¹… - ç›¸å¯¹æ˜¨æ”¶çš„æ¶¨è·Œç™¾åˆ†æ¯”(%)")
    change_amount = Column(Float, comment="æ¶¨è·Œé¢ - ç›¸å¯¹æ˜¨æ”¶çš„æ¶¨è·Œé‡‘é¢(å…ƒ)")
    high = Column(Float, comment="æœ€é«˜ä»· - å½“æ—¥æœ€é«˜æˆäº¤ä»·(å…ƒ)")
    low = Column(Float, comment="æœ€ä½ä»· - å½“æ—¥æœ€ä½æˆäº¤ä»·(å…ƒ)")
    open = Column(Float, comment="å¼€ç›˜ä»· - å½“æ—¥å¼€ç›˜ä»·æ ¼(å…ƒ)")
    close_prev = Column(Float, comment="æ˜¨æ”¶ä»· - å‰ä¸€äº¤æ˜“æ—¥æ”¶ç›˜ä»·(å…ƒ)")
    
    # æˆäº¤ç›¸å…³å­—æ®µ
    volume = Column(Float, comment="æˆäº¤é‡ - å½“æ—¥æˆäº¤è‚¡ç¥¨æ•°é‡(æ‰‹,1æ‰‹=100è‚¡)")
    amount = Column(Float, comment="æˆäº¤é¢ - å½“æ—¥æˆäº¤é‡‘é¢æ€»é¢(å…ƒ)")
    amplitude = Column(Float, comment="æŒ¯å¹… - (æœ€é«˜-æœ€ä½)/æ˜¨æ”¶*100(%)")
    turnover_rate = Column(Float, comment="æ¢æ‰‹ç‡ - æˆäº¤é‡/æµé€šè‚¡æœ¬*100(%)")
    volume_ratio = Column(Float, comment="é‡æ¯” - å½“æ—¥æˆäº¤é‡/è¿‘5æ—¥å¹³å‡æˆäº¤é‡")
    
    # ä¼°å€¼ç›¸å…³å­—æ®µ
    pe_dynamic = Column(Float, comment="å¸‚ç›ˆç‡-åŠ¨æ€ - è‚¡ä»·/æœ€è¿‘12ä¸ªæœˆæ¯è‚¡æ”¶ç›Š")
    pb = Column(Float, comment="å¸‚å‡€ç‡ - è‚¡ä»·/æ¯è‚¡å‡€èµ„äº§")
    
    # å¸‚å€¼ç›¸å…³å­—æ®µ
    total_market_cap = Column(Float, comment="æ€»å¸‚å€¼ - è‚¡ä»·*æ€»è‚¡æœ¬(å…ƒ)")
    circulating_market_cap = Column(Float, comment="æµé€šå¸‚å€¼ - è‚¡ä»·*æµé€šè‚¡æœ¬(å…ƒ)")
    
    # å…¶ä»–æŒ‡æ ‡
    rise_speed = Column(Float, comment="æ¶¨é€Ÿ - å½“å‰æ¶¨è·Œå¹…å˜åŒ–é€Ÿåº¦(%/åˆ†é’Ÿ)")
    change_5min = Column(Float, comment="5åˆ†é’Ÿæ¶¨è·Œ - æœ€è¿‘5åˆ†é’Ÿçš„æ¶¨è·Œå¹…(%)")
    
    updated_at = Column(DateTime, default=datetime.datetime.now, comment="æ›´æ–°æ—¶é—´ - æ•°æ®å…¥åº“æ—¶é—´")


# ============================================================
# å†å²æ•°æ®è¡¨
# ============================================================

class HistoricalData(Base):
    """
    å†å²è¡Œæƒ…æ•°æ®è¡¨ - å­˜å‚¨è‚¡ç¥¨çš„å†å²Kçº¿æ•°æ®
    
    æ•°æ®æº: efinance / akshare (å‰å¤æƒ)
    æ›´æ–°é¢‘ç‡: æŒ‰éœ€è·å–
    ç”¨é€”: è®¡ç®—æŠ€æœ¯æŒ‡æ ‡(æ³¢åŠ¨ç‡ã€å‡çº¿ç­‰)
    æ•°æ®ç±»å‹: å‰å¤æƒæ•°æ®,å·²è°ƒæ•´å†å²ä»·æ ¼
    """
    __tablename__ = "historical_data"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID - è‡ªå¢")
    stock_code = Column(String, index=True, comment="è‚¡ç¥¨ä»£ç  - 6ä½æ•°å­—")
    date = Column(Date, index=True, comment="äº¤æ˜“æ—¥æœŸ - Kçº¿æ—¥æœŸ")
    
    # OHLCæ•°æ® (Open High Low Close)
    open = Column(Float, comment="å¼€ç›˜ä»· - å½“æ—¥å¼€ç›˜ä»·æ ¼(å…ƒ,å‰å¤æƒ)")
    close = Column(Float, comment="æ”¶ç›˜ä»· - å½“æ—¥æ”¶ç›˜ä»·æ ¼(å…ƒ,å‰å¤æƒ)")
    high = Column(Float, comment="æœ€é«˜ä»· - å½“æ—¥æœ€é«˜ä»·æ ¼(å…ƒ,å‰å¤æƒ)")
    low = Column(Float, comment="æœ€ä½ä»· - å½“æ—¥æœ€ä½ä»·æ ¼(å…ƒ,å‰å¤æƒ)")
    
    # æˆäº¤æ•°æ®
    volume = Column(Integer, comment="æˆäº¤é‡ - å½“æ—¥æˆäº¤è‚¡æ•°(è‚¡)")
    amount = Column(Float, comment="æˆäº¤é¢ - å½“æ—¥æˆäº¤é‡‘é¢(å…ƒ)")
    
    # æŠ€æœ¯æŒ‡æ ‡
    amplitude = Column(Float, comment="æŒ¯å¹… - (æœ€é«˜-æœ€ä½)/æ˜¨æ”¶*100(%)")
    change_pct = Column(Float, comment="æ¶¨è·Œå¹… - (æ”¶ç›˜-æ˜¨æ”¶)/æ˜¨æ”¶*100(%)")
    change_amount = Column(Float, comment="æ¶¨è·Œé¢ - æ”¶ç›˜ä»·-æ˜¨æ”¶ä»·(å…ƒ)")
    turnover_rate = Column(Float, comment="æ¢æ‰‹ç‡ - æˆäº¤é‡/æµé€šè‚¡æœ¬*100(%)")
    
    created_at = Column(DateTime, default=datetime.datetime.now, comment="åˆ›å»ºæ—¶é—´ - æ•°æ®å…¥åº“æ—¶é—´")


# ============================================================
# åˆ†çº¢æ•°æ®è¡¨
# ============================================================

class DividendData(Base):
    """
    åˆ†çº¢æ´¾æ¯æ•°æ®è¡¨ - å­˜å‚¨è‚¡ç¥¨çš„åˆ†çº¢é…è‚¡ä¿¡æ¯
    
    æ•°æ®æº: ç™¾åº¦è‚¡å¸‚é€š (news_trade_notify_dividend_baidu)
    æ›´æ–°é¢‘ç‡: æŒ‰éœ€è·å–
    ç”¨é€”: è®¡ç®—è‚¡æ¯ç‡,è¯„ä¼°åˆ†çº¢èƒ½åŠ›
    """
    __tablename__ = "dividend_data"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID - è‡ªå¢")
    stock_code = Column(String, index=True, comment="è‚¡ç¥¨ä»£ç  - 6ä½æ•°å­—")
    stock_name = Column(String, comment="è‚¡ç¥¨åç§° - ä¸­æ–‡ç®€ç§°")
    ex_dividend_date = Column(Date, index=True, comment="é™¤æƒé™¤æ¯æ—¥ - åˆ†çº¢ç”Ÿæ•ˆæ—¥æœŸ")
    
    # åˆ†çº¢æ–¹æ¡ˆ
    dividend = Column(String, comment="ç°é‡‘åˆ†çº¢ - æ¯10è‚¡æ´¾ç°é‡‘é¢(å…ƒ),å¦‚'10æ´¾5'è¡¨ç¤ºæ¯10è‚¡æ´¾5å…ƒ")
    bonus_share = Column(String, comment="é€è‚¡ - æ¯10è‚¡é€è‚¡æ•°é‡,å¦‚'10é€3'è¡¨ç¤ºæ¯10è‚¡é€3è‚¡")
    capitalization = Column(String, comment="è½¬å¢è‚¡æœ¬ - æ¯10è‚¡è½¬å¢æ•°é‡,å¦‚'10è½¬5'è¡¨ç¤ºæ¯10è‚¡è½¬å¢5è‚¡")
    physical = Column(String, comment="å®ç‰©åˆ†é… - å…¶ä»–å½¢å¼çš„åˆ†é…")
    
    # å…¶ä»–ä¿¡æ¯
    exchange = Column(String, comment="äº¤æ˜“æ‰€ - ä¸Šäº¤æ‰€/æ·±äº¤æ‰€")
    report_period = Column(String, comment="æŠ¥å‘ŠæœŸ - åˆ†çº¢å¯¹åº”çš„è´¢æŠ¥æœŸ,å¦‚'2023å¹´æŠ¥'")
    
    created_at = Column(DateTime, default=datetime.datetime.now, comment="åˆ›å»ºæ—¶é—´ - æ•°æ®å…¥åº“æ—¶é—´")


# ============================================================
# åˆ†æç»“æœè¡¨
# ============================================================

class StockAnalysisResult(Base):
    """
    è‚¡ç¥¨åˆ†æç»“æœè¡¨ - å­˜å‚¨è‚¡ç¥¨çš„ç»¼åˆåˆ†æè¯„åˆ†
    
    ç”Ÿæˆæ–¹å¼: ç³»ç»Ÿè‡ªåŠ¨åˆ†æè®¡ç®—
    æ›´æ–°é¢‘ç‡: æ¯æ—¥16:00è‡ªåŠ¨æ›´æ–°
    ç”¨é€”: æ ¹æ®ä¸‰ç»´åº¦è¯„åˆ†ç­›é€‰ä¼˜è´¨è‚¡ç¥¨
    è¯„åˆ†ç»´åº¦: æ³¢åŠ¨ç‡(0-40) + è‚¡æ¯ç‡(0-30) + æˆé•¿æ€§(0-30) = æ€»åˆ†(0-100)
    """
    __tablename__ = "stock_analysis_results"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID - è‡ªå¢")
    stock_code = Column(String, index=True, comment="è‚¡ç¥¨ä»£ç  - 6ä½æ•°å­—")
    stock_name = Column(String, comment="è‚¡ç¥¨åç§° - ä¸­æ–‡ç®€ç§°")
    analysis_date = Column(Date, index=True, comment="åˆ†ææ—¥æœŸ - æ•°æ®åˆ†ææ—¥æœŸ")
    
    # åŸºç¡€æ•°æ®
    latest_price = Column(Float, comment="æœ€æ–°ä»· - åˆ†ææ—¶çš„è‚¡ç¥¨ä»·æ ¼(å…ƒ)")
    pe_ratio = Column(Float, comment="å¸‚ç›ˆç‡ - åŠ¨æ€å¸‚ç›ˆç‡")
    pb_ratio = Column(Float, comment="å¸‚å‡€ç‡ - å½“å‰å¸‚å‡€ç‡")
    
    # æ³¢åŠ¨ç‡æŒ‡æ ‡
    volatility_30d = Column(Float, comment="30æ—¥æ³¢åŠ¨ç‡ - æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥çš„å¹´åŒ–æ³¢åŠ¨ç‡(%)")
    volatility_60d = Column(Float, comment="60æ—¥æ³¢åŠ¨ç‡ - æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥çš„å¹´åŒ–æ³¢åŠ¨ç‡(%)")
    
    # è´¢åŠ¡æŒ‡æ ‡
    dividend_yield = Column(Float, comment="è‚¡æ¯ç‡ - å¹´åº¦åˆ†çº¢/å½“å‰è‚¡ä»·*100(%)")
    roe = Column(Float, comment="ROEå‡€èµ„äº§æ”¶ç›Šç‡ - å‡€åˆ©æ¶¦/å‡€èµ„äº§*100(%)")
    profit_growth = Column(Float, comment="åˆ©æ¶¦å¢é•¿ç‡ - å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡(%)")
    
    # è¯„åˆ†è¯¦æƒ…
    volatility_score = Column(Integer, comment="æ³¢åŠ¨ç‡è¯„åˆ† - 0-40åˆ†,æ³¢åŠ¨è¶Šä½åˆ†æ•°è¶Šé«˜")
    dividend_score = Column(Integer, comment="è‚¡æ¯ç‡è¯„åˆ† - 0-30åˆ†,è‚¡æ¯ç‡è¶Šé«˜åˆ†æ•°è¶Šé«˜")
    growth_score = Column(Integer, comment="æˆé•¿æ€§è¯„åˆ† - 0-30åˆ†,ROEè¶Šé«˜åˆ†æ•°è¶Šé«˜")
    total_score = Column(Integer, comment="ç»¼åˆè¯„åˆ† - æ€»åˆ†0-100åˆ†")
    
    # åˆ†æç»“æœ
    suggestion = Column(String, comment="æŠ•èµ„å»ºè®® - å¼ºçƒˆæ¨è/æ¨è/å¯ä»¥å…³æ³¨/è§‚æœ›/ä¸æ¨è")
    data_source = Column(String, comment="æ•°æ®æ¥æº - market/enhanced/mixed")
    
    created_at = Column(DateTime, default=datetime.datetime.now, comment="åˆ›å»ºæ—¶é—´ - åˆ†æç»“æœç”Ÿæˆæ—¶é—´")


# ============================================================
# æŒ‡æ•°æˆåˆ†è‚¡è¡¨ (æ–°å¢)
# ============================================================

class IndexConstituent(Base):
    """
    æŒ‡æ•°æˆåˆ†è‚¡è¡¨ - å­˜å‚¨å„å¤§æŒ‡æ•°çš„æˆåˆ†è‚¡åŠæƒé‡ä¿¡æ¯
    
    æ•°æ®æº: ä¸­è¯æŒ‡æ•°å…¬å¸/äº¤æ˜“æ‰€å®˜ç½‘
    æ›´æ–°é¢‘ç‡: å­£åº¦è°ƒæ•´,æ¯å­£åº¦é¦–æœˆæ›´æ–°
    ç”¨é€”: 
    1. è·Ÿè¸ªæŒ‡æ•°æˆåˆ†è‚¡å˜åŒ–
    2. åˆ†æè¡Œä¸šé…ç½®æƒé‡
    3. æŒ‡æ•°å¢å¼ºç­–ç•¥æ„å»º
    4. æˆåˆ†è‚¡è½®æ¢ç›‘æ§
    
    æ”¯æŒæŒ‡æ•°:
    - æ²ªæ·±300 (000300)
    - ä¸­è¯500 (000905)
    - ä¸Šè¯50 (000016)
    - åˆ›ä¸šæ¿æŒ‡ (399006)
    - ç§‘åˆ›50 (000688)
    ç­‰ä¸»è¦å¸‚åœºæŒ‡æ•°
    """
    __tablename__ = "index_constituents"
    
    id = Column(Integer, primary_key=True, autoincrement=True, comment="ä¸»é”®ID - è‡ªå¢")
    
    # æ—¶é—´æ ‡è¯†
    date = Column(Date, index=True, comment="ç”Ÿæ•ˆæ—¥æœŸ - æˆåˆ†è‚¡è°ƒæ•´ç”Ÿæ•ˆæ—¥æœŸ,ç”¨äºå†å²è¿½æº¯")
    
    # æŒ‡æ•°ä¿¡æ¯
    index_code = Column(String, index=True, comment="æŒ‡æ•°ä»£ç  - 6ä½æ•°å­—,å¦‚'000300'è¡¨ç¤ºæ²ªæ·±300")
    index_name = Column(String, comment="æŒ‡æ•°åç§° - ä¸­æ–‡åç§°,å¦‚'æ²ªæ·±300'")
    index_name_eng = Column(String, comment="æŒ‡æ•°è‹±æ–‡åç§° - å¦‚'CSI 300'")
    
    # æˆåˆ†è‚¡ä¿¡æ¯
    constituent_code = Column(String, index=True, comment="æˆä»½åˆ¸ä»£ç  - 6ä½è‚¡ç¥¨ä»£ç ,å¦‚'600036'")
    constituent_name = Column(String, comment="æˆä»½åˆ¸åç§° - è‚¡ç¥¨ä¸­æ–‡ç®€ç§°,å¦‚'æ‹›å•†é“¶è¡Œ'")
    constituent_name_eng = Column(String, comment="æˆä»½åˆ¸è‹±æ–‡åç§° - å¦‚'China Merchants Bank'")
    
    # äº¤æ˜“æ‰€ä¿¡æ¯
    exchange = Column(String, comment="äº¤æ˜“æ‰€ - ä¸Šäº¤æ‰€/æ·±äº¤æ‰€,å€¼ä¸º'SH'æˆ–'SZ'")
    exchange_eng = Column(String, comment="äº¤æ˜“æ‰€è‹±æ–‡åç§° - 'Shanghai Stock Exchange'æˆ–'Shenzhen Stock Exchange'")
    
    # æƒé‡ä¿¡æ¯
    weight = Column(Float, comment="æƒé‡ - è¯¥æˆåˆ†è‚¡åœ¨æŒ‡æ•°ä¸­çš„æƒé‡ç™¾åˆ†æ¯”(%),å¦‚5.23è¡¨ç¤ºå æ¯”5.23%")
    
    # è¾…åŠ©å­—æ®µ
    industry = Column(String, comment="æ‰€å±è¡Œä¸š - æˆåˆ†è‚¡æ‰€å±çš„ç”³ä¸‡ä¸€çº§è¡Œä¸š")
    market_cap = Column(Float, comment="å¸‚å€¼ - æˆåˆ†è‚¡æ€»å¸‚å€¼(äº¿å…ƒ)")
    
    created_at = Column(DateTime, default=datetime.datetime.now, comment="åˆ›å»ºæ—¶é—´ - æ•°æ®å…¥åº“æ—¶é—´")
    updated_at = Column(DateTime, default=datetime.datetime.now, onupdate=datetime.datetime.now, 
                       comment="æ›´æ–°æ—¶é—´ - æœ€åä¿®æ”¹æ—¶é—´")
    
    # çŠ¶æ€æ ‡è®°
    is_active = Column(Integer, default=1, comment="æ˜¯å¦æœ‰æ•ˆ - 1:å½“å‰æˆåˆ†è‚¡, 0:å·²è°ƒå‡º")


# ============================================================
# ç´¢å¼•å’Œçº¦æŸè¯´æ˜
# ============================================================

"""
æ•°æ®åº“ç´¢å¼•è®¾è®¡:

1. è”åˆç´¢å¼•:
   - (date, code) on daily_market_data
   - (stock_code, date) on historical_data
   - (date, index_code) on index_constituents
   
2. å•å­—æ®µç´¢å¼•:
   - user_id, stock_code on user_stock_watch
   - code on daily_market_data
   - stock_code on historical_data, dividend_data, stock_analysis_results
   - index_code, constituent_code on index_constituents

3. å”¯ä¸€çº¦æŸ:
   - (date, code) on daily_market_data (ä¸€å¤©ä¸€åªè‚¡ç¥¨åªæœ‰ä¸€æ¡è®°å½•)
   - (stock_code, date) on historical_data (é¿å…é‡å¤Kçº¿)
   - (date, index_code, constituent_code) on index_constituents (é¿å…é‡å¤æˆåˆ†è‚¡)
"""


Base.metadata.create_all(bind=engine)

# ============================================================
# æ ¸å¿ƒæ•°æ®æœåŠ¡å±‚ - å¢å¼ºå­—æ®µæ˜ å°„
# ============================================================
class StockDataService:
    def __init__(self):
        self.target_ut = "fa5fd1943c7b386f172d6893dbfba10b"
        self.target_cookies = {
            "qgqp_b_id": "9fb8c26c0a40e0e20ffd551bb6a52cdf",
            "st_nvi": "4U97b8QAwVvKIFT5nsAGl367a",
            "st_si": "69103863020676",
            "nid18": "03c4e656b6d9f1dfd8b102df6f142ef1",
            "st_sn": "23"
        }
        
        # âœ… å¢å¼ºç‰ˆå­—æ®µæ˜ å°„ - åŒ…å«æ‰€æœ‰å¯ç”¨å­—æ®µ
        self.em_fields_map = {
            # åŸºç¡€ä¿¡æ¯
            'f12': 'code',           # ä»£ç 
            'f14': 'name',           # åç§°
            
            # ä»·æ ¼ç›¸å…³
            'f2': 'latest_price',    # æœ€æ–°ä»·
            'f3': 'change_pct',      # æ¶¨è·Œå¹…
            'f4': 'change_amount',   # æ¶¨è·Œé¢
            'f15': 'high',           # æœ€é«˜
            'f16': 'low',            # æœ€ä½
            'f17': 'open',           # ä»Šå¼€
            'f18': 'close_prev',     # æ˜¨æ”¶
            
            # æˆäº¤ç›¸å…³
            'f5': 'volume',          # æˆäº¤é‡(æ‰‹)
            'f6': 'amount',          # æˆäº¤é¢(å…ƒ)
            'f7': 'amplitude',       # æŒ¯å¹…
            'f8': 'turnover_rate',   # æ¢æ‰‹ç‡
            'f10': 'volume_ratio',   # é‡æ¯”
            
            # ä¼°å€¼ç›¸å…³
            'f9': 'pe_dynamic',      # å¸‚ç›ˆç‡-åŠ¨æ€
            'f23': 'pb',             # å¸‚å‡€ç‡
            
            # å¸‚å€¼ç›¸å…³
            'f20': 'total_market_cap',        # æ€»å¸‚å€¼
            'f21': 'circulating_market_cap',  # æµé€šå¸‚å€¼
            
            # å…¶ä»–
            'f11': 'rise_speed',     # æ¶¨é€Ÿ
            'f22': 'change_5min',    # 5åˆ†é’Ÿæ¶¨è·Œ
        }

    def get_db(self) -> Session:
        db = SessionLocal()
        return db

    def _safe_float(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return None
            # å¤„ç†ç™¾åˆ†æ¯”
            if isinstance(val, str) and '%' in val:
                return float(val.replace('%', ''))
            return float(val)
        except:
            return None
    
    def _safe_int(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•°"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return None
            return int(float(val))
        except:
            return None

    def refresh_ut(self):
        """è‡ªåŠ¨åˆ·æ–° ut å‚æ•°"""
        print("ğŸ”„ æ­£åœ¨åˆ·æ–° ut å‚æ•°...")
        try:
            url = "https://quote.eastmoney.com/center/gridlist.html"
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/121.0 Safari/537.36"
            }
            response = requests.get(url, headers=headers, timeout=10, verify=False, proxies={"http": None, "https": None})
            match = re.search(r'ut:\s*"([a-z0-9]+)"', response.text)
            if match:
                new_ut = match.group(1)
                self.target_ut = new_ut
                print(f"âœ… æˆåŠŸåˆ·æ–° ut: {new_ut}")
                return True
            else:
                print("âŒ æœªèƒ½æå–åˆ° ut")
                return False
        except Exception as e:
            print("âŒ åˆ·æ–° ut å¤±è´¥:", e)
            return False

    async def fetch_em_data_via_web_api(self, page_size: int = 100) -> pd.DataFrame:
        """å¢å¼ºç‰ˆæ•°æ®æŠ“å– - å®Œæ•´å­—æ®µæ˜ å°„"""
        all_dfs = []
        current_page = 1
        total_pages = 999

        url = "https://push2.eastmoney.com/api/qt/clist/get"

        headers = {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Connection": "keep-alive",
            "Referer": "https://quote.eastmoney.com/center/gridlist.html",
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1"
        }

        print(f"\nğŸŒ å¯åŠ¨å¢å¼ºç‰ˆæ•°æ®æŠ“å– (æ¯é¡µ {page_size} æ¡)")
        print(f"   å­—æ®µæ•°é‡: {len(self.em_fields_map)} ä¸ª\n")

        session = requests.Session()
        session.trust_env = False
        session.proxies = {"http": None, "https": None}
        session.cookies.update(self.target_cookies)

        while current_page <= total_pages:
            params = {
                "np": "1",
                "fltt": "1",
                "invt": "2",
                "cb": f"jQuery37109323508735388775_{int(time.time()*1000)}",
                "fs": "m:0+t:6+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:81+s:262144+f:!2",
                "fields": ",".join(self.em_fields_map.keys()),  # è¯·æ±‚æ‰€æœ‰å­—æ®µ
                "fid": "f3",
                "pn": str(current_page),
                "pz": str(page_size),
                "po": "1",
                "dect": "1",
                "ut": self.target_ut,
                "wbp2u": "|0|0|0|web",
                "_": str(int(time.time() * 1000))
            }

            try:
                print(f"   â¤ æŠ“å–ç¬¬ {current_page}/{total_pages if total_pages != 999 else '?'} é¡µ...")

                response = await asyncio.to_thread(
                    session.get, url, params=params, headers=headers, timeout=20, verify=False
                )

                if response.status_code != 200:
                    print(f"   âš ï¸ çŠ¶æ€ç å¼‚å¸¸: {response.status_code}")
                    break

                raw_text = response.text
                json_match = re.search(r'jQuery.*?\((.*)\)', raw_text)
                
                if not json_match:
                    print("   âš ï¸ JSONP è§£æå¤±è´¥")
                    break

                json_str = json_match.group(1)
                res_json = json.loads(json_str)

                if not res_json or not res_json.get("data"):
                    print("âš ï¸ æ•°æ®ä¸ºç©ºï¼Œå°è¯•åˆ·æ–° ut...")
                    if self.refresh_ut():
                        print("ğŸ” ä½¿ç”¨æ–° ut é‡è¯•...")
                        params["ut"] = self.target_ut
                        response = await asyncio.to_thread(
                            session.get, url, params=params, headers=headers, timeout=20, verify=False
                        )
                        raw_text = response.text
                        json_match = re.search(r'jQuery.*?\((.*)\)', raw_text)
                        if json_match:
                            json_str = json_match.group(1)
                            res_json = json.loads(json_str)
                            if not res_json or not res_json.get("data"):
                                print("âŒ åˆ·æ–°åä»å¤±è´¥")
                                break
                        else:
                            break
                    else:
                        break

                if current_page == 1:
                    total_records = res_json["data"]["total"]
                    total_pages = (total_records + page_size - 1) // page_size
                    print(f"   ğŸ“Š å…¨å¸‚åœºå…± {total_records} åªè‚¡ç¥¨ï¼Œé¢„è®¡ {total_pages} é¡µ")

                batch_df = pd.DataFrame(res_json["data"]["diff"])
                all_dfs.append(batch_df)

                if current_page >= total_pages:
                    break

                wait_time = random.uniform(10, 50)
                print(f"   ğŸ’¤ éšæœºç­‰å¾… {wait_time:.1f} ç§’...")
                await asyncio.sleep(wait_time)

                current_page += 1

            except Exception as e:
                print(f"   âŒ ç¬¬ {current_page} é¡µå¤±è´¥: {str(e)[:100]}")
                break

        session.close()

        if not all_dfs:
            return pd.DataFrame()

        final_df = pd.concat(all_dfs, ignore_index=True)
        
        # å­—æ®µé‡å‘½å
        final_df = final_df.rename(columns=self.em_fields_map)

        print(f"\nâœ… æ€»è®¡è·å– {len(final_df)} æ¡æ•°æ®")
        
        # æ˜¾ç¤ºå­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
        print(f"\nğŸ“Š å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
        for col in ['code', 'name', 'latest_price', 'pe_dynamic', 'pb', 'volume', 'amount', 'turnover_rate', 'amplitude']:
            if col in final_df.columns:
                non_null = final_df[col].notna().sum()
                pct = (non_null / len(final_df)) * 100
                status = "âœ…" if pct > 90 else ("âš ï¸" if pct > 50 else "âŒ")
                print(f"   {status} {col:20s}: {non_null:5d}/{len(final_df)} ({pct:5.1f}%)")

        return final_df

    async def fetch_daily_market_data(self, force: bool = False) -> dict:
        """å¢å¼ºç‰ˆå¸‚åœºæ•°æ®è·å– - å®Œæ•´å­—æ®µä¿å­˜"""
        db = self.get_db()
        today = datetime.date.today()
        
        try:
            if not force and db.query(DailyMarketData).filter(DailyMarketData.date == today).first():
                db.close()
                return {"status": "skip", "message": "ä»Šæ—¥æ•°æ®å·²å­˜åœ¨"}

            # æ–¹æ¡ˆ1: ä½¿ç”¨å¢å¼ºçš„Web API
            df = await self.fetch_em_data_via_web_api(page_size=100)
            
            # æ–¹æ¡ˆ2: å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨ efinance ä¿åº•
            if df.empty:
                print("âš ï¸ Web API å¤±è´¥ï¼Œå¯åŠ¨ efinance ä¿åº•...")
                df = await asyncio.to_thread(ef.stock.get_realtime_quotes)
                # efinance å­—æ®µæ˜ å°„
                df = df.rename(columns={
                    'è‚¡ç¥¨ä»£ç ': 'code',
                    'è‚¡ç¥¨åç§°': 'name',
                    'æœ€æ–°ä»·': 'latest_price',
                    'æ¶¨è·Œå¹…': 'change_pct',
                    'æ¶¨è·Œé¢': 'change_amount',
                    'æˆäº¤é‡': 'volume',
                    'æˆäº¤é¢': 'amount',
                    'æŒ¯å¹…': 'amplitude',
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'ä»Šå¼€': 'open',
                    'æ˜¨æ”¶': 'close_prev',
                    'é‡æ¯”': 'volume_ratio',
                    'æ¢æ‰‹ç‡': 'turnover_rate',
                    'åŠ¨æ€å¸‚ç›ˆç‡': 'pe_dynamic',
                    'å¸‚å‡€ç‡': 'pb',
                    'æ€»å¸‚å€¼': 'total_market_cap',
                    'æµé€šå¸‚å€¼': 'circulating_market_cap'
                })
            
            if df.empty:
                db.close()
                return {"status": "error", "message": "æ— æ³•è·å–è¡Œæƒ…"}

            # åˆ é™¤ä»Šæ—¥æ—§æ•°æ®
            db.query(DailyMarketData).filter(DailyMarketData.date == today).delete()
            db.commit()

            print(f"\nğŸ’¾ å­˜å…¥æ•°æ®åº“: {len(df)} æ¡è®°å½•")
            
            batch = []
            field_stats = {}  # ç»Ÿè®¡å„å­—æ®µçš„éç©ºæ•°é‡
            
            for _, row in df.iterrows():
                # æå–ä»£ç ï¼ˆä¼˜å…ˆä»æ˜ å°„åçš„å­—æ®µè·å–ï¼‰
                code = str(row.get('code') or row.get('f12', ''))
                code = re.sub(r'\D', '', code)  # åªä¿ç•™æ•°å­—
                
                if not code:
                    continue
                
                # åˆ›å»ºè®°å½• - ä½¿ç”¨å¢å¼ºçš„å­—æ®µæ˜ å°„
                m = DailyMarketData(
                    date=today,
                    code=code,
                    name=str(row.get('name') or row.get('f14', '')),
                    
                    # ä»·æ ¼ç›¸å…³
                    latest_price=self._safe_float(row.get('latest_price') or row.get('f2')),
                    change_pct=self._safe_float(row.get('change_pct') or row.get('f3')),
                    change_amount=self._safe_float(row.get('change_amount') or row.get('f4')),
                    high=self._safe_float(row.get('high') or row.get('f15')),
                    low=self._safe_float(row.get('low') or row.get('f16')),
                    open=self._safe_float(row.get('open') or row.get('f17')),
                    close_prev=self._safe_float(row.get('close_prev') or row.get('f18')),
                    
                    # æˆäº¤ç›¸å…³
                    volume=self._safe_float(row.get('volume') or row.get('f5')),
                    amount=self._safe_float(row.get('amount') or row.get('f6')),
                    amplitude=self._safe_float(row.get('amplitude') or row.get('f7')),
                    turnover_rate=self._safe_float(row.get('turnover_rate') or row.get('f8')),
                    volume_ratio=self._safe_float(row.get('volume_ratio') or row.get('f10')),
                    
                    # ä¼°å€¼ç›¸å…³
                    pe_dynamic=self._safe_float(row.get('pe_dynamic') or row.get('f9')),
                    pb=self._safe_float(row.get('pb') or row.get('f23')),
                    
                    # å¸‚å€¼ç›¸å…³
                    total_market_cap=self._safe_float(row.get('total_market_cap') or row.get('f20')),
                    circulating_market_cap=self._safe_float(row.get('circulating_market_cap') or row.get('f21')),
                    
                    # å…¶ä»–
                    rise_speed=self._safe_float(row.get('rise_speed') or row.get('f11')),
                    change_5min=self._safe_float(row.get('change_5min') or row.get('f22')),
                    
                    updated_at=datetime.datetime.now()
                )
                
                # ç»Ÿè®¡å­—æ®µ
                for field in ['latest_price', 'pe_dynamic', 'pb', 'volume', 'amount', 'turnover_rate']:
                    val = getattr(m, field)
                    if val is not None:
                        field_stats[field] = field_stats.get(field, 0) + 1
                
                batch.append(m)
                
                # æ‰¹é‡æäº¤
                if len(batch) >= 500:
                    db.bulk_save_objects(batch)
                    db.commit()
                    batch = []
                    print(f"\nâœ… æ•°æ®ä¿å­˜å®Œæˆï¼Œå…± {saved_count} æ¡")
            
            # æäº¤å‰©ä½™æ•°æ®
            if batch:
                db.bulk_save_objects(batch)
                db.commit()
                saved_count += len(batch)
            
            # æ˜¾ç¤ºä¿å­˜ç»Ÿè®¡
            print(f"\nâœ… æ•°æ®ä¿å­˜å®Œæˆ!")
            print(f"\nğŸ“Š å­—æ®µä¿å­˜ç»Ÿè®¡:")
            total = len(df)
            for field, count in sorted(field_stats.items()):
                pct = (count / total) * 100
                status = "âœ…" if pct > 90 else ("âš ï¸" if pct > 50 else "âŒ")
                print(f"   {status} {field:20s}: {count:5d}/{total} ({pct:5.1f}%)")
            
            db.close()
            return {"status": "success", "count": len(df), "field_stats": field_stats}
            
        except Exception as e:
            db.close()
            raise e

    async def fetch_financial_metrics(self, stock_code: str):
        """ä¸ªè‚¡è´¢åŠ¡æ•°æ®è¡¥å¿æŠ“å–"""
        try:
            df = await asyncio.to_thread(ef.stock.get_base_info, stock_code)
            if df is None or df.empty:
                return 0.0, 0.0
            row = df.iloc[0]
            roe = self._safe_float(row.get('å‡€èµ„äº§æ”¶ç›Šç‡(%)', 0))
            growth = self._safe_float(row.get('å‡€åˆ©æ¶¦åŒæ¯”(%)', 0))
            return roe if roe else 0.0, growth if growth else 0.0
        except:
            return 0.0, 0.0

    async def fetch_historical_data(self, stock_code: str, start_date=None, end_date=None):
        """è·å–å†å²æ•°æ®"""
        db = self.get_db()
        try:
            if not end_date:
                end_date = datetime.date.today().strftime("%Y%m%d")
            if not start_date:
                start_date = (datetime.date.today() - datetime.timedelta(days=180)).strftime("%Y%m%d")
            
            # ä¼˜å…ˆ efinance
            try:
                df = await asyncio.to_thread(ef.stock.get_quote_history, stock_code)
                if not df.empty:
                    df = df.rename(columns={'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open', 
                                           'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume',
                                           'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude', 
                                           'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount',
                                           'æ¢æ‰‹ç‡': 'turnover_rate'})
            except:
                df = await asyncio.to_thread(ak.stock_zh_a_hist, symbol=stock_code, 
                                            period="daily", start_date=start_date, 
                                            end_date=end_date, adjust="qfq")
                if not df.empty:
                    df = df.rename(columns={'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open',
                                           'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume',
                                           'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
                                           'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount',
                                           'æ¢æ‰‹ç‡': 'turnover_rate'})

            if df.empty:
                db.close()
                return {"status": "error"}

            # åˆ é™¤æ—§æ•°æ®
            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
            
            # ä¿å­˜æ–°æ•°æ®
            for _, row in df.iterrows():
                h = HistoricalData(
                    stock_code=stock_code,
                    date=pd.to_datetime(row['date']).date(),
                    close=self._safe_float(row.get('close')),
                    open=self._safe_float(row.get('open')),
                    high=self._safe_float(row.get('high')),
                    low=self._safe_float(row.get('low')),
                    volume=self._safe_int(row.get('volume')),
                    amount=self._safe_float(row.get('amount')),
                    amplitude=self._safe_float(row.get('amplitude')),
                    change_pct=self._safe_float(row.get('change_pct')),
                    change_amount=self._safe_float(row.get('change_amount')),
                    turnover_rate=self._safe_float(row.get('turnover_rate'))
                )
                db.add(h)
                
            db.commit()
            db.close()
            return {"status": "success", "count": len(df)}
            
        except Exception as e:
            db.close()
            return {"status": "error", "message": str(e)}

    async def fetch_dividend_data(self, date_str: str = None) -> dict:
        """è·å–åˆ†çº¢æ•°æ®"""
        db = self.get_db()
        try:
            if not date_str:
                date_str = datetime.date.today().strftime("%Y%m%d")
            
            print(f"ğŸ’° è·å– {date_str} åˆ†çº¢æ•°æ®...")
            
            df = ak.news_trade_notify_dividend_baidu(date=date_str)
            
            if df.empty:
                db.close()
                return {"status": "success", "message": f"{date_str} æ— åˆ†çº¢æ•°æ®", "count": 0}
            
            target_date = datetime.datetime.strptime(date_str, "%Y%m%d").date()
            db.query(DividendData).filter(DividendData.ex_dividend_date == target_date).delete()
            
            count = 0
            for _, row in df.iterrows():
                dividend_data = DividendData(
                    stock_code=str(row['è‚¡ç¥¨ä»£ç ']),
                    stock_name=str(row['è‚¡ç¥¨ç®€ç§°']),
                    ex_dividend_date=datetime.datetime.strptime(str(row['é™¤æƒæ—¥']), "%Y-%m-%d").date(),
                    dividend=str(row['åˆ†çº¢']),
                    bonus_share=str(row['é€è‚¡']),
                    capitalization=str(row['è½¬å¢']),
                    physical=str(row['å®ç‰©']),
                    exchange=str(row['äº¤æ˜“æ‰€']),
                    report_period=str(row['æŠ¥å‘ŠæœŸ']),
                )
                db.add(dividend_data)
                count += 1
            
            db.commit()
            db.close()
            
            print(f"   âœ“ ä¿å­˜ {count} æ¡åˆ†çº¢æ•°æ®")
            
            return {"status": "success", "count": count}
            
        except Exception as e:
            db.close()
            return {"status": "error", "message": str(e)}

    async def analyze_stock(self, stock_code: str, db: Session = None) -> dict:
        """åˆ†æå•åªè‚¡ç¥¨"""
        is_internal = db is None
        if is_internal:
            db = self.get_db()
            
        try:
            today = datetime.date.today()
            market_data = db.query(DailyMarketData).filter(
                DailyMarketData.code == stock_code
            ).order_by(desc(DailyMarketData.date)).first()
            
            if not market_data:
                return {"status": "error", "message": "æ— å®æ—¶æ•°æ®"}

            # 1. è·å– ROE å’Œå¢é•¿ç‡
            roe, profit_growth = await self.fetch_financial_metrics(stock_code)
            
            # 2. è®¡ç®—æ³¢åŠ¨ç‡
            vol_30d = 0
            vol_60d = 0
            trend_score = 0
            
            hist = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).order_by(desc(HistoricalData.date)).limit(65).all()
            
            if len(hist) >= 30:
                closes = [h.close for h in reversed(hist) if h.close]
                if len(closes) >= 30:
                    series = pd.Series(closes)
                    
                    # 30æ—¥æ³¢åŠ¨ç‡
                    series_30 = pd.Series(closes[-30:])
                    log_ret_30 = np.log(series_30 / series_30.shift(1)).dropna()
                    vol_30d = log_ret_30.std() * np.sqrt(252) * 100 if len(log_ret_30) > 0 else 0
                    
                    # 60æ—¥æ³¢åŠ¨ç‡
                    if len(closes) >= 60:
                        series_60 = pd.Series(closes[-60:])
                        log_ret_60 = np.log(series_60 / series_60.shift(1)).dropna()
                        vol_60d = log_ret_60.std() * np.sqrt(252) * 100 if len(log_ret_60) > 0 else 0
                        
                        ma60 = series.rolling(60).mean().iloc[-1]
                        trend_score = 10 if closes[-1] > ma60 else 0

            # 3. è‚¡æ¯ç‡è®¡ç®—
            dividend_yield = 0
            one_year_ago = today - datetime.timedelta(days=365)
            dividends = db.query(DividendData).filter(
                DividendData.stock_code == stock_code,
                DividendData.ex_dividend_date >= one_year_ago
            ).all()
            
            if dividends and market_data.latest_price:
                total_dividend = 0
                for div in dividends:
                    div_str = str(div.dividend)
                    match = re.search(r'(\d+\.?\d*)', div_str)
                    if match:
                        total_dividend += float(match.group(1))
                
                if total_dividend > 0:
                    dividend_yield = (total_dividend / market_data.latest_price) * 100

            # 4. è¯„åˆ†ç³»ç»Ÿ
            volatility_score = 0
            if vol_30d > 0:
                if vol_30d < 20:
                    volatility_score = 40
                elif vol_30d < 30:
                    volatility_score = 30
                elif vol_30d < 40:
                    volatility_score = 20
                elif vol_30d < 50:
                    volatility_score = 10
            
            dividend_score = 0
            if dividend_yield >= 5:
                dividend_score = 30
            elif dividend_yield >= 4:
                dividend_score = 25
            elif dividend_yield >= 3:
                dividend_score = 20
            elif dividend_yield >= 2:
                dividend_score = 15
            elif dividend_yield >= 1:
                dividend_score = 10
            
            growth_score = 0
            if roe > 15:
                growth_score = 30
            elif roe > 12:
                growth_score = 25
            elif roe > 10:
                growth_score = 20
            elif roe > 8:
                growth_score = 15
            elif roe > 5:
                growth_score = 10
            
            total = volatility_score + dividend_score + growth_score
            
            if total >= 70:
                suggestion = "å¼ºçƒˆæ¨è"
            elif total >= 60:
                suggestion = "æ¨è"
            elif total >= 50:
                suggestion = "å¯ä»¥å…³æ³¨"
            elif total >= 40:
                suggestion = "è§‚æœ›"
            else:
                suggestion = "ä¸æ¨è"
            
            res = StockAnalysisResult(
                stock_code=stock_code,
                stock_name=market_data.name,
                analysis_date=today,
                latest_price=market_data.latest_price,
                pe_ratio=market_data.pe_dynamic,
                pb_ratio=market_data.pb,
                volatility_30d=round(vol_30d, 2),
                volatility_60d=round(vol_60d, 2),
                dividend_yield=round(dividend_yield, 2),
                roe=round(roe, 2) if roe else 0,
                profit_growth=round(profit_growth, 2) if profit_growth else 0,
                volatility_score=volatility_score,
                dividend_score=dividend_score,
                growth_score=growth_score,
                total_score=total,
                suggestion=suggestion,
                data_source="enhanced"
            )
            
            db.merge(res)
            db.commit()
            
            return {"status": "success", "score": total, "suggestion": suggestion}
            
        except Exception as e:
            return {"status": "error", "message": str(e)}
        finally:
            if is_internal:
                db.close()

    async def analyze_all_watched_stocks(self):
        """åˆ†ææ‰€æœ‰å…³æ³¨è‚¡ç¥¨"""
        db = self.get_db()
        try:
            watched = db.query(UserStockWatch.stock_code).distinct().all()
            
            print(f"\nğŸ“Š å¼€å§‹åˆ†æ {len(watched)} åªå…³æ³¨è‚¡ç¥¨...")
            
            success = 0
            failed = 0
            
            for i, row in enumerate(watched, 1):
                code = row[0]
                print(f"[{i}/{len(watched)}] åˆ†æ {code}...")
                
                # å…ˆç¡®ä¿æœ‰å†å²æ•°æ®
                hist_result = await self.fetch_historical_data(code)
                if hist_result.get("status") == "success":
                    print(f"   âœ“ å†å²æ•°æ®: {hist_result.get('count', 0)} æ¡")
                
                # åˆ†æ
                result = await self.analyze_stock(code, db)
                
                if result["status"] == "success":
                    print(f"   âœ“ è¯„åˆ†: {result.get('score', 0)} - {result.get('suggestion', '')}")
                    success += 1
                else:
                    print(f"   âœ— {result.get('message', '')}")
                    failed += 1
                    
                await asyncio.sleep(0.5)
                
            print(f"\nâœ… åˆ†æå®Œæˆ! æˆåŠŸ: {success}, å¤±è´¥: {failed}\n")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
        finally:
            db.close()
    
#    async def send_daily_reports(self):
#        db = self.get_db()
#        """å‘é€æ¯æ—¥æŠ¥å‘Šåˆ°æ‰€æœ‰ç”¨æˆ·"""
#        email_service = EmailService()
#        
#        # è·å–æ‰€æœ‰å¯ç”¨é‚®ä»¶çš„ç”¨æˆ·
#        users = db.query(User).filter(
#            User.enable_daily_report == True,
#            User.email_verified == True
#        ).all()
#        
#        for user in users:
#            # è·å–ç”¨æˆ·çš„åˆ†æç»“æœ
#            results = get_user_analysis_results(user.user_id)
#            
#            # ç”ŸæˆCSV
#            csv_path = ReportGenerator.generate_user_csv(
#                user.user_id, 
#                results
#            )
#            
#            # è®¡ç®—æ‘˜è¦
#            summary = ReportGenerator.calculate_summary(results)
#            
#            # å‘é€é‚®ä»¶
#            success, error = email_service.send_daily_report(
#                user.email,
#                user.nickname,
#                csv_path,
#                summary
#            )
#            
#            # è®°å½•å‘é€çŠ¶æ€
#            notification = EmailNotification(
#                user_id=user.user_id,
#                recipient_email=user.email,
#                email_type='daily_report',
#                status='sent' if success else 'failed',
#                error_message=error if not success else None
#            )
#            db.add(notification)
#        
#        db.commit()

# --- FastAPI åº”ç”¨ ---
stock_service = StockDataService()
scheduler = AsyncIOScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨å¢å¼ºç‰ˆä»·å€¼åˆ†æç³»ç»Ÿ...\n")

    scheduler.add_job(
        stock_service.fetch_daily_market_data,
        CronTrigger(hour=15, minute=30),
        id="daily_market_fetch",
        replace_existing=True
    )

    scheduler.add_job(
        stock_service.analyze_all_watched_stocks,
        CronTrigger(hour=16, minute=0),
        id="daily_analysis",
        replace_existing=True
    )

    # æ¯æ—¥16:05 - å‘é€é‚®ä»¶æŠ¥å‘Š (æ–°å¢)
    # scheduler.add_job(
    #     email_service.send_all_daily_reports,
    #     CronTrigger(hour=18, minute=5),
    #     id="daily_email_reports"
    # )

    # æ¯æ—¥20:00 - æ›´æ–°æŒä»“ç›ˆäº (æ–°å¢)
    # scheduler.add_job(
    #     holdings_service.update_all_holdings_profit,
    #     CronTrigger(hour=20, minute=0),
    #     id="update_holdings"
    # )

    scheduler.start()

    print("âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨:")
    print("   - æ¯æ—¥15:30è·å–å…¨å¸‚åœºæ•°æ®")
    print("   - æ¯æ—¥16:00åˆ†ææ‰€æœ‰å…³æ³¨è‚¡ç¥¨\n")

    yield

    print("\nğŸ›‘ æ­£åœ¨å…³é—­ç³»ç»Ÿ...")
    if scheduler and scheduler.running:
        scheduler.shutdown()
    print("âœ… ç³»ç»Ÿå·²åœæ­¢\n")

app = FastAPI(
    title="ä»·å€¼åˆ†æç³»ç»Ÿ",
    version="2.3",
    lifespan=lifespan
)

# --- APIæ¥å£ (ä¿æŒä¸å˜,æ­¤å¤„çœç•¥é‡å¤ä»£ç ) ---
@app.post("/users/create")
def create_user(user_id: str, username: str):
    db = SessionLocal()
    try:
        existing = db.query(User).filter(User.user_id == user_id).first()
        if existing:
            db.close()
            raise HTTPException(status_code=400, detail="ç”¨æˆ·IDå·²å­˜åœ¨")
        user = User(user_id=user_id, username=username)
        db.add(user)
        db.commit()
        db.close()
        return {"status": "success", "message": f"ç”¨æˆ· {username} åˆ›å»ºæˆåŠŸ"}
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/watch/add")
def add_watch_stock(user_id: str, stock_codes: str):
    db = SessionLocal()
    try:
        user = db.query(User).filter(User.user_id == user_id).first()
        if not user:
            db.close()
            raise HTTPException(status_code=404, detail="ç”¨æˆ·ä¸å­˜åœ¨")
        codes = re.findall(r'\d{6}', stock_codes)
        added = 0
        for code in set(codes):
            existing = db.query(UserStockWatch).filter(
                UserStockWatch.user_id == user_id,
                UserStockWatch.stock_code == code
            ).first()
            if not existing:
                watch = UserStockWatch(user_id=user_id, stock_code=code)
                db.add(watch)
                added += 1
        db.commit()
        db.close()
        return {"status": "success", "message": f"æˆåŠŸæ·»åŠ  {added} åªè‚¡ç¥¨åˆ°å…³æ³¨åˆ—è¡¨"}
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/watch/remove")
def remove_watch_stock(user_id: str, stock_code: str):
    db = SessionLocal()
    try:
        result = db.query(UserStockWatch).filter(
            UserStockWatch.user_id == user_id,
            UserStockWatch.stock_code == stock_code
        ).delete()
        db.commit()
        db.close()
        if result > 0:
            return {"status": "success", "message": f"å·²ç§»é™¤è‚¡ç¥¨ {stock_code}"}
        else:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥å…³æ³¨è®°å½•")
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/watch/list")
def list_watch_stocks(user_id: str):
    db = SessionLocal()
    try:
        watches = db.query(UserStockWatch).filter(UserStockWatch.user_id == user_id).all()
        db.close()
        return {
            "user_id": user_id,
            "watched_stocks": [{"code": w.stock_code, "added_at": str(w.added_at)} for w in watches],
            "count": len(watches)
        }
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/data/market/fetch")
async def fetch_market_data(force: bool = False):
    result = await stock_service.fetch_daily_market_data(force=force)
    return result

@app.post("/data/history/fetch")
async def fetch_history_data(stock_code: str, start_date: str = None, end_date: str = None):
    result = await stock_service.fetch_historical_data(stock_code, start_date, end_date)
    return result

@app.post("/data/dividend/fetch")
async def fetch_dividend_data(date_str: str = None):
    result = await stock_service.fetch_dividend_data(date_str)
    return result

@app.post("/analyze/manual")
async def manual_analyze(background_tasks: BackgroundTasks):
    background_tasks.add_task(stock_service.analyze_all_watched_stocks)
    return {"status": "success", "message": "åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨"}

@app.post("/analyze/stock")
async def analyze_single_stock(stock_code: str):
    result = await stock_service.analyze_stock(stock_code)
    return result

@app.get("/export/global")
def export_global_csv():
    db = SessionLocal()
    try:
        subquery = db.query(
            StockAnalysisResult.stock_code,
            func.max(StockAnalysisResult.analysis_date).label('max_date')
        ).group_by(StockAnalysisResult.stock_code).subquery()
        
        results = db.query(StockAnalysisResult).join(
            subquery,
            (StockAnalysisResult.stock_code == subquery.c.stock_code) &
            (StockAnalysisResult.analysis_date == subquery.c.max_date)
        ).order_by(desc(StockAnalysisResult.total_score)).all()
        
        data = []
        for r in results:
            data.append({
                "è‚¡ç¥¨ä»£ç ": r.stock_code,
                "è‚¡ç¥¨åç§°": r.stock_name,
                "åˆ†ææ—¥æœŸ": str(r.analysis_date),
                "æœ€æ–°ä»·": r.latest_price,
                "å¸‚ç›ˆç‡": r.pe_ratio,
                "å¸‚å‡€ç‡": r.pb_ratio,
                "30æ—¥æ³¢åŠ¨ç‡%": r.volatility_30d,
                "60æ—¥æ³¢åŠ¨ç‡%": r.volatility_60d,
                "è‚¡æ¯ç‡%": r.dividend_yield,
                "ROE%": r.roe,
                "åˆ©æ¶¦å¢é•¿%": r.profit_growth,
                "æ³¢åŠ¨ç‡è¯„åˆ†": r.volatility_score,
                "è‚¡æ¯ç‡è¯„åˆ†": r.dividend_score,
                "æˆé•¿æ€§è¯„åˆ†": r.growth_score,
                "ç»¼åˆè¯„åˆ†": r.total_score,
                "æŠ•èµ„å»ºè®®": r.suggestion,
                "æ•°æ®æ¥æº": r.data_source
            })
        
        out_dir = "outputs"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        
        df = pd.DataFrame(data)
        output_file = os.path.join(out_dir, "å…¨å±€è‚¡ç¥¨åˆ†æç»“æœ.csv")
        df.to_csv(output_file, index=False, encoding="utf_8_sig")
        
        db.close()
        return FileResponse(output_file, filename="å…¨å±€è‚¡ç¥¨åˆ†æç»“æœ.csv")
        
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/export/user")
def export_user_csv(user_id: str):
    db = SessionLocal()
    try:
        watched = db.query(UserStockWatch.stock_code).filter(UserStockWatch.user_id == user_id).all()
        watched_codes = [w[0] for w in watched]
        
        if not watched_codes:
            db.close()
            raise HTTPException(status_code=404, detail="ç”¨æˆ·æœªå…³æ³¨ä»»ä½•è‚¡ç¥¨")
        
        subquery = db.query(
            StockAnalysisResult.stock_code,
            func.max(StockAnalysisResult.analysis_date).label('max_date')
        ).filter(
            StockAnalysisResult.stock_code.in_(watched_codes)
        ).group_by(StockAnalysisResult.stock_code).subquery()
        
        results = db.query(StockAnalysisResult).join(
            subquery,
            (StockAnalysisResult.stock_code == subquery.c.stock_code) &
            (StockAnalysisResult.analysis_date == subquery.c.max_date)
        ).order_by(desc(StockAnalysisResult.total_score)).all()
        
        data = []
        for r in results:
            data.append({
                "è‚¡ç¥¨ä»£ç ": r.stock_code,
                "è‚¡ç¥¨åç§°": r.stock_name,
                "åˆ†ææ—¥æœŸ": str(r.analysis_date),
                "æœ€æ–°ä»·": r.latest_price,
                "å¸‚ç›ˆç‡": r.pe_ratio,
                "å¸‚å‡€ç‡": r.pb_ratio,
                "30æ—¥æ³¢åŠ¨ç‡%": r.volatility_30d,
                "60æ—¥æ³¢åŠ¨ç‡%": r.volatility_60d,
                "è‚¡æ¯ç‡%": r.dividend_yield,
                "ROE%": r.roe,
                "åˆ©æ¶¦å¢é•¿%": r.profit_growth,
                "æ³¢åŠ¨ç‡è¯„åˆ†": r.volatility_score,
                "è‚¡æ¯ç‡è¯„åˆ†": r.dividend_score,
                "æˆé•¿æ€§è¯„åˆ†": r.growth_score,
                "ç»¼åˆè¯„åˆ†": r.total_score,
                "æŠ•èµ„å»ºè®®": r.suggestion,
                "æ•°æ®æ¥æº": r.data_source
            })
        
        out_dir = "outputs"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        
        df = pd.DataFrame(data)
        output_file = os.path.join(out_dir, f"ç”¨æˆ·{user_id}_è‚¡ç¥¨åˆ†æç»“æœ.csv")
        df.to_csv(output_file, index=False, encoding="utf_8_sig")
        
        db.close()
        return FileResponse(output_file, filename=f"ç”¨æˆ·{user_id}_è‚¡ç¥¨åˆ†æç»“æœ.csv")
        
    except HTTPException:
        db.close()
        raise
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
def get_status():
    db = SessionLocal()
    try:
        user_count = db.query(User).count()
        watch_count = db.query(UserStockWatch).count()
        market_data_count = db.query(DailyMarketData).count()
        historical_data_count = db.query(HistoricalData).count()
        dividend_data_count = db.query(DividendData).count()
        analysis_count = db.query(StockAnalysisResult).count()
        
        latest_market = db.query(func.max(DailyMarketData.date)).scalar()
        latest_analysis = db.query(func.max(StockAnalysisResult.analysis_date)).scalar()
        
        db.close()
        
        return {
            "system": "ä»·å€¼åˆ†æç³»ç»Ÿ",
            "users": user_count,
            "watched_stocks": watch_count,
            "market_data_records": market_data_count,
            "historical_data_records": historical_data_count,
            "dividend_data_records": dividend_data_count,
            "analysis_records": analysis_count,
            "latest_market_date": str(latest_market) if latest_market else None,
            "latest_analysis_date": str(latest_analysis) if latest_analysis else None,
            "scheduler_running": scheduler.running
        }
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    print("\n" + "="*60)
    print("ğŸš€ ä»·å€¼åˆ†æç³»ç»Ÿ")
    print("="*60)
    print("\nâœ¨ æ–°å¢ä¼˜åŒ–:")
    print("  â€¢ å®Œæ•´å­—æ®µæ˜ å°„ (22ä¸ªå­—æ®µ)")
    print("  â€¢ å®æ—¶å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡")
    print("  â€¢ å¢å¼ºçš„æ•°æ®ä¿å­˜é€»è¾‘")
    print("  â€¢ æ”¹è¿›çš„å¼‚å¸¸å€¼å¤„ç†")
    print("  â€¢ å†å²æ•°æ®å®Œæ•´ä¿å­˜")
    print("\nğŸ“š æ ¸å¿ƒåŠŸèƒ½:")
    print("  âœ“ å¤šç”¨æˆ·æ”¯æŒ")
    print("  âœ“ ä¸‰æ•°æ®æºç‹¬ç«‹å­˜å‚¨")
    print("  âœ“ è‡ªåŠ¨å®šæ—¶ä»»åŠ¡")
    print("  âœ“ æ™ºèƒ½è¯„åˆ†ç³»ç»Ÿ")
    print("\nğŸ”— è®¿é—®:")
    print("  APIæ–‡æ¡£: http://localhost:8000/docs")
    print("  ç³»ç»ŸçŠ¶æ€: http://localhost:8000/status")
    print("="*60 + "\n")
    
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)