import os
import time
from contextlib import asynccontextmanager
import datetime
import asyncio
import re
import json
import pandas as pd
import numpy as np
import akshare as ak
from typing import Optional, List
from sqlalchemy import create_engine, Column, String, Float, DateTime, Integer, desc, func, Boolean, Date
from sqlalchemy.orm import sessionmaker, Session, declarative_base
from starlette.background import BackgroundTasks
from fastapi import FastAPI, Depends, HTTPException
from fastapi.responses import FileResponse
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import urllib3
import random
import efinance as ef

# ============================================================
# ç½‘ç»œé…ç½® - ç¦ç”¨ä»£ç†å’ŒSSLè­¦å‘Š
# ============================================================
# ============================================================
# é¡¶çº§è¡¥ä¸ï¼šå…¨å±€æ‹¦æˆª requestsï¼Œå¼ºåˆ¶ä¼ªè£…å¹¶ç¦ç”¨ä»£ç†
# ============================================================
from requests.sessions import Session

_orig_request = Session.request

def my_request(self, method, url, **kwargs):
    # 1. å¼ºåˆ¶æŠ¹é™¤ä»£ç† (è§£å†³ RemoteDisconnected çš„æ ¸å¿ƒ)
    kwargs['proxies'] = {'http': None, 'https': None}
    
    # 2. æ³¨å…¥ä¼ªè£… Headers (å¦‚æœæ¥å£æ²¡ä¼  headersï¼Œæˆ‘ä»¬å°±ç»™å®ƒä¸€ä¸ª)
    if 'headers' not in kwargs or not kwargs['headers']:
        kwargs['headers'] = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Connection': 'keep-alive'
        }
    
    # 3. å»¶é•¿è¶…æ—¶
    if 'timeout' not in kwargs:
        kwargs['timeout'] = 30
        
    return _orig_request(self, method, url, **kwargs)

# å®æ–½å…¨å±€æ‹¦æˆªï¼šä»æ­¤æ‰€æœ‰è°ƒç”¨ requests çš„åº“ (akshare, efinance) éƒ½ä¼šå¸¦ä¸Šä¼ªè£…
Session.request = my_request

# æ–¹æ³•1: ç¯å¢ƒå˜é‡ç¦ç”¨ä»£ç†
os.environ['HTTP_PROXY'] = ''
os.environ['HTTPS_PROXY'] = ''
os.environ['http_proxy'] = ''
os.environ['https_proxy'] = ''
os.environ['NO_PROXY'] = '*'
os.environ['no_proxy'] = '*'

# æ–¹æ³•2: ç¦ç”¨urllib3çš„SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# æ–¹æ³•3: ç¦ç”¨requestsçš„ä»£ç†(å¦‚æœakshareå†…éƒ¨ä½¿ç”¨requests)
import requests
requests.packages.urllib3.disable_warnings()

# ============================================================
# æ•°æ®åº“é…ç½®
# ============================================================

SQLALCHEMY_DATABASE_URL = "sqlite:///./stock_advanced_system.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# --- æ•°æ®æ¨¡å‹ ---

class User(Base):
    """ç”¨æˆ·è¡¨"""
    __tablename__ = "users"
    user_id = Column(String, primary_key=True)
    username = Column(String, unique=True)
    created_at = Column(DateTime, default=datetime.datetime.now)

class UserStockWatch(Base):
    """ç”¨æˆ·å…³æ³¨è‚¡ç¥¨åˆ—è¡¨"""
    __tablename__ = "user_stock_watch"
    id = Column(Integer, primary_key=True, autoincrement=True)
    user_id = Column(String, index=True)
    stock_code = Column(String, index=True)
    added_at = Column(DateTime, default=datetime.datetime.now)

class DailyMarketData(Base):
    """æ¥å£1: æ¯æ—¥å…¨å¸‚åœºå®æ—¶æ•°æ® - stock_zh_a_spot_em"""
    __tablename__ = "daily_market_data"
    id = Column(Integer, primary_key=True, autoincrement=True)
    date = Column(Date, index=True)
    code = Column(String, index=True)
    name = Column(String)
    latest_price = Column(Float)
    change_pct = Column(Float)
    change_amount = Column(Float)
    volume = Column(Float)
    amount = Column(Float)
    amplitude = Column(Float)
    high = Column(Float)
    low = Column(Float)
    open = Column(Float)
    close_prev = Column(Float)
    volume_ratio = Column(Float)
    turnover_rate = Column(Float)
    pe_dynamic = Column(Float)
    pb = Column(Float)
    total_market_cap = Column(Float)
    circulating_market_cap = Column(Float)
    rise_speed = Column(Float)
    change_5min = Column(Float)
    change_60day = Column(Float)
    change_ytd = Column(Float)
    updated_at = Column(DateTime, default=datetime.datetime.now)

class HistoricalData(Base):
    """æ¥å£2: å†å²è¡Œæƒ…æ•°æ® - stock_zh_a_hist (å‰å¤æƒ)"""
    __tablename__ = "historical_data"
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String, index=True)
    date = Column(Date, index=True)
    open = Column(Float)
    close = Column(Float)
    high = Column(Float)
    low = Column(Float)
    volume = Column(Integer)
    amount = Column(Float)
    amplitude = Column(Float)
    change_pct = Column(Float)
    change_amount = Column(Float)
    turnover_rate = Column(Float)
    created_at = Column(DateTime, default=datetime.datetime.now)

class DividendData(Base):
    """æ¥å£3: åˆ†çº¢æ´¾æ¯æ•°æ® - news_trade_notify_dividend_baidu"""
    __tablename__ = "dividend_data"
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String, index=True)
    stock_name = Column(String)
    ex_dividend_date = Column(Date, index=True)
    dividend = Column(String)
    bonus_share = Column(String)
    capitalization = Column(String)
    physical = Column(String)
    exchange = Column(String)
    report_period = Column(String)
    created_at = Column(DateTime, default=datetime.datetime.now)

class StockAnalysisResult(Base):
    """è‚¡ç¥¨åˆ†æç»“æœè¡¨"""
    __tablename__ = "stock_analysis_results"
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String, index=True)
    stock_name = Column(String)
    analysis_date = Column(Date, index=True)
    
    latest_price = Column(Float)
    pe_ratio = Column(Float)
    pb_ratio = Column(Float)
    
    volatility_30d = Column(Float)
    volatility_60d = Column(Float)
    
    dividend_yield = Column(Float)
    
    roe = Column(Float)
    profit_growth = Column(Float)
    
    volatility_score = Column(Integer)
    dividend_score = Column(Integer)
    growth_score = Column(Integer)
    total_score = Column(Integer)
    suggestion = Column(String)
    
    data_source = Column(String)
    
    created_at = Column(DateTime, default=datetime.datetime.now)

Base.metadata.create_all(bind=engine)

# ============================================================
# é‡è¯•è£…é¥°å™¨
# ============================================================

def retry_on_error(max_retries=3, delay=2, backoff=2):
    """
    é‡è¯•è£…é¥°å™¨
    max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    delay: åˆå§‹å»¶è¿Ÿç§’æ•°
    backoff: å»¶è¿Ÿå€æ•°
    """
    def decorator(func):
        async def wrapper(*args, **kwargs):
            current_delay = delay
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥,æŠ›å‡ºå¼‚å¸¸
                        raise e
                    
                    print(f"âš ï¸  ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {str(e)}")
                    print(f"   ç­‰å¾…{current_delay}ç§’åé‡è¯•...")
                    await asyncio.sleep(current_delay)
                    current_delay *= backoff
            
        return wrapper
    return decorator

# ============================================================
# æ•°æ®æœåŠ¡å±‚
# ============================================================

class StockDataService:
    def __init__(self):
        self.last_market_fetch = None
        # å®šä¹‰ä¸œè´¢å­—æ®µä¸æ•°æ®åº“å­—æ®µçš„æ˜ å°„
        self.em_fields_map = {
            'f12': 'code', 'f14': 'name', 'f2': 'latest_price', 'f3': 'change_pct',
            'f4': 'change_amount', 'f5': 'volume', 'f6': 'amount', 'f7': 'amplitude',
            'f15': 'high', 'f16': 'low', 'f17': 'open', 'f18': 'close_prev',
            'f8': 'turnover_rate', 'f9': 'pe_dynamic', 'f23': 'pb',
            'f20': 'total_market_cap', 'f21': 'circulating_market_cap',
            'f11': 'rise_speed', 'f22': 'change_5min'
        }

    def get_db(self) -> Session:
        db = SessionLocal()
        try: return db
        finally: pass

    def _safe_float(self, val):
        """å®‰å…¨è½¬æ¢ float è¾…åŠ©å‡½æ•°"""
        try:
            if pd.isna(val) or val == '-' or val is None: return None
            return float(val)
        except:
            return None

    async def fetch_em_data_via_web_api(self, page_size: int = 100) -> pd.DataFrame:
        """ã€æ–¹æ¡ˆä¸€ã€‘åŸç”Ÿç½‘é¡µ API åˆ†é¡µè¯·æ±‚æ–¹å¼"""
        all_dfs = []
        current_page = 1
        total_pages = 999
        
        url = "http://82.push2.eastmoney.com/api/qt/clist/get"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Referer": "http://quote.eastmoney.com/center/gridlist.html"
        }

        print(f"\nğŸŒ å¯åŠ¨åŸç”Ÿç½‘é¡µ API æŠ“å–æ¨¡å¼ (æ¯é¡µ {page_size} æ¡)")
        
        while current_page <= total_pages:
            params = {
                "pn": current_page, "pz": page_size,
                "po": "1", "np": "1", "ut": "bd1d9ddb04089700cf9c27f6f7426281",
                "fltt": "2", "invt": "2", "fid": "f3",
                "fs": "m:0 t:6,m:0 t:80,m:1 t:2,m:1 t:23,m:0 t:81 s:2048",
                "fields": ",".join(self.em_fields_map.keys()),
            }

            try:
                print(f"   â¤ æŠ“å–ç¬¬ {current_page}/{total_pages if total_pages != 999 else '?'} é¡µ...")
                response = await asyncio.to_thread(
                    requests.get, 
                    url, 
                    params=params, 
                    headers=headers, 
                    timeout=20
                )
                res_json = response.json()
                
                if not res_json or 'data' not in res_json or res_json['data'] is None:
                    print(f"   âš ï¸ ç¬¬ {current_page} é¡µæœªèƒ½è·å–æœ‰æ•ˆæ•°æ®")
                    break

                # é¦–é¡µè¯·æ±‚æ—¶æ›´æ–°æ€»é¡µæ•°
                if current_page == 1:
                    total_records = res_json['data']['total']
                    total_pages = (total_records + page_size - 1) // page_size
                    print(f"   ğŸ“Š å…¨å¸‚åœºå…±è®¡ {total_records} åªè‚¡ç¥¨ï¼Œé¢„è®¡çˆ¬å– {total_pages} é¡µ")

                batch_df = pd.DataFrame(res_json['data']['diff'])
                all_dfs.append(batch_df)
                
                if current_page >= total_pages: break

                # æ ¸å¿ƒè¦æ±‚ï¼šéšæœºé—´éš” 10-50 ç§’
                wait_time = random.uniform(10, 50)
                print(f"   ğŸ’¤ éšæœºç­‰å¾… {wait_time:.1f} ç§’ä»¥è§„é¿é£æ§...")
                await asyncio.sleep(wait_time)
                
                current_page += 1

            except Exception as e:
                print(f"   âŒ ç¬¬ {current_page} é¡µå‡ºé”™: {str(e)[:50]}ã€‚60ç§’åé‡è¯•...")
                await asyncio.sleep(60)
                continue

        if not all_dfs: return pd.DataFrame()
        
        final_df = pd.concat(all_dfs, ignore_index=True)
        # ç»Ÿä¸€å­—æ®µå
        final_df = final_df.rename(columns={k: v for k, v in self.em_fields_map.items()})
        return final_df

    async def fetch_via_efinance(self) -> pd.DataFrame:
        """ã€æ–¹æ¡ˆäºŒ/ä¿åº•æ–¹æ¡ˆã€‘ä½¿ç”¨ efinance åº“è·å–æ•°æ®"""
        print("\nğŸ”„ åˆ‡æ¢è‡³ efinance ä¿åº•æ¨¡å¼è·å–å…¨é‡æ•°æ®...")
        try:
            # efinance çš„è·å–é€šå¸¸æ¯”è¾ƒå¿«ï¼Œå› ä¸ºå®ƒå†…éƒ¨åšäº†å¤šçº¿ç¨‹/å¹¶å‘ä¼˜åŒ–
            df = ef.stock.get_realtime_quotes()
            if df.empty: return pd.DataFrame()
            
            # å°† efinance çš„ä¸­æ–‡åˆ—åæ˜ å°„å›ç³»ç»Ÿç»Ÿä¸€çš„è‹±æ–‡å
            ef_map = {
                'è‚¡ç¥¨ä»£ç ': 'code', 'è‚¡ç¥¨åç§°': 'name', 'æœ€æ–°ä»·': 'latest_price',
                'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount', 'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude', 'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                'ä»Šå¼€': 'open', 'æ˜¨æ”¶': 'close_prev', 'æ¢æ‰‹ç‡': 'turnover_rate',
                'åŠ¨æ€å¸‚ç›ˆç‡': 'pe_dynamic', 'å¸‚å‡€ç‡': 'pb', 'æ€»å¸‚å€¼': 'total_market_cap',
                'æµé€šå¸‚å€¼': 'circulating_market_cap', 'æ¶¨é€Ÿ': 'rise_speed'
            }
            df = df.rename(columns=ef_map)
            print(f"   âœ… efinance æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
            return df
        except Exception as e:
            print(f"   âŒ efinance æ¨¡å¼ä¹Ÿå¤±æ•ˆ: {e}")
            return pd.DataFrame()

    @retry_on_error(max_retries=2, delay=5)
    async def fetch_daily_market_data(self, force: bool = False) -> dict:
        """ä¸»å…¥å£ï¼šå…·å¤‡åˆ‡æ¢æœºåˆ¶çš„è·å–é€»è¾‘"""
        db = self.get_db()
        today = datetime.date.today()
        
        # 1. æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²æœ‰æ•°æ®
        if not force:
            existing = db.query(DailyMarketData).filter(DailyMarketData.date == today).first()
            if existing:
                db.close()
                return {"status": "skip", "message": "ä»Šæ—¥æ•°æ®å·²å­˜åœ¨"}

        print(f"\n{'='*60}\nğŸ“Š å¼€å§‹æ‰§è¡Œæ¯æ—¥å…¨å¸‚åœºæ•°æ®é‡‡é›†ç¨‹åº")
        
        # 2. å°è¯•æ–¹æ¡ˆä¸€ï¼ˆåŸç”Ÿ APIï¼‰
        try:
            df = await self.fetch_em_data_via_web_api(page_size=100)
            source = "EM_WebAPI"
        except Exception as e:
            print(f"âš ï¸ æ–¹æ¡ˆä¸€å¤±è´¥ï¼Œæ­£åœ¨å¯åŠ¨æ–¹æ¡ˆäºŒ...")
            df = pd.DataFrame()

        # 3. å°è¯•æ–¹æ¡ˆäºŒï¼ˆefinanceï¼‰
        if df.empty:
            df = await self.fetch_via_efinance()
            source = "efinance"

        if df.empty:
            db.close()
            return {"status": "error", "message": "æ‰€æœ‰æ•°æ®æºå‡ä¸å¯ç”¨"}

        # 4. æ•°æ®æ¸…ç†ä¸ä¿å­˜
        try:
            # æ¸…ç†æ—§æ•°æ®
            db.query(DailyMarketData).filter(DailyMarketData.date == today).delete()
            db.commit()

            print(f"\nğŸ’¾ æ­£åœ¨å°† {len(df)} åªè‚¡ç¥¨å­˜å…¥æ•°æ®åº“...")
            batch_data = []
            for _, row in df.iterrows():
                # ä½¿ç”¨ _safe_float å¤„ç†å„ç§å¼‚å¸¸å€¼
                m = DailyMarketData(
                    date=today,
                    code=str(row['code']),
                    name=str(row['name']),
                    latest_price=self._safe_float(row.get('latest_price')),
                    change_pct=self._safe_float(row.get('change_pct')),
                    change_amount=self._safe_float(row.get('change_amount')),
                    volume=self._safe_float(row.get('volume')),
                    amount=self._safe_float(row.get('amount')),
                    amplitude=self._safe_float(row.get('amplitude')),
                    high=self._safe_float(row.get('high')),
                    low=self._safe_float(row.get('low')),
                    open=self._safe_float(row.get('open')),
                    close_prev=self._safe_float(row.get('close_prev')),
                    turnover_rate=self._safe_float(row.get('turnover_rate')),
                    pe_dynamic=self._safe_float(row.get('pe_dynamic')),
                    pb=self._safe_float(row.get('pb')),
                    total_market_cap=self._safe_float(row.get('total_market_cap')),
                    circulating_market_cap=self._safe_float(row.get('circulating_market_cap')),
                    rise_speed=self._safe_float(row.get('rise_speed')),
                    updated_at=datetime.datetime.now()
                )
                batch_data.append(m)
                
                if len(batch_data) >= 500:
                    db.bulk_save_objects(batch_data)
                    db.commit()
                    batch_data = []

            if batch_data:
                db.bulk_save_objects(batch_data)
                db.commit()

            print(f"âœ… æ•°æ®é‡‡é›†å®Œæˆï¼æ¥æº: {source}, æ€»è®¡: {len(df)} æ¡")
            db.close()
            return {"status": "success", "source": source, "count": len(df)}

        except Exception as e:
            db.close()
            print(f"âŒ å­˜å‚¨å…¥åº“å¤±è´¥: {e}")
            raise
    
    @retry_on_error(max_retries=2, delay=2)
    async def fetch_historical_data(self, stock_code: str, start_date: str = None, 
                                    end_date: str = None, period: str = "daily") -> dict:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„å†å²æ•°æ® (æ¥å£2: stock_zh_a_hist)
        ä½¿ç”¨å‰å¤æƒæ•°æ®
        """
        db = self.get_db()
        try:
            if not end_date:
                end_date = datetime.date.today().strftime("%Y%m%d")
            if not start_date:
                start_date = (datetime.date.today() - datetime.timedelta(days=500)).strftime("%Y%m%d")
            
            print(f"ğŸ“ˆ è·å– {stock_code} å†å²æ•°æ®: {start_date} è‡³ {end_date}")
            
            df = pd.DataFrame()
            data_source = ""

            # --- æ–¹æ¡ˆ 1: ä¼˜å…ˆå°è¯• efinance (ç¨³å®šæ€§é«˜ï¼Œå¸¦ä¼ªè£…) ---
            try:
                # efinance çš„ get_quote_history ä¼šè‡ªåŠ¨å¤„ç†å¤æƒï¼Œé»˜è®¤æ˜¯å‰å¤æƒ
                df = ef.stock.get_quote_history(stock_code)
                if not df.empty:
                    # efinance è¿”å›çš„æ˜¯å…¨é‡ï¼Œæˆ‘ä»¬éœ€è¦æŒ‰æ—¥æœŸè¿‡æ»¤
                    # å°† 'æ—¥æœŸ' åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ä»¥ä¾¿å¯¹æ¯”ï¼Œæˆ–è€…ç»Ÿä¸€è½¬ä¸º datetime
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                    # è½¬æ¢ start_date å’Œ end_date ä¸º datetime å¯¹è±¡
                    s_dt = pd.to_datetime(start_date, format='%Y%m%d')
                    e_dt = pd.to_datetime(end_date, format='%Y%m%d')
                    
                    df = df[(df['æ—¥æœŸ'] >= s_dt) & (df['æ—¥æœŸ'] <= e_dt)]
                    
                    # æ˜ å°„ efinance çš„ä¸­æ–‡åˆ—ååˆ°æ•°æ®åº“å­—æ®µå
                    df = df.rename(columns={
                        'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                        'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
                        'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount', 'æ¢æ‰‹ç‡': 'turnover_rate'
                    })
                    data_source = "efinance"
            except Exception as e:
                print(f"   âš ï¸ efinance è·å–å¤±è´¥: {e}ï¼Œå°è¯•åˆ‡æ¢ AkShare...")

            # --- æ–¹æ¡ˆ 2: AkShare ä¿åº• ---
            if df.empty:
                try:
                    df = ak.stock_zh_a_hist(
                        symbol=stock_code,
                        period=period,
                        start_date=start_date,
                        end_date=end_date,
                        adjust="qfq"
                    )
                    if not df.empty:
                        # AkShare çš„åˆ—åä¹Ÿæ˜¯ä¸­æ–‡ï¼Œéœ€è¦æ˜ å°„
                        df = df.rename(columns={
                            'æ—¥æœŸ': 'æ—¥æœŸ', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                            'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
                            'æ¶¨è·Œå¹…': 'change_pct', 'æ¶¨è·Œé¢': 'change_amount', 'æ¢æ‰‹ç‡': 'turnover_rate'
                        })
                        data_source = "akshare"
                except Exception as e:
                    print(f"   âŒ AkShare ä¿åº•ä¹Ÿå¤±è´¥: {e}")

            if df.empty:
                db.close()
                return {"status": "error", "message": f"è‚¡ç¥¨ {stock_code} æ— å†å²æ•°æ®"}
            
            # --- æ•°æ®å…¥åº“é€»è¾‘ ---
            # åˆ é™¤æ—§æ•°æ®
            target_start = datetime.datetime.strptime(start_date, "%Y%m%d").date()
            target_end = datetime.datetime.strptime(end_date, "%Y%m%d").date()
            
            db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code,
                HistoricalData.date >= target_start,
                HistoricalData.date <= target_end
            ).delete()
            
            count = 0
            for _, row in df.iterrows():
                # å¤„ç†æ—¥æœŸï¼šefinance è¿”å›å¯èƒ½æ˜¯ Timestamp
                raw_date = row['æ—¥æœŸ']
                if isinstance(raw_date, pd.Timestamp):
                    final_date = raw_date.date()
                else:
                    final_date = datetime.datetime.strptime(str(raw_date), "%Y-%m-%d").date()

                hist_data = HistoricalData(
                    stock_code=stock_code,
                    date=final_date,
                    open=self._safe_float(row.get('open')),
                    close=self._safe_float(row.get('close')),
                    high=self._safe_float(row.get('high')),
                    low=self._safe_float(row.get('low')),
                    volume=int(row.get('volume', 0)) if pd.notna(row.get('volume')) else 0,
                    amount=self._safe_float(row.get('amount')),
                    amplitude=self._safe_float(row.get('amplitude')),
                    change_pct=self._safe_float(row.get('change_pct')),
                    change_amount=self._safe_float(row.get('change_amount')),
                    turnover_rate=self._safe_float(row.get('turnover_rate')),
                )
                db.add(hist_data)
                count += 1
            
            db.commit()
            db.close()
            print(f"   âœ“ æ¥æº[{data_source}] ä¿å­˜ {count} æ¡å†å²æ•°æ®")
            
            return {
                "status": "success",
                "source": data_source,
                "count": count,
                "start_date": start_date,
                "end_date": end_date
            }
            
        except Exception as e:
            if db: db.close()
            print(f"   âœ— è·å–å†å²æ•°æ®æµç¨‹å´©æºƒ: {str(e)}")
            raise
    
    async def fetch_dividend_data(self, date_str: str = None) -> dict:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„åˆ†çº¢æ´¾æ¯æ•°æ® (æ¥å£3: news_trade_notify_dividend_baidu)
        """
        db = self.get_db()
        try:
            if not date_str:
                date_str = datetime.date.today().strftime("%Y%m%d")
            
            print(f"ğŸ’° è·å– {date_str} åˆ†çº¢æ•°æ®...")
            
            # è°ƒç”¨akshareæ¥å£
            df = ak.news_trade_notify_dividend_baidu(date=date_str)
            
            if df.empty:
                db.close()
                return {"status": "success", "message": f"{date_str} æ— åˆ†çº¢æ•°æ®", "count": 0}
            
            # åˆ é™¤è¯¥æ—¥æœŸçš„æ—§æ•°æ®
            target_date = datetime.datetime.strptime(date_str, "%Y%m%d").date()
            db.query(DividendData).filter(
                DividendData.ex_dividend_date == target_date
            ).delete()
            
            # æ‰¹é‡æ’å…¥
            count = 0
            for _, row in df.iterrows():
                dividend_data = DividendData(
                    stock_code=str(row['è‚¡ç¥¨ä»£ç ']),
                    stock_name=str(row['è‚¡ç¥¨ç®€ç§°']),
                    ex_dividend_date=datetime.datetime.strptime(str(row['é™¤æƒæ—¥']), "%Y-%m-%d").date(),
                    dividend=str(row['åˆ†çº¢']),
                    bonus_share=str(row['é€è‚¡']),
                    capitalization=str(row['è½¬å¢']),
                    physical=str(row['å®ç‰©']),
                    exchange=str(row['äº¤æ˜“æ‰€']),
                    report_period=str(row['æŠ¥å‘ŠæœŸ']),
                )
                db.add(dividend_data)
                count += 1
            
            db.commit()
            db.close()
            
            print(f"   âœ“ ä¿å­˜ {count} æ¡åˆ†çº¢æ•°æ®")
            
            return {
                "status": "success",
                "message": f"æˆåŠŸè·å– {date_str} åˆ†çº¢æ•°æ®",
                "count": count,
                "date": date_str
            }
            
        except Exception as e:
            db.close()
            return {"status": "error", "message": f"è·å–åˆ†çº¢æ•°æ®å¤±è´¥: {str(e)}"}
        
    async def fetch_stock_financials(self, stock_code: str):
        """è·å–ä¸ªè‚¡å…³é”®è´¢åŠ¡æŒ‡æ ‡ (ROE, å‡€åˆ©å¢é•¿)"""
        try:
            # ä½¿ç”¨ efinance è·å–åŸºç¡€ä¿¡æ¯ (åŒ…å« ROE ç­‰)
            # æ³¨æ„ï¼šef.stock.get_base_info è¿”å›çš„æ˜¯ DataFrame
            df = await asyncio.to_thread(ef.stock.get_base_info, stock_code)
            if df.empty: return 0.0, 0.0
            
            # è¿™é‡Œçš„å­—æ®µåé€šå¸¸æ˜¯ï¼š'å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'å‡€åˆ©æ¶¦åŒæ¯”(%)'
            # ä¸åŒç‰ˆæœ¬çš„ efinance å­—æ®µåå¯èƒ½æœ‰ç»†å¾®å·®åˆ«ï¼Œå»ºè®®åŠ ä¸ª try-catch
            roe = self._safe_float(df.iloc[0].get('å‡€èµ„äº§æ”¶ç›Šç‡(%)', 0))
            growth = self._safe_float(df.iloc[0].get('å‡€åˆ©æ¶¦åŒæ¯”(%)', 0))
            return roe, growth
        except:
            print(f"      âš ï¸ è´¢åŠ¡æ•°æ®è·å–å¤±è´¥ ({stock_code}): {e}")
            return 0.0, 0.0
        
    async def analyze_stock(self, stock_code: str, db: Session = None) -> dict:
        """åˆ†æå•åªè‚¡ç¥¨"""
        should_close = False
        if db is None:
            db = self.get_db()
            should_close = True
        
        try:
            today = datetime.date.today()
            
            # 1. è·å–æœ€æ–°å¸‚åœºæ•°æ®
            market_data = db.query(DailyMarketData).filter(
                DailyMarketData.code == stock_code,
                DailyMarketData.date == today
            ).first()
            
            if not market_data:
                market_data = db.query(DailyMarketData).filter(
                    DailyMarketData.code == stock_code
                ).order_by(desc(DailyMarketData.date)).first()
            
            if not market_data:
                if should_close:
                    db.close()
                return {"status": "error", "message": f"è‚¡ç¥¨ {stock_code} æ— å¸‚åœºæ•°æ®"}
            
            latest_price = market_data.latest_price
            pe_ratio = market_data.pe_dynamic
            pb_ratio = market_data.pb
            stock_name = market_data.name
            data_source = "market"
            
            # 2. è®¡ç®—æ³¢åŠ¨ç‡
            volatility_30d = 0
            volatility_60d = 0
            
            hist_data = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).order_by(desc(HistoricalData.date)).limit(60).all()
            
            if hist_data and len(hist_data) >= 30:
                closes = [h.close for h in reversed(hist_data) if h.close]
                
                if len(closes) >= 30:
                    series_30 = pd.Series(closes[-30:])
                    log_ret_30 = np.log(series_30 / series_30.shift(1)).dropna()
                    volatility_30d = log_ret_30.std() * np.sqrt(252) * 100
                    
                    if len(closes) >= 60:
                        series_60 = pd.Series(closes[-60:])
                        log_ret_60 = np.log(series_60 / series_60.shift(1)).dropna()
                        volatility_60d = log_ret_60.std() * np.sqrt(252) * 100
                    
                    data_source = "mixed"
            
            # å¦‚æœå†å²æ•°æ®ä¸è¶³,å°è¯•è·å–
            if volatility_30d == 0:
                print(f"   {stock_code} å†å²æ•°æ®ä¸è¶³ï¼Œå°è¯•è·å–...")
                await self.fetch_historical_data(stock_code)
                
                hist_data = db.query(HistoricalData).filter(
                    HistoricalData.stock_code == stock_code
                ).order_by(desc(HistoricalData.date)).limit(60).all()
                
                if hist_data and len(hist_data) >= 30:
                    closes = [h.close for h in reversed(hist_data) if h.close]
                    if len(closes) >= 30:
                        series_30 = pd.Series(closes[-30:])
                        log_ret_30 = np.log(series_30 / series_30.shift(1)).dropna()
                        volatility_30d = log_ret_30.std() * np.sqrt(252) * 100
                        data_source = "mixed"
            
            # 3. è®¡ç®—è‚¡æ¯ç‡
            dividend_yield = 0
            one_year_ago = today - datetime.timedelta(days=365)
            dividends = db.query(DividendData).filter(
                DividendData.stock_code == stock_code,
                DividendData.ex_dividend_date >= one_year_ago
            ).all()
            
            if dividends and latest_price:
                total_dividend = 0
                for div in dividends:
                    div_str = str(div.dividend)
                    match = re.search(r'(\d+\.?\d*)', div_str)
                    if match:
                        total_dividend += float(match.group(1))
                
                if total_dividend > 0:
                    dividend_yield = (total_dividend / latest_price) * 100
                    data_source = "mixed"
            
            # 4. ROEå’Œæˆé•¿æ€§
            print(f"   æ­£åœ¨è·å– {stock_code} è´¢åŠ¡æ•°æ®...")
            roe, profit_growth = await self.fetch_stock_financials(stock_code)
            
            # --- 5. ç»¼åˆè¯„åˆ†ç³»ç»Ÿ ---
            
            # (A) æ³¢åŠ¨ç‡è¯„åˆ† (æœ€é«˜ 40åˆ†) - è¶Šä½åˆ†è¶Šé«˜ï¼Œä»£è¡¨ç¨³å¥
            volatility_score = 0
            if volatility_30d > 0:
                if volatility_30d < 20: volatility_score = 40
                elif volatility_30d < 30: volatility_score = 30
                elif volatility_30d < 40: volatility_score = 20
                elif volatility_30d < 50: volatility_score = 10
            
            # (B) è‚¡æ¯ç‡è¯„åˆ† (æœ€é«˜ 30åˆ†) - ç°é‡‘çº¢åˆ©èƒ½åŠ›
            dividend_score = 0
            if dividend_yield >= 5: dividend_score = 30
            elif dividend_yield >= 4: dividend_score = 25
            elif dividend_yield >= 3: dividend_score = 20
            elif dividend_yield >= 2: dividend_score = 15
            elif dividend_yield >= 1: dividend_score = 10
            
            # (C) æˆé•¿æ€§è¯„åˆ† (æœ€é«˜ 30åˆ†) - ROE(20åˆ†) + åˆ©æ¶¦å¢é•¿(10åˆ†)
            growth_score = 0
            
            # ROE å­é¡¹ (20åˆ†)
            if roe > 15: growth_score += 20
            elif roe > 10: growth_score += 15
            elif roe > 5: growth_score += 10
            elif roe > 0: growth_score += 5
            
            # åˆ©æ¶¦å¢é•¿å­é¡¹ (10åˆ†)
            if profit_growth > 20: growth_score += 10
            elif profit_growth > 10: growth_score += 7
            elif profit_growth > 0: growth_score += 4
            
            # --- æ€»åˆ†è®¡ç®— ---
            total_score = volatility_score + dividend_score + growth_score
            
            # --- æŠ•èµ„å»ºè®®é€»è¾‘ ---
            if total_score >= 80:
                suggestion = "ğŸŒŸ æé«˜ä»·å€¼ (è´¢åŠ¡å¼ºå¥+é«˜åˆ†çº¢+ä½æ³¢åŠ¨)"
            elif total_score >= 70:
                suggestion = "å¼ºçƒˆæ¨è"
            elif total_score >= 60:
                suggestion = "æ¨è"
            elif total_score >= 50:
                suggestion = "å¯ä»¥å…³æ³¨"
            elif total_score >= 40:
                suggestion = "è§‚æœ›"
            else:
                suggestion = "ä¸æ¨è (é£é™©è¾ƒé«˜æˆ–ä»·å€¼ä¸è¶³)"
            
            # 6. ä¿å­˜åˆ†æç»“æœ
            analysis_result = StockAnalysisResult(
                stock_code=stock_code,
                stock_name=stock_name,
                analysis_date=today,
                latest_price=latest_price,
                pe_ratio=pe_ratio,
                pb_ratio=pb_ratio,
                volatility_30d=round(volatility_30d, 2),
                volatility_60d=round(volatility_60d, 2),
                dividend_yield=round(dividend_yield, 2),
                roe=roe,
                profit_growth=profit_growth,
                volatility_score=volatility_score,
                dividend_score=dividend_score,
                growth_score=growth_score,
                total_score=total_score,
                suggestion=suggestion,
                data_source=data_source
            )
            
            db.add(analysis_result)
            db.commit()
            
            if should_close:
                db.close()
            
            return {
                "status": "success",
                "stock_code": stock_code,
                "stock_name": stock_name,
                "total_score": total_score,
                "suggestion": suggestion
            }
            
        except Exception as e:
            if should_close:
                db.close()
            return {"status": "error", "message": f"åˆ†æ {stock_code} å¤±è´¥: {str(e)}"}
    
    async def analyze_all_watched_stocks(self) -> dict:
        """åˆ†ææ‰€æœ‰ç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨"""
        db = self.get_db()
        try:
            watched_stocks = db.query(UserStockWatch.stock_code).distinct().all()
            watched_codes = [s[0] for s in watched_stocks]
            
            if not watched_codes:
                db.close()
                return {"status": "success", "message": "æ²¡æœ‰ç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨", "count": 0}
            
            print(f"\n{'='*60}")
            print(f"ğŸ“Š å¼€å§‹åˆ†æ {len(watched_codes)} åªè¢«å…³æ³¨çš„è‚¡ç¥¨")
            print(f"{'='*60}\n")
            
            success_count = 0
            error_count = 0
            
            for i, code in enumerate(watched_codes, 1):
                print(f"[{i}/{len(watched_codes)}] åˆ†æ {code}...")
                result = await self.analyze_stock(code, db)
                if result["status"] == "success":
                    success_count += 1
                    print(f"   âœ“ {result.get('stock_name', code)} - è¯„åˆ†:{result.get('total_score', 0)} - {result.get('suggestion', '')}")
                else:
                    error_count += 1
                    print(f"   âœ— {result.get('message', '')}")
                
                await asyncio.sleep(0.3)
            
            print(f"\n{'='*60}")
            print(f"âœ… åˆ†æå®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {error_count}")
            print(f"{'='*60}\n")
            
            db.close()
            
            return {
                "status": "success",
                "message": f"åˆ†æå®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {error_count}",
                "success_count": success_count,
                "error_count": error_count,
                "total": len(watched_codes)
            }
            
        except Exception as e:
            db.close()
            return {"status": "error", "message": f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}"}



stock_service = StockDataService()

scheduler = AsyncIOScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""

    # ================= å¯åŠ¨é˜¶æ®µ =================
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨ä»·å€¼åˆ†æç³»ç»Ÿ...\n")

    scheduler.add_job(
        stock_service.fetch_daily_market_data,
        CronTrigger(hour=15, minute=30),
        id="daily_market_fetch",
        replace_existing=True
    )

    scheduler.add_job(
        stock_service.analyze_all_watched_stocks,
        CronTrigger(hour=16, minute=0),
        id="daily_analysis",
        replace_existing=True
    )

    scheduler.start()

    print("âœ… å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨:")
    print("   - æ¯æ—¥15:30è·å–å…¨å¸‚åœºæ•°æ®")
    print("   - æ¯æ—¥16:00åˆ†ææ‰€æœ‰å…³æ³¨è‚¡ç¥¨\n")

    yield  # ğŸ‘ˆ å…³é”®ï¼šç”Ÿå‘½å‘¨æœŸåˆ†ç•Œçº¿

    # ================= å…³é—­é˜¶æ®µ =================
    print("\nğŸ›‘ æ­£åœ¨å…³é—­ç³»ç»Ÿ...")

    if scheduler and scheduler.running:
        scheduler.shutdown()

    print("âœ… å®šæ—¶ä»»åŠ¡å·²å®‰å…¨åœæ­¢\n")

# --- FastAPIåº”ç”¨ ---
app = FastAPI(
    title="ä»·å€¼åˆ†æç³»ç»Ÿ v2.1",
    version="2.1",
    lifespan=lifespan
)

# --- APIæ¥å£ ---

@app.post("/users/create")
def create_user(user_id: str, username: str):
    """åˆ›å»ºç”¨æˆ·"""
    db = SessionLocal()
    try:
        existing = db.query(User).filter(User.user_id == user_id).first()
        if existing:
            db.close()
            raise HTTPException(status_code=400, detail="ç”¨æˆ·IDå·²å­˜åœ¨")
        
        user = User(user_id=user_id, username=username)
        db.add(user)
        db.commit()
        db.close()
        
        return {"status": "success", "message": f"ç”¨æˆ· {username} åˆ›å»ºæˆåŠŸ"}
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/watch/add")
def add_watch_stock(user_id: str, stock_codes: str):
    """æ·»åŠ è‚¡ç¥¨åˆ°ç”¨æˆ·å…³æ³¨åˆ—è¡¨"""
    db = SessionLocal()
    try:
        user = db.query(User).filter(User.user_id == user_id).first()
        if not user:
            db.close()
            raise HTTPException(status_code=404, detail="ç”¨æˆ·ä¸å­˜åœ¨")
        
        codes = re.findall(r'\d{6}', stock_codes)
        added = 0
        
        for code in set(codes):
            existing = db.query(UserStockWatch).filter(
                UserStockWatch.user_id == user_id,
                UserStockWatch.stock_code == code
            ).first()
            
            if not existing:
                watch = UserStockWatch(user_id=user_id, stock_code=code)
                db.add(watch)
                added += 1
        
        db.commit()
        db.close()
        
        return {"status": "success", "message": f"æˆåŠŸæ·»åŠ  {added} åªè‚¡ç¥¨åˆ°å…³æ³¨åˆ—è¡¨"}
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/watch/remove")
def remove_watch_stock(user_id: str, stock_code: str):
    """ç§»é™¤è‚¡ç¥¨ä»ç”¨æˆ·å…³æ³¨åˆ—è¡¨"""
    db = SessionLocal()
    try:
        result = db.query(UserStockWatch).filter(
            UserStockWatch.user_id == user_id,
            UserStockWatch.stock_code == stock_code
        ).delete()
        
        db.commit()
        db.close()
        
        if result > 0:
            return {"status": "success", "message": f"å·²ç§»é™¤è‚¡ç¥¨ {stock_code}"}
        else:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥å…³æ³¨è®°å½•")
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/watch/list")
def list_watch_stocks(user_id: str):
    """æŸ¥çœ‹ç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨åˆ—è¡¨"""
    db = SessionLocal()
    try:
        watches = db.query(UserStockWatch).filter(
            UserStockWatch.user_id == user_id
        ).all()
        
        db.close()
        
        return {
            "user_id": user_id,
            "watched_stocks": [{"code": w.stock_code, "added_at": str(w.added_at)} for w in watches],
            "count": len(watches)
        }
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/data/market/fetch")
async def fetch_market_data(force: bool = False):
    """æ‰‹åŠ¨è·å–å…¨å¸‚åœºæ•°æ®"""
    result = await stock_service.fetch_daily_market_data(force=force)
    return result

@app.post("/data/history/fetch")
async def fetch_history_data(stock_code: str, start_date: str = None, end_date: str = None):
    """æ‰‹åŠ¨è·å–æŒ‡å®šè‚¡ç¥¨çš„å†å²æ•°æ®"""
    result = await stock_service.fetch_historical_data(stock_code, start_date, end_date)
    return result

@app.post("/data/dividend/fetch")
async def fetch_dividend_data(date_str: str = None):
    """æ‰‹åŠ¨è·å–åˆ†çº¢æ•°æ®"""
    result = await stock_service.fetch_dividend_data(date_str)
    return result

@app.post("/analyze/manual")
async def manual_analyze(background_tasks: BackgroundTasks):
    """æ‰‹åŠ¨è§¦å‘åˆ†ææ‰€æœ‰å…³æ³¨è‚¡ç¥¨"""
    background_tasks.add_task(stock_service.analyze_all_watched_stocks)
    return {"status": "success", "message": "åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨"}

@app.post("/analyze/stock")
async def analyze_single_stock(stock_code: str):
    """åˆ†æå•åªè‚¡ç¥¨"""
    result = await stock_service.analyze_stock(stock_code)
    return result

@app.get("/export/global")
def export_global_csv():
    """å¯¼å‡ºå…¨å±€åˆ†æç»“æœåˆ°CSV"""
    db = SessionLocal()
    try:
        subquery = db.query(
            StockAnalysisResult.stock_code,
            func.max(StockAnalysisResult.analysis_date).label('max_date')
        ).group_by(StockAnalysisResult.stock_code).subquery()
        
        results = db.query(StockAnalysisResult).join(
            subquery,
            (StockAnalysisResult.stock_code == subquery.c.stock_code) &
            (StockAnalysisResult.analysis_date == subquery.c.max_date)
        ).order_by(desc(StockAnalysisResult.total_score)).all()
        
        data = []
        for r in results:
            data.append({
                "è‚¡ç¥¨ä»£ç ": r.stock_code,
                "è‚¡ç¥¨åç§°": r.stock_name,
                "åˆ†ææ—¥æœŸ": str(r.analysis_date),
                "æœ€æ–°ä»·": r.latest_price,
                "å¸‚ç›ˆç‡": r.pe_ratio,
                "å¸‚å‡€ç‡": r.pb_ratio,
                "30æ—¥æ³¢åŠ¨ç‡%": r.volatility_30d,
                "60æ—¥æ³¢åŠ¨ç‡%": r.volatility_60d,
                "è‚¡æ¯ç‡%": r.dividend_yield,
                "ROE%": r.roe,
                "åˆ©æ¶¦å¢é•¿%": r.profit_growth,
                "æ³¢åŠ¨ç‡è¯„åˆ†": r.volatility_score,
                "è‚¡æ¯ç‡è¯„åˆ†": r.dividend_score,
                "æˆé•¿æ€§è¯„åˆ†": r.growth_score,
                "ç»¼åˆè¯„åˆ†": r.total_score,
                "æŠ•èµ„å»ºè®®": r.suggestion,
                "æ•°æ®æ¥æº": r.data_source
            })
        
        df = pd.DataFrame(data)
        out_dir = "outputs"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
            
        df = pd.DataFrame(data)
        output_file = os.path.join(out_dir, "å…¨å±€è‚¡ç¥¨åˆ†æç»“æœ.csv")
        df.to_csv(output_file, index=False, encoding="utf_8_sig")
        
        db.close()
        return FileResponse(output_file, filename="å…¨å±€è‚¡ç¥¨åˆ†æç»“æœ.csv")
        
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/export/user")
def export_user_csv(user_id: str):
    """å¯¼å‡ºç”¨æˆ·å…³æ³¨è‚¡ç¥¨çš„åˆ†æç»“æœåˆ°CSV"""
    db = SessionLocal()
    try:
        watched = db.query(UserStockWatch.stock_code).filter(
            UserStockWatch.user_id == user_id
        ).all()
        
        watched_codes = [w[0] for w in watched]
        
        if not watched_codes:
            db.close()
            raise HTTPException(status_code=404, detail="ç”¨æˆ·æœªå…³æ³¨ä»»ä½•è‚¡ç¥¨")
        
        subquery = db.query(
            StockAnalysisResult.stock_code,
            func.max(StockAnalysisResult.analysis_date).label('max_date')
        ).filter(
            StockAnalysisResult.stock_code.in_(watched_codes)
        ).group_by(StockAnalysisResult.stock_code).subquery()
        
        results = db.query(StockAnalysisResult).join(
            subquery,
            (StockAnalysisResult.stock_code == subquery.c.stock_code) &
            (StockAnalysisResult.analysis_date == subquery.c.max_date)
        ).order_by(desc(StockAnalysisResult.total_score)).all()
        
        data = []
        for r in results:
            data.append({
                "è‚¡ç¥¨ä»£ç ": r.stock_code,
                "è‚¡ç¥¨åç§°": r.stock_name,
                "åˆ†ææ—¥æœŸ": str(r.analysis_date),
                "æœ€æ–°ä»·": r.latest_price,
                "å¸‚ç›ˆç‡": r.pe_ratio,
                "å¸‚å‡€ç‡": r.pb_ratio,
                "30æ—¥æ³¢åŠ¨ç‡%": r.volatility_30d,
                "60æ—¥æ³¢åŠ¨ç‡%": r.volatility_60d,
                "è‚¡æ¯ç‡%": r.dividend_yield,
                "ROE%": r.roe,
                "åˆ©æ¶¦å¢é•¿%": r.profit_growth,
                "æ³¢åŠ¨ç‡è¯„åˆ†": r.volatility_score,
                "è‚¡æ¯ç‡è¯„åˆ†": r.dividend_score,
                "æˆé•¿æ€§è¯„åˆ†": r.growth_score,
                "ç»¼åˆè¯„åˆ†": r.total_score,
                "æŠ•èµ„å»ºè®®": r.suggestion,
                "æ•°æ®æ¥æº": r.data_source
            })
        
        df = pd.DataFrame(data)
        out_dir = "outputs"
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
            
        df = pd.DataFrame(data)
        output_file = os.path.join(out_dir, "ç”¨æˆ·{user_id}_è‚¡ç¥¨åˆ†æç»“æœ.csv")
        df.to_csv(output_file, index=False, encoding="utf_8_sig")
        
        db.close()
        return FileResponse(output_file, filename="ç”¨æˆ·{user_id}_è‚¡ç¥¨åˆ†æç»“æœ.csv")
        
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    db = SessionLocal()
    try:
        user_count = db.query(User).count()
        watch_count = db.query(UserStockWatch).count()
        market_data_count = db.query(DailyMarketData).count()
        historical_data_count = db.query(HistoricalData).count()
        dividend_data_count = db.query(DividendData).count()
        analysis_count = db.query(StockAnalysisResult).count()
        
        latest_market = db.query(func.max(DailyMarketData.date)).scalar()
        latest_analysis = db.query(func.max(StockAnalysisResult.analysis_date)).scalar()
        
        db.close()
        
        return {
            "system": "è‚¡ç¥¨ä»·å€¼åˆ†æç³»ç»Ÿ v2.1 (ç½‘ç»œä¼˜åŒ–ç‰ˆ)",
            "users": user_count,
            "watched_stocks": watch_count,
            "market_data_records": market_data_count,
            "historical_data_records": historical_data_count,
            "dividend_data_records": dividend_data_count,
            "analysis_records": analysis_count,
            "latest_market_date": str(latest_market) if latest_market else None,
            "latest_analysis_date": str(latest_analysis) if latest_analysis else None,
            "scheduler_running": scheduler.running
        }
    except Exception as e:
        db.close()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    print("\n" + "="*60)
    print("ğŸš€ è‚¡ç¥¨ä»·å€¼åˆ†æç³»ç»Ÿ v2.1 - ç½‘ç»œä¼˜åŒ–ç‰ˆ")
    print("="*60)
    print("\nâœ¨ æ–°å¢åŠŸèƒ½:")
    print("  â€¢ æ™ºèƒ½é‡è¯•æœºåˆ¶ (æœ€å¤š3æ¬¡é‡è¯•)")
    print("  â€¢ å½»åº•ç¦ç”¨ä»£ç†")
    print("  â€¢ æ‰¹é‡ä¿å­˜ä¼˜åŒ–")
    print("  â€¢ è¯¦ç»†è¿›åº¦æ˜¾ç¤º")
    print("\nğŸ“š æ ¸å¿ƒåŠŸèƒ½:")
    print("  âœ“ å¤šç”¨æˆ·æ”¯æŒ")
    print("  âœ“ ä¸‰æ•°æ®æºç‹¬ç«‹å­˜å‚¨")
    print("  âœ“ è‡ªåŠ¨å®šæ—¶ä»»åŠ¡ (15:30 + 16:00)")
    print("  âœ“ æ™ºèƒ½è¯„åˆ†ç³»ç»Ÿ")
    print("\nğŸ”— è®¿é—®:")
    print("  APIæ–‡æ¡£: http://localhost:8000/docs")
    print("  ç³»ç»ŸçŠ¶æ€: http://localhost:8000/status")
    print("="*60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)