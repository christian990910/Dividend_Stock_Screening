import os
import re
import time
import json
import random
import asyncio
import datetime
import pandas as pd
import numpy as np
import requests
import efinance as ef
import akshare as ak
from sqlalchemy.orm import Session
from sqlalchemy import desc, func

from core.database import SessionLocal
from core.config import settings  # ç¡®ä¿è¿™è¡Œå­˜åœ¨
from models.stock import DailyMarketData, HistoricalData, DividendData, StockAnalysisResult, UserStockWatch
from models.holdings import UserStockHolding  # æ·»åŠ è¿™è¡Œå¯¼å…¥
from crud.stock import save_market_data_batch, save_analysis_result

class StockDataService:
    def __init__(self):
        self.settings = settings
        self.debug_mode = os.getenv('DEBUG_MODE', 'false').lower() == 'true'
        
        # æ·»åŠ ç¼“å­˜å±‚
        self.financial_cache = {}  # è´¢åŠ¡æ•°æ®ç¼“å­˜
        self.cache_expiry = {}     # ç¼“å­˜è¿‡æœŸæ—¶é—´
        self.CACHE_TTL = 3600      # ç¼“å­˜æœ‰æ•ˆæœŸ1å°æ—¶

        self.em_fields_map = {
        'f12': 'code',          # è‚¡ç¥¨ä»£ç 
        'f14': 'name',          # è‚¡ç¥¨åç§°
        'f2': 'latest_price',   # æœ€æ–°ä»·
        'f3': 'change_pct',     # æ¶¨è·Œå¹…
        'f9': 'pe_dynamic',     # åŠ¨æ€å¸‚ç›ˆç‡
        'f23': 'pb',            # å¸‚å‡€ç‡
        'f5': 'volume',         # æˆäº¤é‡
        'f6': 'amount',         # æˆäº¤é¢
        # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šå­—æ®µæ˜ å°„
    }

        # ä¼˜åŒ–è¯·æ±‚ä¼šè¯é…ç½®
        self.session = requests.Session()
        self.session.trust_env = False
        self.session.proxies = {"http": None, "https": None}
        
        # å¢å¼ºè¿æ¥æ± é…ç½®
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,  # æ€»é‡è¯•æ¬¡æ•°
            backoff_factor=1,  # é€€é¿å› å­
            status_forcelist=[429, 500, 502, 503, 504],  # éœ€è¦é‡è¯•çš„çŠ¶æ€ç 
            allowed_methods=["HEAD", "GET", "OPTIONS"]  # å…è®¸é‡è¯•çš„æ–¹æ³•
        )
        
        adapter = HTTPAdapter(
            pool_connections=10,  # è¿æ¥æ± å¤§å°
            pool_maxsize=20,      # æœ€å¤§è¿æ¥æ•°
            max_retries=retry_strategy
        )
        
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0"
        }
        self.session.headers.update(self.headers)
        
        # ç›®æ ‡å‚æ•° (ä¸œæ–¹è´¢å¯Œ)
        self.target_ut = "bd1d9ddb04089700cf9c27f6f7426281"
        # âœ… å®Œæ•´ Cookieï¼Œå¯¹é½æµè§ˆå™¨å®é™…è¯·æ±‚ï¼ˆç¼ºå°‘è¿™äº›ä¸œè´¢ä¼šæ–­å¼€è¿æ¥ï¼‰
        # æ³¨æ„ï¼šqgqp_b_id / nid18 ç­‰æœ‰æ•ˆæœŸè¾ƒé•¿ï¼Œä½†å»ºè®®æ¯éš”å‡ å‘¨ä»æµè§ˆå™¨é‡æ–°å¤åˆ¶ä¸€æ¬¡
        self.target_cookies = {
            "ut": self.target_ut,
            "qgqp_b_id": "9fb8c26c0a40e0e20ffd551bb6a52cdf",
            "st_nvi": "4U97b8QAwVvKIFT5nsAGl367a",
            "nid18": "03c4e656b6d9f1dfd8b102df6f142ef1",
            "nid18_create_time": "1770771500629",
            "gviem": "4GJIS9Ainpfv_DL4nyasN4263",
            "gviem_create_time": "1770771500629",
            "quote_lt": "1",
            "st_pvi": "35819178068592",
            "st_sp": "2025-09-17 09:51:41",
            "st_inirUrl": "https://www.google.com/",
        }

        self._check_akshare_interfaces()

    def _check_akshare_interfaces(self):
        """æ£€æŸ¥akshareå¯ç”¨æ¥å£"""
        if self.debug_mode:
            print("ğŸ” æ£€æŸ¥akshareæ¥å£å¯ç”¨æ€§...")
        
        # æµ‹è¯•å¸¸ç”¨æ¥å£
        interfaces_to_check = [
            'stock_financial_abstract_ths',
            'stock_financial_report_sina', 
            'stock_a_indicator_lg',
            'stock_a_lg_indicator',
            'stock_individual_info'
        ]
        
        available_interfaces = []
        for interface in interfaces_to_check:
            if hasattr(ak, interface):
                available_interfaces.append(interface)
                if self.debug_mode:
                    print(f"   âœ“ {interface}")
            else:
                if self.debug_mode:
                    print(f"   âœ— {interface}")
        
        self.available_akshare_interfaces = available_interfaces
        if self.debug_mode:
            print(f"âœ… å¯ç”¨æ¥å£: {len(available_interfaces)}ä¸ª")

    # =========================================================================
    # æ•°æ®ç±»å‹å®‰å…¨è½¬æ¢
    # =========================================================================

    def _safe_float(self, val):
        """
        å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•° - é€šç”¨ç‰ˆ
        ä»…åšç±»å‹è½¬æ¢å’Œç©ºå€¼/å¼‚å¸¸å€¼å¤„ç†ï¼Œä¸å«ä»»ä½•ä¸šåŠ¡é€»è¾‘
        éœ€è¦ä¸šåŠ¡æ ¡éªŒçš„å­—æ®µï¼ˆPE/PBï¼‰è¯·ä½¿ç”¨ä¸“ç”¨æ–¹æ³• _safe_pe / _safe_pb
        """
        try:
            if val is None or val == '' or val == '-':
                return None
            if isinstance(val, float) and (pd.isna(val) or np.isinf(val)):
                return None
            if isinstance(val, str):
                # å¤„ç†ç™¾åˆ†æ¯”
                if '%' in val:
                    return float(val.replace('%', '').strip())
                val = val.strip().replace(',', '')
                if val.lower() in ['--', 'null', 'nan', 'none', '-']:
                    return None
            result = float(val)
            if np.isinf(result) or np.isnan(result):
                return None
            return result
        except (ValueError, TypeError) as e:
            if hasattr(self, 'debug_mode') and self.debug_mode:
                print(f"      âš ï¸ æ•°å€¼è½¬æ¢è­¦å‘Š: '{val}' -> None ({str(e)})")
            return None

    def _safe_float_default(self, val, default: float = 0.0):
        """å¸¦é»˜è®¤å€¼çš„å®‰å…¨æµ®ç‚¹è½¬æ¢ï¼ŒNone æ—¶è¿”å› defaultï¼ˆç”¨äºä¸å…è®¸ç©ºçš„æ•°å€¼å­—æ®µï¼‰"""
        result = self._safe_float(val)
        return result if result is not None else default

    def _safe_pe(self, val):
        """
        PE ä¸“ç”¨å®‰å…¨è½¬æ¢
        - ä¿ç•™è´Ÿ PE è¯­ä¹‰ï¼ˆäºæŸè‚¡ï¼‰
        - æ— æ•ˆå€¼ï¼ˆ'-', nullï¼‰æˆ–æç«¯å€¼ï¼ˆç»å¯¹å€¼è¶…è¿‡ 10000ï¼‰è¿”å› None
        - None å­˜å…¥æ•°æ®åº“ï¼ŒåŒºåˆ«äº 0ï¼ˆ0 ä¼šäº§ç”Ÿè¯¯åˆ¤ï¼‰
        """
        result = self._safe_float(val)
        if result is None:
            return None
        # ä¸œæ–¹è´¢å¯Œå¯¹äºæŸè‚¡æœ‰æ—¶è¿”å› -999.xx è¿™æ ·çš„æ ‡è®°å€¼ï¼Œè¿‡æ»¤æ‰
        if result <= -10000 or result >= 10000:
            if self.debug_mode:
                print(f"      âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸PEå€¼: {result}ï¼Œå·²ç½®ä¸º None")
            return None
        return result

    def _safe_pb(self, val):
        """
        PB ä¸“ç”¨å®‰å…¨è½¬æ¢
        - PB < 0 é€šå¸¸æ˜¯æ•°æ®å¼‚å¸¸ï¼Œè¿”å› None
        - è¶…è¿‡ 10000 è¿”å› None
        """
        result = self._safe_float(val)
        if result is None:
            return None
        if result < 0 or result >= 10000:
            if self.debug_mode:
                print(f"      âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸PBå€¼: {result}ï¼Œå·²ç½®ä¸º None")
            return None
        return result

    def _safe_int(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•° - å¢å¼ºç‰ˆ"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return 0
            if isinstance(val, str):
                val = val.strip().replace(',', '')
                if val.lower() in ['--', 'null', 'nan', 'none']:
                    return 0
            return int(float(val))  # å…ˆè½¬floatå†è½¬inté¿å…ç²¾åº¦é—®é¢˜
        except (ValueError, TypeError):
            return 0

    def refresh_ut(self):
        """è‡ªåŠ¨åˆ·æ–° ut å‚æ•°"""
        print("ğŸ”„ æ­£åœ¨åˆ·æ–° ut å‚æ•°...")
        try:
            url = "https://quote.eastmoney.com/center/gridlist.html"
            response = self.session.get(url, timeout=10, verify=False)
            if response.status_code == 200:
                print("âœ… ut å‚æ•°åˆ·æ–°æˆåŠŸ")
                return True
            return False
        except Exception as e:
            print("âŒ åˆ·æ–° ut å¤±è´¥:", e)
            return False

    # =========================================================================
    # æ ¸å¿ƒæŠ“å–é€»è¾‘
    # =========================================================================

    async def fetch_em_data_via_web_api(self, page_size: int = 100) -> pd.DataFrame:
        """å¢å¼ºç‰ˆæ•°æ®æŠ“å– - å¢åŠ ç½‘ç»œå®¹é”™"""
        all_dfs = []
        current_page = 1
        total_pages = 999
        url = "https://push2.eastmoney.com/api/qt/clist/get"
        
        # clist/get æ˜¯ JSONP æ¥å£ï¼Œæµè§ˆå™¨ä»¥è„šæœ¬æ–¹å¼åŠ è½½ï¼ˆscriptæ ‡ç­¾ï¼‰ï¼Œå¯¹åº”å¤´éƒ¨å¦‚ä¸‹
        headers = {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Connection": "keep-alive",
            "Referer": "https://quote.eastmoney.com/center/gridlist.html",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36",
            "Sec-Fetch-Dest": "script",
            "Sec-Fetch-Mode": "no-cors",
            "Sec-Fetch-Site": "same-site",
            "sec-ch-ua": '"Not(A:Brand";v="8", "Chromium";v="144", "Google Chrome";v="144"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
        }
        
        print(f"\nğŸŒ å¯åŠ¨å¢å¼ºç‰ˆæ•°æ®æŠ“å– (æ¯é¡µ {page_size} æ¡)")

        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        def _make_session():
            """æ¯æ¬¡åˆ›å»ºå…¨æ–° sessionï¼Œé¿å…åŒä¸€ TCP è¿æ¥è¢«é™é€Ÿ"""
            s = requests.Session()
            s.trust_env = False
            s.proxies = {"http": None, "https": None}
            s.cookies.update(self.target_cookies)
            # æ³¨æ„ï¼šè¿™é‡Œä¸é…ç½®è‡ªåŠ¨é‡è¯•ï¼Œæ–­è¿ç”±å¤–å±‚é€»è¾‘æ‰‹åŠ¨å¤„ç†å¹¶é‡å»ºsession
            adapter = HTTPAdapter(pool_connections=2, pool_maxsize=5, max_retries=0)
            s.mount("http://", adapter)
            s.mount("https://", adapter)
            return s

        session = _make_session()
        consecutive_failures = 0
        max_consecutive_failures = 5  # æé«˜å®¹å¿åº¦
        # æ¯éš”å‡ é¡µä¸»åŠ¨é‡å»º sessionï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨é‡æ–°æ‰“å¼€
        pages_per_session = random.randint(4, 7)
        pages_in_current_session = 0

        while current_page <= total_pages and consecutive_failures < max_consecutive_failures:
            try:
                # ä¸»åŠ¨è½®æ¢ sessionï¼ˆæ¨¡æ‹Ÿç”¨æˆ·é—´éš”æ“ä½œï¼‰
                if pages_in_current_session >= pages_per_session:
                    session.close()
                    cooldown = random.uniform(30, 60)
                    print(f"   ğŸ”„ ä¸»åŠ¨è½®æ¢è¿æ¥ï¼Œå†·å´ {cooldown:.0f} ç§’...")
                    await asyncio.sleep(cooldown)
                    session = _make_session()
                    pages_in_current_session = 0
                    pages_per_session = random.randint(4, 7)

                print(f"   â¤ æŠ“å–ç¬¬ {current_page}/{total_pages if total_pages != 999 else '?'} é¡µ...")
                
                # âœ… cb å’Œ _ æ¯æ¬¡è¯·æ±‚åŠ¨æ€ç”Ÿæˆï¼Œé¿å…è¢«è¯†åˆ«ä¸ºçˆ¬è™«
                _ts = int(time.time() * 1000)
                params = {
                    "cb": f"jQuery341015241163678647807_{_ts}",
                    "pn": str(current_page),
                    "np": "1",
                    "ut": self.target_ut,
                    "fltt": "2",
                    "invt": "2",
                    "fs": "m:0+t:6+f:!2,m:0+t:13+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:81+s:2048",
                    "fields": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f23,f24,f25,f22,f11,f62,f111,f128,f136,f115,f148,f152",
                    "wbp2u": "|0|0|0|web",
                    "fid": "f3",
                    "po": "1",
                    "pz": str(page_size),
                    "_": str(_ts)
                }
                
                # å‘é€è¯·æ±‚
                response = await asyncio.to_thread(
                    session.get, 
                    url, 
                    params=params, 
                    headers=headers, 
                    timeout=30,
                    verify=False
                )
                
                if response.status_code != 200:
                    print(f"   âš ï¸ HTTPçŠ¶æ€ç : {response.status_code}")
                    consecutive_failures += 1
                    await asyncio.sleep(5)
                    continue
                
                # è§£å‹å“åº”ï¼šrequests è‡ªåŠ¨å¤„ç† gzip/deflate/br
                # è‹¥æœåŠ¡å™¨ä»å¼ºåˆ¶è¿”å› zstdï¼Œç”¨ zstandard åº“æ‰‹åŠ¨è§£å‹
                content_encoding = response.headers.get("Content-Encoding", "").lower()
                if "zstd" in content_encoding:
                    try:
                        import zstandard as zstd_lib
                        raw_text = zstd_lib.ZstdDecompressor().decompress(response.content).decode("utf-8")
                    except ImportError:
                        print("   âŒ æœåŠ¡å™¨è¿”å›äº† zstd å‹ç¼©ï¼Œè¯·æ‰§è¡Œ: pip install zstandard")
                        consecutive_failures += 1
                        await asyncio.sleep(5)
                        continue
                    except Exception as e:
                        print(f"   âš ï¸ zstd è§£å‹å¤±è´¥: {e}")
                        consecutive_failures += 1
                        await asyncio.sleep(5)
                        continue
                else:
                    raw_text = response.text
                json_match = re.search(r'jQuery.*?\((.*)\)', raw_text)
                if not json_match:
                    print(f"   âš ï¸ æ— æ³•è§£æJSONå“åº”ï¼ŒåŸå§‹å†…å®¹(å‰500å­—ç¬¦): {raw_text[:500]!r}")
                    consecutive_failures += 1
                    await asyncio.sleep(5)
                    continue
                
                res_json = json.loads(json_match.group(1))
                if not res_json or not res_json.get("data"):
                    if self.refresh_ut():
                        params["ut"] = self.target_ut
                        consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                        continue
                    else:
                        print("   âš ï¸ æ— æ³•åˆ·æ–°utå‚æ•°")
                        consecutive_failures += 1
                        await asyncio.sleep(10)
                        continue
                
                # é¦–æ¬¡è·å–æ€»è®°å½•æ•°
                if current_page == 1:
                    total_records = res_json["data"]["total"]
                    total_pages = (total_records + page_size - 1) // page_size
                    print(f"   ğŸ“Š å…¨å¸‚åœºå…± {total_records} åªè‚¡ç¥¨ï¼Œé¢„è®¡ {total_pages} é¡µ")
                
                # å¤„ç†æ•°æ®
                batch_df = pd.DataFrame(res_json["data"]["diff"])
                if not batch_df.empty:
                    all_dfs.append(batch_df)
                    consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                    pages_in_current_session += 1
                    print(f"   âœ… ç¬¬ {current_page} é¡µæŠ“å–æˆåŠŸ ({len(batch_df)} æ¡è®°å½•)")
                else:
                    print(f"   âš ï¸ ç¬¬ {current_page} é¡µæ— æ•°æ®")
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if current_page >= total_pages:
                    break
                    
                # é¡µé—´ç­‰å¾…ï¼šæ¨¡æ‹Ÿæ­£å¸¸ç¿»é¡µèŠ‚å¥ï¼ˆ3~8ç§’ï¼‰ï¼Œsessionè½®æ¢æ—¶ä¼šæœ‰æ›´é•¿å†·å´
                wait_time = random.uniform(3, 8)
                print(f"   ğŸ’¤ ç­‰å¾… {wait_time:.1f} ç§’...")
                await asyncio.sleep(wait_time)
                current_page += 1
                
            except requests.exceptions.ConnectionError as e:
                print(f"   âŒ è¿æ¥é”™è¯¯: {str(e)[:100]}")
                consecutive_failures += 1
                if consecutive_failures < max_consecutive_failures:
                    # æ–­è¿æ—¶é‡å»º session + è¾ƒé•¿å†·å´ï¼Œé¿å…ç»§ç»­ç”¨åŒä¸€è¿æ¥è¢«æ‹’
                    session.close()
                    wait_time = consecutive_failures * 20 + random.uniform(10, 30)
                    print(f"   ğŸ”„ é‡å»ºè¿æ¥ï¼Œå†·å´ {wait_time:.0f} ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                    session = _make_session()
                    pages_in_current_session = 0
                continue
                
            except requests.exceptions.Timeout as e:
                print(f"   âŒ è¯·æ±‚è¶…æ—¶: {str(e)[:100]}")
                consecutive_failures += 1
                if consecutive_failures < max_consecutive_failures:
                    print("   ğŸ’¤ è¶…æ—¶é‡è¯•ä¸­...")
                    await asyncio.sleep(10)
                continue
                
            except Exception as e:
                print(f"   âŒ ç¬¬ {current_page} é¡µå¤„ç†å¼‚å¸¸: {str(e)[:100]}")
                consecutive_failures += 1
                if consecutive_failures < max_consecutive_failures:
                    print("   ğŸ’¤ å¼‚å¸¸é‡è¯•ä¸­...")
                    await asyncio.sleep(15)
                continue
        
        # æ¸…ç†èµ„æº
        try:
            session.close()
        except Exception:
            pass
        
        # è¿”å›ç»“æœ
        if not all_dfs:
            print("âŒ æ‰€æœ‰é¡µé¢æŠ“å–å¤±è´¥")
            return pd.DataFrame()
        
        final_df = pd.concat(all_dfs, ignore_index=True)
        
        # åº”ç”¨å­—æ®µæ˜ å°„
        if hasattr(self, 'em_fields_map'):
            final_df = final_df.rename(columns=self.em_fields_map)
        
        # æ˜¾ç¤ºå­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
        print(f"\nâœ… æ€»è®¡è·å– {len(final_df)} æ¡æ•°æ®")
        print(f"\nğŸ“Š å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
        for col in ['code', 'name', 'latest_price', 'pe_dynamic', 'pb']:
            if col in final_df.columns:
                non_null = final_df[col].notna().sum()
                pct = (non_null / len(final_df)) * 100
                print(f"   [{'âœ…' if pct > 90 else 'âš ï¸'}] {col:20s}: {non_null:5d}/{len(final_df)} ({pct:5.1f}%)")
        
        return final_df


    async def fetch_em_data_via_akshare(self) -> pd.DataFrame:
        """
        é€šè¿‡ akshare è·å–å…¨é‡Aè‚¡è¡Œæƒ…ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        akshare åº•å±‚åŒæ ·æ˜¯ä¸œè´¢æ•°æ®ï¼Œä½†å°è£…äº†è¯·æ±‚ç»†èŠ‚ï¼Œä¸éœ€è¦æ‰‹åŠ¨ç»´æŠ¤ Cookie/Header
        å­—æ®µæ˜ å°„åˆ°ä¸ fetch_em_data_via_web_api ç›¸åŒçš„åˆ—å
        """
        print("\nğŸ“¡ é€šè¿‡ akshare è·å–å…¨é‡è¡Œæƒ…æ•°æ®...")
        try:
            df = await asyncio.to_thread(ak.stock_zh_a_spot_em)
            if df is None or df.empty:
                print("   âŒ akshare è¿”å›ç©ºæ•°æ®")
                return pd.DataFrame()

            print(f"   âœ… akshare è·å–æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")

            # akshare å­—æ®µå -> å†…éƒ¨å­—æ®µå
            col_map = {
                "ä»£ç ":     "code",
                "åç§°":     "name",
                "æœ€æ–°ä»·":   "latest_price",
                "æ¶¨è·Œå¹…":   "change_pct",
                "å¸‚ç›ˆç‡-åŠ¨æ€": "pe_dynamic",
                "å¸‚å‡€ç‡":   "pb",
                "æˆäº¤é‡":   "volume",
                "æˆäº¤é¢":   "amount",
            }
            df = df.rename(columns=col_map)

            # åªä¿ç•™éœ€è¦çš„åˆ—ï¼ˆå¿½ç•¥å¤šä½™åˆ—ï¼‰
            keep = [c for c in col_map.values() if c in df.columns]
            df = df[keep].copy()

            # å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
            print(f"\nğŸ“Š å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
            for col in ["code", "name", "latest_price", "pe_dynamic", "pb"]:
                if col in df.columns:
                    non_null = df[col].notna().sum()
                    pct = non_null / len(df) * 100
                    print(f"   [{'âœ…' if pct > 90 else 'âš ï¸'}] {col:20s}: {non_null:5d}/{len(df)} ({pct:5.1f}%)")

            return df

        except Exception as e:
            print(f"   âŒ akshare è·å–å¤±è´¥: {e}")
            return pd.DataFrame()

    async def fetch_daily_market_data(self, force: bool = False):
        """å…¥åº“é€»è¾‘æ•´åˆ"""
        db = SessionLocal()
        today = datetime.date.today()
        
        if not force and db.query(DailyMarketData).filter(DailyMarketData.date == today).first():
            db.close()
            return {"status": "skip", "message": "ä»Šæ—¥æ•°æ®å·²å­˜åœ¨"}

        # ä¼˜å…ˆä½¿ç”¨ akshareï¼ˆæ›´ç¨³å®šï¼‰ï¼Œå¤±è´¥åé™çº§åˆ°ç›´æ¥è¯·æ±‚ä¸œè´¢æ¥å£
        df = await self.fetch_em_data_via_akshare()
        if df.empty:
            print("   âš ï¸ akshare å¤±è´¥ï¼Œé™çº§åˆ°ç›´æ¥è¯·æ±‚ä¸œè´¢æ¥å£...")
            df = await self.fetch_em_data_via_web_api()
        if df.empty:
            db.close()
            return {"status": "error", "message": "æŠ“å–æ•°æ®ä¸ºç©º"}

        # åˆ é™¤æ—§æ•°æ®å¹¶å…¥åº“
        db.query(DailyMarketData).filter(DailyMarketData.date == today).delete()
        
        batch = []
        for _, row in df.iterrows():
            m = DailyMarketData(
                date=today,
                code=str(row.get('code', '')),
                name=str(row.get('name', '')),
                latest_price=self._safe_float_default(row.get('latest_price')),
                change_pct=self._safe_float_default(row.get('change_pct')),
                # âœ… ä½¿ç”¨ä¸“ç”¨æ–¹æ³•ï¼šä¿ç•™è´ŸPEè¯­ä¹‰ï¼ŒNone å­˜åº“è€Œé 0
                pe_dynamic=self._safe_pe(row.get('pe_dynamic')),
                pb=self._safe_pb(row.get('pb')),
                volume=self._safe_float_default(row.get('volume')),
                amount=self._safe_float_default(row.get('amount')),
                updated_at=datetime.datetime.now()
            )
            batch.append(m)
        
        db.bulk_save_objects(batch)
        db.commit()
        db.close()
        return {"status": "success", "count": len(batch)}
   
    async def fetch_dividend_data(self, stock_code: str = None):
        """åŒæ­¥åˆ†çº¢æ•°æ® (åŸºäºAkshare)"""
        db = SessionLocal()
        try:
            # æ­¤å¤„ç¤ºä¾‹ä¸ºè·å–æœ€æ–°åˆ†çº¢å…¬å‘Šï¼Œå®é™…ç”Ÿäº§ç¯å¢ƒå»ºè®®å®šæ—¶åŒæ­¥å…¨é‡
            df = ak.news_trade_notify_dividend_baidu(date=datetime.date.today().strftime('%Y%m%d'))
            if df.empty: return
            
            for _, row in df.iterrows():
                div = DividendData(
                    stock_code=row['è‚¡ç¥¨ä»£ç '],
                    stock_name=row['è‚¡ç¥¨ç®€ç§°'],
                    ex_dividend_date=pd.to_datetime(row['é™¤æƒæ—¥']).date(),
                    dividend=row['åˆ†çº¢'],
                    report_period=row['æŠ¥å‘ŠæœŸ']
                )
                db.merge(div)
            db.commit()
        except: pass
        finally: db.close()

    async def _request_with_retry(self, url, params, max_retries=3):
        """å¢å¼ºç‰ˆé‡è¯•è¯·æ±‚åŒ…è£…å™¨"""
        for i in range(max_retries):
            try:
                # åœ¨çº¿ç¨‹ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
                response = await asyncio.to_thread(
                    self.session.get, url, params=params, timeout=15, verify=False
                )
                if response.status_code == 200:
                    return response.json()
            except (requests.exceptions.ConnectionError, requests.exceptions.ChunkedEncodingError, requests.exceptions.RemoteDisconnected) as e:
                wait_time = (i + 1) * 3  # å¢åŠ ç­‰å¾…æ—¶é—´
                if i < max_retries - 1:
                    print(f"      âš ï¸ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... ({i+1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                    continue
                raise e
            except requests.exceptions.Timeout as e:
                if i < max_retries - 1:
                    print(f"      âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­... ({i+1}/{max_retries})")
                    continue
                raise e
        return None
    
    async def fetch_historical_data(self, stock_code: str):
        """åŒæ­¥å†å²Kçº¿"""
        db = SessionLocal()
        try:
            existing_count = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).count()
            if existing_count >= 100:
                return True
        finally:
            db.close()

        try:
            # éšæœºå»¶è¿Ÿï¼Œé¿å…å¹¶å‘è¯·æ±‚è¢«è¯†åˆ«
            await asyncio.sleep(random.uniform(2, 6))

            market = "1" if stock_code.startswith(('6', '9', '11')) else "0"
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                "cb": f"jQuery_{int(time.time()*1000)}",
                "secid": f"{market}.{stock_code}",
                "ut": self.target_ut,
                "fields1": "f1,f2,f3,f4,f5,f6",
                "fields2": "f51,f52,f53,f54,f55,f56",
                "klt": "101", "fqt": "1", "beg": "0", "end": "20500101",
                "lmt": "120", "_": str(int(time.time() * 1000))
            }

            # ç”¨ä¸€æ¬¡æ€§ sessionï¼Œä¸å¸¦è‡ªåŠ¨é‡è¯•
            def _do_request():
                s = requests.Session()
                s.trust_env = False
                s.proxies = {"http": None, "https": None}
                s.cookies.update(self.target_cookies)
                from requests.adapters import HTTPAdapter
                s.mount("http://", HTTPAdapter(max_retries=0))
                s.mount("https://", HTTPAdapter(max_retries=0))
                try:
                    headers = {
                        "Referer": "https://quote.eastmoney.com/",
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36",
                    }
                    return s.get(url, params=params, headers=headers, timeout=20, verify=False)
                finally:
                    s.close()

            response = await asyncio.to_thread(_do_request)

            if response and response.status_code == 200:
                match = re.search(r'\(({.*})\)', response.text)
                if match:
                    res = json.loads(match.group(1))
                    klines = res.get("data", {}).get("klines", [])
                    if klines:
                        db = SessionLocal()
                        try:
                            db.query(HistoricalData).filter(
                                HistoricalData.stock_code == stock_code
                            ).delete()
                            for line in klines:
                                cols = line.split(',')
                                if len(cols) >= 5:
                                    h = HistoricalData(
                                        stock_code=stock_code,
                                        date=datetime.datetime.strptime(cols[0], "%Y-%m-%d").date(),
                                        open=self._safe_float_default(cols[1]),
                                        close=self._safe_float_default(cols[2]),
                                        high=self._safe_float_default(cols[3]),
                                        low=self._safe_float_default(cols[4])
                                    )
                                    db.add(h)
                            db.commit()
                            return True
                        except Exception as e:
                            db.rollback()
                            if self.debug_mode:
                                print(f"      âš ï¸ Kçº¿ä¿å­˜å¤±è´¥: {e}")
                        finally:
                            db.close()

            return True  # Kçº¿å¤±è´¥ä¸é˜»æ–­åç»­åˆ†æ

        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ Kçº¿è·å–å¼‚å¸¸: {str(e)[:80]}")
            return True

    def _robust_request(self, url, params, timeout=20):
        """å¢å¼ºç‰ˆHTTPè¯·æ±‚ - å¸¦é‡è¯•å’Œé”™è¯¯å¤„ç†"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.session.get(url, params=params, timeout=timeout, verify=False)
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 200:
                    return response
                elif response.status_code in [429, 500, 502, 503, 504]:
                    # æœåŠ¡å™¨é”™è¯¯ï¼Œéœ€è¦é‡è¯•
                    wait_time = (attempt + 1) * 2
                    if self.debug_mode:
                        print(f"      âš ï¸ æœåŠ¡å™¨é”™è¯¯ {response.status_code}ï¼Œ{wait_time}ç§’åé‡è¯•... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    # å…¶ä»–é”™è¯¯
                    if self.debug_mode:
                        print(f"      âš ï¸ HTTPé”™è¯¯ {response.status_code}")
                    return None
                    
            except requests.exceptions.ConnectionError as e:
                wait_time = (attempt + 1) * 3
                if attempt < max_retries - 1:
                    if self.debug_mode:
                        print(f"      âš ï¸ è¿æ¥é”™è¯¯ï¼Œ{wait_time}ç§’åé‡è¯•... ({attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    if self.debug_mode:
                        print(f"      âš ï¸ è¿æ¥å¤±è´¥: {str(e)[:50]}")
                    return None
                    
            except requests.exceptions.Timeout as e:
                if attempt < max_retries - 1:
                    if self.debug_mode:
                        print(f"      âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­... ({attempt+1}/{max_retries})")
                    continue
                else:
                    if self.debug_mode:
                        print(f"      âš ï¸ è¯·æ±‚è¶…æ—¶: {str(e)[:50]}")
                    return None
                    
            except Exception as e:
                if self.debug_mode:
                    print(f"      âš ï¸ è¯·æ±‚å¼‚å¸¸: {str(e)[:50]}")
                return None
        
        return None
        
    async def _fetch_kline_local(self, stock_code: str):
        """æœ¬åœ°æ•°æ®è¡¥å……æ–¹æ¡ˆ"""
        db = SessionLocal()
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰éƒ¨åˆ†æ•°æ®
            existing_count = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).count()
            
            if existing_count > 0:
                print(f"      â„¹ï¸ ä½¿ç”¨ç°æœ‰{existing_count}æ¡Kçº¿æ•°æ®")
                return True
            
            # å¦‚æœå®Œå…¨æ²¡æœ‰æ•°æ®ï¼Œç”ŸæˆåŸºç¡€æ•°æ®ç”¨äºåˆ†æ
            market_data = db.query(DailyMarketData).filter(
                DailyMarketData.code == stock_code
            ).first()
            
            if market_data and market_data.latest_price:
                # ç”Ÿæˆä¸€æ¡åŸºç¡€Kçº¿æ•°æ®
                fake_kline = HistoricalData(
                    stock_code=stock_code,
                    date=datetime.date.today(),
                    open=market_data.latest_price,
                    close=market_data.latest_price,
                    high=market_data.latest_price * 1.02,
                    low=market_data.latest_price * 0.98
                )
                db.add(fake_kline)
                db.commit()
                print(f"      â„¹ï¸ ç”ŸæˆåŸºç¡€Kçº¿æ•°æ®ç”¨äºåˆ†æ")
                return True
                
        except Exception as e:
            print(f"      âš ï¸ æœ¬åœ°æ•°æ®è¡¥å……å¤±è´¥: {str(e)[:50]}")
        finally:
            db.close()
        
        return False
    
    async def _save_kline_data(self, stock_code: str, df):
        """ä¿å­˜Kçº¿æ•°æ®çš„é€šç”¨æ–¹æ³•"""
        db = SessionLocal()
        try:
            # æ¸…ç†æ—§æ•°æ®
            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
            
            # ä¿å­˜æ–°æ•°æ®
            for _, row in df.iterrows():
                h = HistoricalData(
                    stock_code=stock_code,
                    date=pd.to_datetime(row['date'] if 'date' in row else row.index).date(),
                    open=self._safe_float_default(row.get('open', 0)),
                    close=self._safe_float_default(row.get('close', 0)),
                    high=self._safe_float_default(row.get('high', 0)),
                    low=self._safe_float_default(row.get('low', 0))
                )
                db.add(h)
            
            db.commit()
        finally:
            db.close()

    async def fetch_stock_dividend_history(self, stock_code: str):
        """åŒæ­¥å†å²åˆ†çº¢è®°å½•"""
        db = SessionLocal()
        try:
            df = await asyncio.to_thread(ak.stock_history_dividend_detail, symbol=stock_code, indicator="åˆ†çº¢")
            if df is None or df.empty: return
            
            for _, row in df.iterrows():
                ex_date_raw = row.get('é™¤æƒé™¤æ¯æ—¥')
                if pd.isna(ex_date_raw) or str(ex_date_raw) in ['NaT', 'nan', '']: continue
                
                ex_date = pd.to_datetime(ex_date_raw).date()
                div_val = row.get('æ´¾æ¯(æ¯10è‚¡æ´¾,ç¨å‰)', 0)
                if not div_val: continue
                
                div = DividendData(
                    stock_code=stock_code,
                    stock_name=row.get('åç§°', 'æœªçŸ¥'),
                    ex_dividend_date=ex_date,
                    dividend=f"10æ´¾{div_val}",
                    report_period=str(row.get('åˆ†çº¢å¹´åº¦', ''))
                )
                db.merge(div)
            db.commit()
        except Exception as e:
            print(f"   âš ï¸ {stock_code} åˆ†çº¢æŠ“å–å¤±è´¥: {e}")
        finally:
            db.close()

    # =========================================================================
    # è´¢åŠ¡æŒ‡æ ‡è·å–
    # =========================================================================

    async def fetch_financial_metrics(self, stock_code: str):
        """è·å–è´¢åŠ¡æŒ‡æ ‡ - ä¿®å¤ç‰ˆ"""
        # ç¼“å­˜æ£€æŸ¥
        cache_key = f"financial_{stock_code}"
        if cache_key in self.financial_cache:
            if time.time() < self.cache_expiry[cache_key]:
                cached_data = self.financial_cache[cache_key]
                if self.debug_mode:
                    print(f"      â„¹ï¸ ä½¿ç”¨ç¼“å­˜è´¢åŠ¡æ•°æ®: ROE={cached_data[0]:.2f}%, Growth={cached_data[1]:.2f}%")
                return cached_data
        
        roe, growth = 0.0, 0.0
        attempts = []
        success_source = "none"
        
        try:
            # 1. é¦–é€‰ï¼šefinance è´¢åŠ¡æ•°æ®
            attempts.append("efinance")
            df = await asyncio.to_thread(ef.stock.get_base_info, stock_code)
            
            if df is not None and not df.empty:
                # ç»Ÿä¸€æ•°æ®æ ¼å¼å¤„ç†
                if isinstance(df, pd.DataFrame):
                    if len(df) > 0:
                        data = df.iloc[0].to_dict()
                    else:
                        data = {}
                elif isinstance(df, pd.Series):
                    data = df.to_dict()
                else:
                    data = {}
                
                # å¤šç§å­—æ®µååŒ¹é…
                roe_fields = ['å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'ROE(%)', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'roe', 'ROE']
                growth_fields = ['å‡€åˆ©æ¶¦åŒæ¯”(%)', 'å‡€åˆ©æ¶¦å¢é•¿ç‡(%)', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿', 'net_profit_growth', 'profit_growth']
                
                # æå– ROE
                for field in roe_fields:
                    if field in data and data[field] is not None:
                        roe_val = self._safe_float_default(data[field])
                        if roe_val != 0:
                            roe = roe_val
                            break
                
                # æå–åˆ©æ¶¦å¢é•¿ç‡
                for field in growth_fields:
                    if field in data and data[field] is not None:
                        growth_val = self._safe_float_default(data[field])
                        if growth_val != 0:
                            growth = growth_val
                            break
                
                if roe != 0 or growth != 0:
                    if self.debug_mode:
                        print(f"      âœ“ é€šè¿‡ efinance è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "efinance"
                    self.financial_cache[cache_key] = (float(roe), float(growth))
                    self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                    return float(roe), float(growth)
                    
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ efinance å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 2. å¤‡é€‰ï¼šakshare è´¢åŠ¡æŠ¥è¡¨
            attempts.append("akshare_financial")
            formatted_code = self._format_stock_code_for_akshare(stock_code)
            
            try:
                df_fin = await asyncio.to_thread(ak.stock_financial_abstract_ths, symbol=stock_code)
            except AttributeError:
                try:
                    df_fin = await asyncio.to_thread(ak.stock_financial_report_sina, symbol=formatted_code)
                except:
                    df_fin = None
            
            if df_fin is not None and not df_fin.empty and len(df_fin) > 0:
                data_fin = df_fin.iloc[0].to_dict()
                
                roe = self._safe_float_default(data_fin.get('å‡€èµ„äº§æ”¶ç›Šç‡') or 
                                    data_fin.get('ROE') or 
                                    data_fin.get('å‡€èµ„äº§æ”¶ç›Šç‡(%)') or 0)
                growth = self._safe_float_default(data_fin.get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿') or 
                                        data_fin.get('å‡€åˆ©æ¶¦å¢é•¿ç‡') or 
                                        data_fin.get('å‡€åˆ©æ¶¦åŒæ¯”(%)') or 0)
                
                if roe != 0 or growth != 0:
                    if self.debug_mode:
                        print(f"      âœ“ é€šè¿‡ akshare è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "akshare_financial"
                    self.financial_cache[cache_key] = (float(roe), float(growth))
                    self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                    return float(roe), float(growth)
                    
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ akshare financial å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 3. å†å¤‡é€‰ï¼šakshare ä¸»è¦æŒ‡æ ‡
            attempts.append("akshare_indicator")
            formatted_code = self._format_stock_code_for_akshare(stock_code)
            
            df_ind = None
            indicator_functions = [
                'stock_a_indicator_lg',
                'stock_a_lg_indicator',
                'stock_individual_info',
            ]
            
            for func_name in indicator_functions:
                try:
                    if hasattr(ak, func_name):
                        df_ind = await asyncio.to_thread(getattr(ak, func_name), symbol=stock_code)
                        if df_ind is not None and not df_ind.empty:
                            break
                except:
                    continue
            
            if df_ind is not None and not df_ind.empty and len(df_ind) > 0:
                data_ind = df_ind.iloc[0].to_dict()
                
                roe_fields = ['å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'ROE', 'roe', 'å‡€èµ„äº§æ”¶ç›Šç‡']
                growth_fields = ['å‡€åˆ©æ¶¦åŒæ¯”(%)', 'å‡€åˆ©æ¶¦å¢é•¿ç‡(%)', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿']
                
                for field in roe_fields:
                    if field in data_ind and data_ind[field] is not None:
                        roe_val = self._safe_float_default(data_ind[field])
                        if roe_val != 0:
                            roe = roe_val
                            break
                
                for field in growth_fields:
                    if field in data_ind and data_ind[field] is not None:
                        growth_val = self._safe_float_default(data_ind[field])
                        if growth_val != 0:
                            growth = growth_val
                            break
                
                if roe != 0 or growth != 0:
                    if self.debug_mode:
                        print(f"      âœ“ é€šè¿‡ akshare æŒ‡æ ‡è·å–: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "akshare_indicator"
                    self.financial_cache[cache_key] = (float(roe), float(growth))
                    self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                    return float(roe), float(growth)
                    
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ akshare indicator å¤±è´¥: {str(e)[:50]}")
        
        # 4. æœ€åå¤‡é€‰ï¼šä»å¸‚åœºä»·æ ¼æ•°æ®æ¨ç®—
        try:
            attempts.append("market_derived")
            derived_roe, derived_growth = await self._derive_financial_from_market(stock_code)
            if derived_roe != 0 or derived_growth != 0:
                if self.debug_mode:
                    print(f"      âœ“ é€šè¿‡å¸‚åœºæ•°æ®æ¨ç®—: ROE={derived_roe:.2f}%, Growth={derived_growth:.2f}%")
                success_source = "market_derived"
                self.financial_cache[cache_key] = (float(derived_roe), float(derived_growth))
                self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                return float(derived_roe), float(derived_growth)
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ å¸‚åœºæ•°æ®æ¨ç®—å¤±è´¥: {str(e)[:50]}")
        
        if roe == 0 and growth == 0:
            if self.debug_mode:
                print(f"      âŒ {stock_code} è´¢åŠ¡æŒ‡æ ‡è·å–å®Œå…¨å¤±è´¥ (å°è¯•äº†: {', '.join(attempts)})")
        
        return float(roe), float(growth)
    
    def _format_stock_code_for_akshare(self, stock_code: str) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä»¥é€‚é… akshare æ¥å£"""
        if stock_code.startswith(('6', '9')):
            return f"sh{stock_code}"
        elif stock_code.startswith(('0', '3')):
            return f"sz{stock_code}"
        return stock_code
    
    async def _derive_financial_from_market(self, stock_code: str):
        """ä»å¸‚åœºä»·æ ¼æ•°æ®æ¨ç®—åŸºç¡€è´¢åŠ¡æŒ‡æ ‡ - å¢å¼ºç‰ˆ"""
        db = SessionLocal()
        try:
            hist_data = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).order_by(HistoricalData.date.desc()).limit(252).all()
            
            if len(hist_data) < 30:
                return 0.0, 0.0
            
            prices = [float(h.close) for h in reversed(hist_data)]
            if len(prices) >= 2:
                annual_growth = ((prices[-1] / prices[0]) ** (252/len(prices)) - 1) * 100
                derived_growth = max(-50, min(50, annual_growth))
            else:
                derived_growth = 0.0
            
            if stock_code.startswith('688'):
                derived_roe = max(0, min(30, abs(derived_growth) * 0.6))
            else:
                derived_roe = max(0, min(30, abs(derived_growth) * 0.8))
            
            if self.debug_mode:
                print(f"      â„¹ï¸ å¸‚åœºæ•°æ®æ¨ç®—: ROEâ‰ˆ{derived_roe:.2f}%, Growthâ‰ˆ{derived_growth:.2f}% (åŸºäº{len(prices)}å¤©æ•°æ®)")
            
            return float(derived_roe), float(derived_growth)
            
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ å¸‚åœºæ•°æ®æ¨ç®—å¼‚å¸¸: {str(e)[:50]}")
            return 0.0, 0.0
        finally:
            db.close()

    def _assess_data_quality(self, roe: float, growth: float, source: str) -> float:
        """è¯„ä¼°æ•°æ®è´¨é‡ (0-1)"""
        quality = 0.0
        source_weights = {
            "efinance": 1.0,
            "akshare_financial": 0.8,
            "akshare_indicator": 0.6,
            "market_derived": 0.3
        }
        quality += source_weights.get(source, 0.1)
        if -50 <= roe <= 50:
            quality += 0.3
        if -100 <= growth <= 200:
            quality += 0.3
        if roe != 0:
            quality += 0.2
        if growth != 0:
            quality += 0.2
        return min(1.0, quality)

    # =========================================================================
    # è¯„åˆ†ä½“ç³»ï¼ˆæ»¡åˆ† 100 åˆ†ï¼‰
    #
    #  ç»´åº¦           åˆ†å€¼    è¯´æ˜
    #  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  æ³¢åŠ¨ç‡          0~30   ä½æ³¢åŠ¨ä¼˜å…ˆï¼Œv30 å¹´åŒ–æ³¢åŠ¨ç‡
    #  è‚¡æ¯ç‡          0~25   å¹´åŒ–è‚¡æ¯ç‡
    #  æˆé•¿æ€§          0~25   ROE(0~15) + åˆ©æ¶¦å¢é€Ÿ(0~10)
    #  ä¼°å€¼            0~20   PE(0~12) + PB(0~8)ï¼Œè´ŸPEä¸åŠ åˆ†
    #
    #  å»ºè®®æ¡£ä½ï¼šâ‰¥75 å¼ºçƒˆæ¨è / â‰¥55 æ¨è / â‰¥40 å…³æ³¨ / <40 è§‚æœ›
    # =========================================================================

    def _calc_volatility_score(self, v30: float) -> int:
        """æ³¢åŠ¨ç‡è¯„åˆ† (0-30 åˆ†)ï¼Œv30 ä¸º 30 æ—¥å¹´åŒ–æ³¢åŠ¨ç‡(%)"""
        if v30 <= 0:
            return 0
        if v30 < 20:
            return 30
        elif v30 < 30:
            return 22
        elif v30 < 40:
            return 14
        elif v30 < 55:
            return 8
        else:
            return 3

    def _calc_dividend_score(self, div_yield: float) -> int:
        """è‚¡æ¯ç‡è¯„åˆ† (0-25 åˆ†)ï¼Œdiv_yield ä¸ºå¹´åŒ–è‚¡æ¯ç‡(%)"""
        if div_yield >= 6:
            return 25
        elif div_yield >= 4:
            return 20
        elif div_yield >= 2.5:
            return 14
        elif div_yield >= 1.2:
            return 8
        else:
            return 0

    def _calc_growth_score(self, roe: float, profit_growth: float) -> int:
        """
        æˆé•¿æ€§è¯„åˆ† (0-25 åˆ†)
        ROE å­åˆ† (0-15) + åˆ©æ¶¦å¢é€Ÿå­åˆ† (0-10)
        """
        # ROE å­åˆ†
        if roe >= 20:
            roe_score = 15
        elif roe >= 15:
            roe_score = 12
        elif roe >= 10:
            roe_score = 9
        elif roe >= 6:
            roe_score = 5
        elif roe > 0:
            roe_score = 2
        else:
            roe_score = 0  # äºæŸä¸ç»™åˆ†

        # åˆ©æ¶¦å¢é€Ÿå­åˆ†
        if profit_growth >= 30:
            growth_sub = 10
        elif profit_growth >= 15:
            growth_sub = 8
        elif profit_growth >= 5:
            growth_sub = 5
        elif profit_growth >= 0:
            growth_sub = 2
        else:
            growth_sub = 0  # åˆ©æ¶¦ä¸‹æ»‘ä¸ç»™åˆ†

        return roe_score + growth_sub

    def _calc_valuation_score(self, pe: float | None, pb: float | None) -> int:
        """
        ä¼°å€¼è¯„åˆ† (0-20 åˆ†)
        PE å­åˆ† (0-12)ï¼šè´ŸPE=äºæŸä¸åŠ åˆ†ï¼ŒNone=æ— æ•°æ®ä¸åŠ åˆ†
        PB å­åˆ† (0-8)
        """
        pe_score = 0
        pb_score = 0

        # PE å­åˆ†
        if pe is not None and pe > 0:
            if pe < 10:
                pe_score = 12
            elif pe < 18:
                pe_score = 10
            elif pe < 28:
                pe_score = 7
            elif pe < 40:
                pe_score = 4
            elif pe < 60:
                pe_score = 2
            else:
                pe_score = 0

        # PB å­åˆ†
        if pb is not None and pb > 0:
            if pb < 1.0:
                pb_score = 8
            elif pb < 2.0:
                pb_score = 6
            elif pb < 3.5:
                pb_score = 4
            elif pb < 6.0:
                pb_score = 2
            else:
                pb_score = 0

        return pe_score + pb_score

    # =========================================================================
    # ç»¼åˆåˆ†æ
    # =========================================================================

    async def analyze_stock(self, stock_code: str, db: Session):
        """
        ç»¼åˆåˆ†æè¯„åˆ†ï¼ˆæ»¡åˆ† 100 åˆ†ï¼‰
        ç»´åº¦ï¼šæ³¢åŠ¨ç‡(30) + è‚¡æ¯ç‡(25) + æˆé•¿æ€§(25) + ä¼°å€¼(20)
        """
        today = datetime.date.today()
        
        # 1. åŸºç¡€è¡Œæƒ…æ ¡éªŒ
        market = db.query(DailyMarketData).filter(
            DailyMarketData.code == stock_code
        ).order_by(desc(DailyMarketData.date)).first()
        
        if not market or not market.latest_price:
            print(f"   âš ï¸ {stock_code} ç¼ºå¤±å®æ—¶è¡Œæƒ…ï¼Œæ— æ³•åˆ†æ")
            return None

        # ---------------------------------------------------------
        # 2. æ³¢åŠ¨ç‡è®¡ç®—
        # ---------------------------------------------------------
        v30, v60, vol_score = 0.0, 0.0, 0
        
        hist = db.query(HistoricalData).filter(
            HistoricalData.stock_code == stock_code
        ).order_by(desc(HistoricalData.date)).limit(120).all()

        if len(hist) >= 20:
            prices = [h.close for h in reversed(hist)]
            price_series = pd.Series(prices)
            log_returns = np.log(price_series / price_series.shift(1)).dropna()
            
            if len(log_returns) >= 30:
                v30 = float(log_returns.tail(30).std() * np.sqrt(252) * 100)
                
            if len(log_returns) >= 60:
                v60 = float(log_returns.tail(60).std() * np.sqrt(252) * 100)
            
            vol_score = self._calc_volatility_score(v30)

        # ---------------------------------------------------------
        # 3. è‚¡æ¯ç‡è®¡ç®—
        # ---------------------------------------------------------
        div_yield, div_score = 0.0, 0
        one_year_ago = today - datetime.timedelta(days=365)
        
        dividends = db.query(DividendData).filter(
            DividendData.stock_code == stock_code,
            DividendData.ex_dividend_date >= one_year_ago
        ).all()
        
        total_cash_div = 0.0
        if dividends:
            for d in dividends:
                match = re.search(r'æ´¾(\d+\.?\d*)', str(d.dividend))
                if match:
                    total_cash_div += float(match.group(1)) / 10
            
            if total_cash_div > 0 and market.latest_price:
                div_yield = (total_cash_div / market.latest_price) * 100
                if self.debug_mode:
                    print(f"      âœ“ è‚¡æ¯ç‡: {div_yield:.2f}% (å¹´åº¦åˆ†çº¢: {total_cash_div:.2f}å…ƒ/è‚¡)")
            
            div_score = self._calc_dividend_score(div_yield)

        # ---------------------------------------------------------
        # 4. è´¢åŠ¡æ•°æ® (ROE & Growth)
        # ---------------------------------------------------------
        roe, profit_growth = await self.fetch_financial_metrics(stock_code)
        growth_score = self._calc_growth_score(roe, profit_growth)

        # ---------------------------------------------------------
        # 5. ä¼°å€¼è¯„åˆ†ï¼ˆç›´æ¥ä½¿ç”¨ä¿®å¤åçš„ None è¯­ä¹‰ï¼‰
        # ---------------------------------------------------------
        pe_val = market.pe_dynamic   # None=äºæŸ/æ— æ•°æ®ï¼Œè´Ÿæ•°=äºæŸï¼Œå‡ä¸åŠ åˆ†
        pb_val = market.pb
        valuation_score = self._calc_valuation_score(pe_val, pb_val)

        # ---------------------------------------------------------
        # 6. æ±‡æ€»
        # ---------------------------------------------------------
        total = int(vol_score + div_score + growth_score + valuation_score)

        if total >= 75:
            suggestion = "å¼ºçƒˆæ¨è"
        elif total >= 55:
            suggestion = "æ¨è"
        elif total >= 40:
            suggestion = "å…³æ³¨"
        else:
            suggestion = "è§‚æœ›"

        if self.debug_mode:
            print(
                f"      ğŸ“Š {stock_code} è¯„åˆ†: "
                f"æ³¢åŠ¨ç‡{vol_score} + è‚¡æ¯{div_score} + æˆé•¿{growth_score} + ä¼°å€¼{valuation_score} "
                f"= {total} [{suggestion}]  PE={pe_val}  PB={pb_val}"
            )

        # ---------------------------------------------------------
        # 7. æŒä¹…åŒ–
        # ---------------------------------------------------------
        analysis_res = StockAnalysisResult(
            stock_code=stock_code,
            stock_name=market.name,
            analysis_date=today,
            
            # åŸºç¡€æ•°æ®
            latest_price=market.latest_price,
            pe_ratio=pe_val,      # âœ… ä¿ç•™ None / è´Ÿæ•°è¯­ä¹‰
            pb_ratio=pb_val,
            
            # æ³¢åŠ¨ç‡æŒ‡æ ‡
            volatility_30d=round(v30, 2),
            volatility_60d=round(v60, 2),
            
            # è´¢åŠ¡æŒ‡æ ‡
            dividend_yield=round(div_yield, 2),
            roe=round(roe, 2),
            profit_growth=round(profit_growth, 2),
            
            # è¯„åˆ†
            volatility_score=int(vol_score),
            dividend_score=int(div_score),
            growth_score=int(growth_score),
            valuation_score=int(valuation_score),   # âœ… æ–°å¢ä¼°å€¼å¾—åˆ†å­—æ®µ
            total_score=total,
            
            suggestion=suggestion,
            data_source="automated_v4"
        )

        try:
            db.merge(analysis_res)
            db.commit()
            return analysis_res.total_score
        except Exception as e:
            db.rollback()
            print(f"   âŒ {stock_code} ç»“æœå…¥åº“å¤±è´¥: {e}")
            return None

    # =========================================================================
    # æ‰¹é‡åˆ†æä»»åŠ¡
    # =========================================================================

    async def analyze_all_watched_stocks(self):
        """ä¸»åˆ†æä»»åŠ¡å¾ªç¯ - ä¿®å¤ç‰ˆ"""
        db = SessionLocal()
        stats = {
            "success": 0, 
            "failed": 0, 
            "financial_failed": 0,
            "network_errors": 0,
            "data_errors": 0,
            "timeout_errors": 0,
            "total_processed": 0
        }
        semaphore = asyncio.Semaphore(self.settings.CONCURRENT_LIMIT)
        
        try:
            # è·å–å…³æ³¨è‚¡ç¥¨åˆ—è¡¨
            watched_raw = db.query(UserStockWatch.stock_code).distinct().all()
            watched_codes = list(set([w[0] for w in watched_raw if w[0] and len(w[0]) == 6 and w[0].isdigit()]))
            total = len(watched_codes)
            
            print(f"ğŸš€ å¯åŠ¨æ·±åº¦åˆ†æ (å…± {total} åª)...")
            print(f"ğŸ“Š é…ç½®: å¹¶å‘æ•°{self.settings.CONCURRENT_LIMIT}, è¶…æ—¶{self.settings.FINANCIAL_FETCH_TIMEOUT}s")
            
            # è·å–é«˜ä¼˜å…ˆçº§è‚¡ç¥¨
            priority_stocks = await self._get_priority_stocks(db, [(code,) for code in watched_codes])
            print(f"ğŸ¯ ä¼˜å…ˆå¤„ç† {len(priority_stocks)} åªé‡è¦è‚¡ç¥¨...")
            
            # è®°å½•å·²å¤„ç†çš„è‚¡ç¥¨
            processed_stocks = set()
            tasks = []
            
            async def process_stock(stock_index, stock_code):
                if stock_code in processed_stocks:
                    return
                processed_stocks.add(stock_code)
                
                async with semaphore:
                    try:
                        stats["total_processed"] += 1
                        current_index = stats["total_processed"]
                        
                        kline_success = await self.fetch_historical_data(stock_code)
                        if not kline_success and self.debug_mode:
                            print(f"      âš ï¸ Kçº¿è·å–å¤±è´¥ï¼Œä½†ä»ç»§ç»­åˆ†æ...")
                        
                        await self.fetch_stock_dividend_history(stock_code)
                        score = await self.analyze_stock(stock_code, db)
                        
                        if score is not None:
                            stats["success"] += 1
                            success_rate = (stats["success"] / current_index) * 100 if current_index > 0 else 0
                            print(f"   âœ“ {current_index}/{total} {stock_code} åˆ†æå®Œæˆ (è¯„åˆ†: {score}, æˆåŠŸç‡: {success_rate:.1f}%)")
                        else:
                            stats["failed"] += 1
                            success_rate = (stats["success"] / current_index) * 100 if current_index > 0 else 0
                            print(f"   âŒ {current_index}/{total} {stock_code} åˆ†æå¤±è´¥ (æˆåŠŸç‡: {success_rate:.1f}%)")
                        
                    except Exception as e:
                        stats["failed"] += 1
                        stats["total_processed"] += 1
                        current_index = stats["total_processed"]
                        success_rate = (stats["success"] / current_index) * 100 if current_index > 0 else 0
                        error_msg = str(e).lower()
                        
                        if "connection" in error_msg or "disconnected" in error_msg:
                            stats["network_errors"] += 1
                        elif "timeout" in error_msg:
                            stats["timeout_errors"] += 1
                        elif "data" in error_msg or "format" in error_msg:
                            stats["data_errors"] += 1
                        else:
                            stats["financial_failed"] += 1
                        
                        print(f"   âŒ {current_index}/{total} {stock_code} å¤„ç†å¼‚å¸¸: {str(e)[:50]} (æˆåŠŸç‡: {success_rate:.1f}%)")
                    
                    # å»¶è¿Ÿç­–ç•¥
                    delay = random.uniform(
                        self.settings.FETCH_DELAY_MIN, 
                        self.settings.FETCH_DELAY_MAX
                    )
                    remaining = total - current_index
                    eta_minutes = (remaining * delay) / 60 if remaining > 0 else 0
                    print(f"   ğŸ’¤ ç­‰å¾… {delay:.1f} ç§’... (é¢„è®¡å‰©ä½™: {eta_minutes:.1f}åˆ†é’Ÿ)")
                    await asyncio.sleep(delay)
            
            # å¤„ç†æ‰€æœ‰è‚¡ç¥¨
            all_stocks = priority_stocks + [code for code in watched_codes if code not in priority_stocks]
            for i, code in enumerate(all_stocks, 1):
                tasks.append(process_stock(i, code))
                
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # æœ€ç»ˆç»Ÿè®¡
            final_success_rate = (stats["success"] / total) * 100 if total > 0 else 0
            print(f"\nğŸ åˆ†æå®Œæˆ!")
            print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
            print(f"   æ€»æ•°: {total}")
            print(f"   æˆåŠŸ: {stats['success']} ({final_success_rate:.1f}%)")
            print(f"   å¤±è´¥: {stats['failed']}")
            if stats["network_errors"] > 0:
                print(f"   ç½‘ç»œé”™è¯¯: {stats['network_errors']}")
            if stats["timeout_errors"] > 0:
                print(f"   è¶…æ—¶é”™è¯¯: {stats['timeout_errors']}")
            if stats["data_errors"] > 0:
                print(f"   æ•°æ®é”™è¯¯: {stats['data_errors']}")
            if stats["financial_failed"] > 0:
                print(f"   è´¢åŠ¡æ•°æ®å¤±è´¥: {stats['financial_failed']}")
                
        except Exception as e:
            print(f"ğŸš¨ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            db.close()
    
    async def _check_update_needed(self, db: Session, watched_stocks):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°"""
        latest_analysis = db.query(StockAnalysisResult).order_by(
            desc(StockAnalysisResult.analysis_date)
        ).first()
        
        if not latest_analysis:
            return True
        
        watched_codes = set([row[0] for row in watched_stocks])
        today_analyzed_codes = set([
            result.stock_code for result in 
            db.query(StockAnalysisResult.stock_code).filter(
                StockAnalysisResult.analysis_date == datetime.date.today()
            ).all()
        ])
        
        return not watched_codes.issubset(today_analyzed_codes)
    
    async def _get_priority_stocks(self, db: Session, all_stocks):
        """è·å–é«˜ä¼˜å…ˆçº§è‚¡ç¥¨ï¼ˆæŒä»“æˆ–é«˜è¯„åˆ†ï¼‰"""
        holdings = db.query(UserStockHolding.stock_code).filter(
            UserStockHolding.is_active == True
        ).distinct().all()
        
        high_score = db.query(StockAnalysisResult.stock_code).filter(
            StockAnalysisResult.total_score > 80
        ).distinct().all()
        
        priority_set = set([h[0] for h in holdings] + [s[0] for s in high_score])
        all_codes = set([row[0] for row in all_stocks])
        
        return list(priority_set.intersection(all_codes))
    
    async def _check_network_health(self):
        """æ£€æŸ¥ç½‘ç»œè¿æ¥å¥åº·åº¦"""
        try:
            response = await asyncio.to_thread(
                self.session.get, "https://httpbin.org/get", timeout=5
            )
            return response.status_code == 200
        except:
            return False
    
    async def _adaptive_delay(self, network_healthy: bool):
        """è‡ªé€‚åº”å»¶è¿Ÿè°ƒæ•´"""
        if network_healthy:
            return random.uniform(
                self.settings.FETCH_DELAY_MIN,
                self.settings.FETCH_DELAY_MAX
            )
        else:
            return random.uniform(
                self.settings.FETCH_DELAY_MAX,
                self.settings.FETCH_DELAY_MAX * 2
            )

    # =========================================================================
    # æ•°æ®ç»´æŠ¤å·¥å…·
    # =========================================================================

    async def clean_abnormal_pe_data(self):
        """æ¸…ç†å†å²å¼‚å¸¸PEæ•°æ®ï¼ˆå°†æ—§é€»è¾‘é”™è¯¯å½’é›¶çš„è®°å½•ä¿®æ­£ä¸º Noneï¼‰"""
        db = SessionLocal()
        try:
            # pe_ratio=0 ä¸”è‚¡ä»·æ­£å¸¸ â†’ å¤§æ¦‚ç‡æ˜¯è¢«æ—§ _safe_float è¯¯å½’é›¶çš„
            abnormal_records = db.query(StockAnalysisResult).filter(
                StockAnalysisResult.pe_ratio == 0.0,
                StockAnalysisResult.latest_price > 0
            ).all()
            
            if abnormal_records:
                print(f"ğŸ” å‘ç° {len(abnormal_records)} æ¡ç–‘ä¼¼è¢«é”™è¯¯å½’é›¶çš„PEè®°å½•ï¼Œå·²ä¿®æ­£ä¸º None")
                for record in abnormal_records:
                    record.pe_ratio = None
                db.commit()
                print("âœ… å†å²å¼‚å¸¸PEæ•°æ®å·²æ¸…ç†")
            else:
                print("âœ… æœªå‘ç°å¼‚å¸¸PEæ•°æ®")
                
        except Exception as e:
            print(f"âŒ æ¸…ç†å¼‚å¸¸æ•°æ®å¤±è´¥: {e}")
        finally:
            db.close()

    async def validate_analysis_data(self):
        """éªŒè¯åˆ†ææ•°æ®çš„åˆç†æ€§"""
        db = SessionLocal()
        try:
            one_week_ago = datetime.date.today() - datetime.timedelta(days=7)
            
            suspicious_records = db.query(StockAnalysisResult).filter(
                StockAnalysisResult.analysis_date >= one_week_ago,
                (StockAnalysisResult.total_score > 100) |
                (StockAnalysisResult.total_score < 0)
            ).all()
            
            if suspicious_records:
                print(f"âš ï¸ å‘ç° {len(suspicious_records)} æ¡å¯ç–‘æ•°æ®:")
                for record in suspicious_records:
                    issues = []
                    if record.total_score > 100 or record.total_score < 0:
                        issues.append(f"è¯„åˆ†å¼‚å¸¸({record.total_score})")
                    print(f"   {record.stock_code} {record.analysis_date}: {', '.join(issues)}")
            else:
                print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
                
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        finally:
            db.close()

stock_service = StockDataService()