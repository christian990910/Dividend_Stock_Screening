import os
import re
import time
import json
import random
import asyncio
import datetime
import pandas as pd
import numpy as np
import requests
import efinance as ef
import akshare as ak
from sqlalchemy.orm import Session
from sqlalchemy import desc, func

from core.database import SessionLocal
from core.config import settings  # ç¡®ä¿è¿™è¡Œå­˜åœ¨
from models.stock import DailyMarketData, HistoricalData, DividendData, StockAnalysisResult, UserStockWatch
from models.holdings import UserStockHolding  # æ·»åŠ è¿™è¡Œå¯¼å…¥
from crud.stock import save_market_data_batch, save_analysis_result

class StockDataService:
    def __init__(self):
        self.settings = settings
        self.debug_mode = os.getenv('DEBUG_MODE', 'false').lower() == 'true'
        
        # æ·»åŠ ç¼“å­˜å±‚
        self.financial_cache = {}  # è´¢åŠ¡æ•°æ®ç¼“å­˜
        self.cache_expiry = {}     # ç¼“å­˜è¿‡æœŸæ—¶é—´
        self.CACHE_TTL = 3600      # ç¼“å­˜æœ‰æ•ˆæœŸ1å°æ—¶
        
        # ä¼˜åŒ–è¯·æ±‚ä¼šè¯é…ç½®
        self.session = requests.Session()
        self.session.trust_env = False
        self.session.proxies = {"http": None, "https": None}
        
        # å¢å¼ºè¿æ¥æ± é…ç½®
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,  # æ€»é‡è¯•æ¬¡æ•°
            backoff_factor=1,  # é€€é¿å› å­
            status_forcelist=[429, 500, 502, 503, 504],  # éœ€è¦é‡è¯•çš„çŠ¶æ€ç 
            allowed_methods=["HEAD", "GET", "OPTIONS"]  # å…è®¸é‡è¯•çš„æ–¹æ³•
        )
        
        adapter = HTTPAdapter(
            pool_connections=10,  # è¿æ¥æ± å¤§å°
            pool_maxsize=20,      # æœ€å¤§è¿æ¥æ•°
            max_retries=retry_strategy
        )
        
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0"
        }
        self.session.headers.update(self.headers)
        
        # ç›®æ ‡å‚æ•° (ä¸œæ–¹è´¢å¯Œ)
        self.target_ut = "bd1d9ddb04089700cf9c27f6f7426281"
        self.target_cookies = {
            "ut": self.target_ut,
        }

        self._check_akshare_interfaces()

    def _check_akshare_interfaces(self):
        """æ£€æŸ¥akshareå¯ç”¨æ¥å£"""
        if self.debug_mode:
            print("ğŸ” æ£€æŸ¥akshareæ¥å£å¯ç”¨æ€§...")
        
        # æµ‹è¯•å¸¸ç”¨æ¥å£
        interfaces_to_check = [
            'stock_financial_abstract_ths',
            'stock_financial_report_sina', 
            'stock_a_indicator_lg',
            'stock_a_lg_indicator',
            'stock_individual_info'
        ]
        
        available_interfaces = []
        for interface in interfaces_to_check:
            if hasattr(ak, interface):
                available_interfaces.append(interface)
                if self.debug_mode:
                    print(f"   âœ“ {interface}")
            else:
                if self.debug_mode:
                    print(f"   âœ— {interface}")
        
        self.available_akshare_interfaces = available_interfaces
        if self.debug_mode:
            print(f"âœ… å¯ç”¨æ¥å£: {len(available_interfaces)}ä¸ª")

    def _safe_float(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•° - å¢å¼ºç‰ˆ"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return 0.0
            if isinstance(val, str):
                # å¤„ç†ç™¾åˆ†æ¯”
                if '%' in val:
                    return float(val.replace('%', '').strip())
                # å¤„ç†ä¸­æ–‡æ•°å€¼å•ä½
                val = val.strip().replace(',', '')  # ç§»é™¤åƒåˆ†ä½é€—å·
                if val.lower() in ['--', 'null', 'nan', 'none']:
                    return 0.0
        
            result = float(val)
            
            # æ·»åŠ å¼‚å¸¸å€¼æ£€æŸ¥
            if result > 1000000:  # è¶…è¿‡100ä¸‡çš„PEå€¼è§†ä¸ºå¼‚å¸¸
                print(f"      âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸PEå€¼: {result}, å·²ä¿®æ­£ä¸º0")
                return 0.0
            if result < 0:  # è´ŸPEå€¼å¤„ç†
                return 0.0
                
            return result
        except (ValueError, TypeError) as e:
            if hasattr(self, 'debug_mode') and self.debug_mode:
                print(f"      âš ï¸ æ•°å€¼è½¬æ¢è­¦å‘Š: '{val}' -> 0.0 ({str(e)})")
            return 0.0
    
    def _safe_int(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•° - å¢å¼ºç‰ˆ"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return 0
            if isinstance(val, str):
                val = val.strip().replace(',', '')
                if val.lower() in ['--', 'null', 'nan', 'none']:
                    return 0
            return int(float(val))  # å…ˆè½¬floatå†è½¬inté¿å…ç²¾åº¦é—®é¢˜
        except (ValueError, TypeError):
            return 0

    def refresh_ut(self):
        """è‡ªåŠ¨åˆ·æ–° ut å‚æ•° (è¿˜åŸ)"""
        print("ğŸ”„ æ­£åœ¨åˆ·æ–° ut å‚æ•°...")
        try:
            url = "https://quote.eastmoney.com/center/gridlist.html"
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/121.0 Safari/537.36"}
            response = requests.get(url, headers=headers, timeout=10, verify=False, proxies={"http": None, "https": None})
            total_cash_div = 0.0
            if dividends and market.latest_price:
                for d in dividends:
                    div_str = str(d.dividend)
                    
                    # æ ¼å¼1: "10æ´¾5.2" âœ…
                    match = re.search(r'10æ´¾(\d+\.?\d*)', div_str)
                    if match:
                        total_cash_div += float(match.group(1)) / 10
                        continue
                    
                    # æ ¼å¼2: "æ´¾1.5" âœ…
                    match = re.search(r'æ´¾(\d+\.?\d*)', div_str)
                    if match:
                        total_cash_div += float(match.group(1)) / 10
                
                if total_cash_div > 0:
                    div_yield = float((total_cash_div / market.latest_price) * 100)
                    print(f"      âœ“ è‚¡æ¯ç‡: {div_yield:.2f}% (å¹´åº¦åˆ†çº¢: {total_cash_div:.2f}å…ƒ/è‚¡)")
                return True
        except Exception as e:
            print("âŒ åˆ·æ–° ut å¤±è´¥:", e)
            return False

    # --- æ ¸å¿ƒæŠ“å–é€»è¾‘ (å®Œå…¨è¿˜åŸä½ æä¾›çš„ä»£ç ) ---

    async def fetch_em_data_via_web_api(self, page_size: int = 100) -> pd.DataFrame:
        """å¢å¼ºç‰ˆæ•°æ®æŠ“å– - åŒé‡ä¿éšœ (Akshareå®˜æ–¹æ¥å£ + æç®€é˜²å±è”½ç›´è¿)"""
        print(f"\nğŸŒ å¯åŠ¨å…¨å¸‚åœºè¡Œæƒ…æŠ“å–...")

        # ğŸ† æ–¹æ¡ˆ A: ä¼˜å…ˆä½¿ç”¨å¼€æºç¤¾åŒºæŒç»­æ›´æ–°çš„ Akshare æ¥å£ (æœ€ç¨³å®šã€æœ€æŠ—å°)
        try:
            print("   â¤ å°è¯•ä½¿ç”¨ Akshare å®˜æ–¹é€šé“è·å–æ•°æ®...")
            # è°ƒç”¨ akshare çš„ä¸œæ–¹è´¢å¯Œå®æ—¶è¡Œæƒ…æ¥å£
            df = await asyncio.to_thread(ak.stock_zh_a_spot_em)
            if df is not None and not df.empty:
                print("   âœ“ Akshare é€šé“è·å–æˆåŠŸï¼")
                
                # æ˜ å°„ akshare çš„ä¸­æ–‡åˆ—ååˆ°æ•°æ®åº“è‹±æ–‡å­—æ®µ
                ak_map = {
                    'ä»£ç ': 'code',
                    'åç§°': 'name',
                    'æœ€æ–°ä»·': 'latest_price',
                    'æ¶¨è·Œå¹…': 'change_pct',
                    'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe_dynamic',
                    'å¸‚å‡€ç‡': 'pb',
                    'æˆäº¤é‡': 'volume',
                    'æˆäº¤é¢': 'amount'
                }
                df = df.rename(columns=ak_map)
                
                # æ¸…æ´—å¯èƒ½çš„éæ•°å€¼ (æŠŠ '-' æˆ– 'NaN' è½¬ä¸º 0)
                for col in ['latest_price', 'change_pct', 'pe_dynamic', 'pb', 'volume', 'amount']:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                        
                print(f"âœ… æ€»è®¡è·å– {len(df)} æ¡æ•°æ®")
                return df
                
        except Exception as e:
            print(f"   âš ï¸ Akshare é€šé“å¤±è´¥: {str(e)[:100]}")
            print("   ğŸ”„ è‡ªåŠ¨åˆ‡æ¢è‡³çº¯å‡€å¤‡ç”¨é€šé“...")

        # ğŸ›¡ï¸ æ–¹æ¡ˆ B: æç®€çº¯å‡€ HTTP ç›´è¿ 
        # (å»æ‰å¤æ‚çš„å‡Cookieï¼Œä»…ä¿ç•™æœ€æ ¸å¿ƒçš„æµè§ˆå™¨å¤´éƒ¨ï¼Œé˜²æ­¢ç”»è›‡æ·»è¶³è¢«æ‹¦æˆª)
        print("   â¤ å¯ç”¨åŸç”Ÿæç®€ HTTP ç€‘å¸ƒæµæŠ“å–...")
        all_dfs = []
        current_page = 1
        total_pages = 999
        url = "https://push2.eastmoney.com/api/qt/clist/get"

        headers = {
            "Host": "push2.eastmoney.com",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Referer": "https://quote.eastmoney.com/",
            "Connection": "keep-alive"
        }

        # æ„å»ºä¸€ä¸ªå¸¦é‡è¯•æœºåˆ¶çš„çº¯å‡€ Session
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        session = requests.Session()
        retry = Retry(total=3, backoff_factor=1, status_forcelist=[403, 429, 500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retry)
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        session.headers.update(headers)

        while current_page <= total_pages:
            cb_name = f"jQuery3410{random.randint(100000, 999999)}_{int(time.time()*1000)}"
            params = {
                "cb": cb_name,
                "pn": str(current_page),
                "np": "1",
                "ut": "bd1d9ddb04089700cf9c27f6f7426281",
                "fltt": "2",
                "invt": "2",
                "fs": "m:0+t:6+f:!2,m:0+t:13+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:81+s:2048",
                "fields": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f23,f24,f25,f22,f11,f62,f111,f128,f136,f115,f148,f152",
                "wbp2u": "|0|0|0|wap",
                "fid": "f3",
                "po": "1",
                "pz": str(page_size),
                "_": str(int(time.time() * 1000))
            }

            try:
                print(f"   â¤ æŠ“å–ç¬¬ {current_page}/{total_pages if total_pages != 999 else '?'} é¡µ...")
                response = await asyncio.to_thread(session.get, url, params=params, timeout=15, verify=False)
                
                if response.status_code != 200: break
                match = re.search(r'jQuery.*?\((.*)\)', response.text)
                if not match: break

                res_json = json.loads(match.group(1))
                if not res_json or not res_json.get("data"): break

                # ç¬¬ä¸€é¡µè·å–æ€»é¡µæ•°
                if current_page == 1:
                    total_pages = (res_json["data"]["total"] + page_size - 1) // page_size

                batch_df = pd.DataFrame(res_json["data"]["diff"])
                all_dfs.append(batch_df)

                if current_page >= total_pages: break
                
                # å¤‡ç”¨æ–¹æ¡ˆç¨å¾®çŸ­ä¸€ç‚¹çš„ç­‰å¾…æ—¶é—´
                wait_time = random.uniform(2.5, 6.0)
                await asyncio.sleep(wait_time)
                current_page += 1

            except Exception as e:
                print(f"   âŒ å¤‡ç”¨é€šé“æŠ¥é”™åœæ­¢: {str(e)[:50]}")
                break

        session.close()
        if not all_dfs: return pd.DataFrame()

        final_df = pd.concat(all_dfs, ignore_index=True)
        em_fields_map = {
            'f12': 'code', 'f14': 'name', 'f2': 'latest_price', 
            'f3': 'change_pct', 'f9': 'pe_dynamic', 'f22': 'pb', 
            'f5': 'volume', 'f6': 'amount'
        }
        rename_map = {k: v for k, v in em_fields_map.items() if k in final_df.columns}
        final_df = final_df.rename(columns=rename_map)
        
        print(f"\nâœ… å¤‡ç”¨é€šé“è·å– {len(final_df)} æ¡æ•°æ®")
        return final_df

    async def fetch_daily_market_data(self, force: bool = False):
        """å…¥åº“é€»è¾‘æ•´åˆ"""
        db = SessionLocal()
        today = datetime.date.today()
        
        if not force and db.query(DailyMarketData).filter(DailyMarketData.date == today).first():
            db.close()
            return {"status": "skip", "message": "ä»Šæ—¥æ•°æ®å·²å­˜åœ¨"}

        df = await self.fetch_em_data_via_web_api()
        if df.empty:
            db.close()
            return {"status": "error", "message": "æŠ“å–æ•°æ®ä¸ºç©º"}

        # åˆ é™¤æ—§æ•°æ®å¹¶å…¥åº“
        db.query(DailyMarketData).filter(DailyMarketData.date == today).delete()
        
        batch = []
        for _, row in df.iterrows():
            m = DailyMarketData(
                date=today,
                code=str(row.get('code', '')),
                name=str(row.get('name', '')),
                latest_price=self._safe_float(row.get('latest_price')),
                change_pct=self._safe_float(row.get('change_pct')),
                pe_dynamic=self._safe_float(row.get('pe_dynamic')),
                pb=self._safe_float(row.get('pb')),
                volume=self._safe_float(row.get('volume')),
                amount=self._safe_float(row.get('amount')),
                updated_at=datetime.datetime.now()
            )
            batch.append(m)
        
        db.bulk_save_objects(batch)
        db.commit()
        db.close()
        return {"status": "success", "count": len(batch)}
   
    async def fetch_dividend_data(self, stock_code: str = None):
        """åŒæ­¥åˆ†çº¢æ•°æ® (åŸºäºAkshare)"""
        db = SessionLocal()
        try:
            # æ­¤å¤„ç¤ºä¾‹ä¸ºè·å–æœ€æ–°åˆ†çº¢å…¬å‘Šï¼Œå®é™…ç”Ÿäº§ç¯å¢ƒå»ºè®®å®šæ—¶åŒæ­¥å…¨é‡
            df = ak.news_trade_notify_dividend_baidu(date=datetime.date.today().strftime('%Y%m%d'))
            if df.empty: return
            
            for _, row in df.iterrows():
                div = DividendData(
                    stock_code=row['è‚¡ç¥¨ä»£ç '],
                    stock_name=row['è‚¡ç¥¨ç®€ç§°'],
                    ex_dividend_date=pd.to_datetime(row['é™¤æƒæ—¥']).date(),
                    dividend=row['åˆ†çº¢'],
                    report_period=row['æŠ¥å‘ŠæœŸ']
                )
                db.merge(div)
            db.commit()
        except: pass
        finally: db.close()

    async def _request_with_retry(self, url, params, max_retries=3):
        """å¢å¼ºç‰ˆé‡è¯•è¯·æ±‚åŒ…è£…å™¨"""
        for i in range(max_retries):
            try:
                # åœ¨çº¿ç¨‹ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
                response = await asyncio.to_thread(
                    self.session.get, url, params=params, timeout=15, verify=False
                )
                if response.status_code == 200:
                    return response.json()
            except (requests.exceptions.ConnectionError, requests.exceptions.ChunkedEncodingError, requests.exceptions.RemoteDisconnected) as e:
                wait_time = (i + 1) * 3  # å¢åŠ ç­‰å¾…æ—¶é—´
                if i < max_retries - 1:
                    print(f"      âš ï¸ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... ({i+1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                    continue
                raise e
            except requests.exceptions.Timeout as e:
                if i < max_retries - 1:
                    print(f"      âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­... ({i+1}/{max_retries})")
                    continue
                raise e
        return None
    
    async def fetch_historical_data(self, stock_code: str):
        """åŒæ­¥å†å²Kçº¿ - å¢å¼ºç‰ˆ(ç½‘ç»œç¨³å®šæ€§ä¼˜åŒ–)"""
        # é¦–å…ˆæ£€æŸ¥æœ¬åœ°æ•°æ®
        db = SessionLocal()
        try:
            existing_count = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).count()
            
            # ä¼˜åŒ–ï¼šå¦‚æœå·²æœ‰è¶³å¤Ÿæ•°æ®ï¼ˆæ¯”å¦‚100æ¡ä»¥ä¸Šï¼‰ï¼Œå°±ä¸é‡å¤è·å–
            if existing_count >= 100:
                if self.debug_mode:
                    print(f"      â„¹ï¸ å·²æœ‰{existing_count}æ¡Kçº¿æ•°æ®ï¼Œè·³è¿‡è·å–")
                return True
        finally:
            db.close()
        
        try:
            market = "1" if stock_code.startswith(('6', '9', '11')) else "0"
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                "cb": f"jQuery_{int(time.time()*1000)}",
                "secid": f"{market}.{stock_code}",
                "ut": self.target_ut,
                "fields1": "f1,f2,f3,f4,f5,f6",
                "fields2": "f51,f52,f53,f54,f55,f56",
                "klt": "101", "fqt": "1", "beg": "0", "end": "20500101", 
                "lmt": "120", "_": str(int(time.time() * 1000))
            }
            
            # ä½¿ç”¨å¢å¼ºçš„ä¼šè¯å’Œé‡è¯•æœºåˆ¶
            response = await asyncio.to_thread(
                self._robust_request, url, params, timeout=20
            )
            
            if response and response.status_code == 200:
                match = re.search(r'\(({.*})\)', response.text)
                if match:
                    res = json.loads(match.group(1))
                    klines = res.get("data", {}).get("klines", [])
                    if klines:
                        db = SessionLocal()
                        try:
                            # åªä¿ç•™æœ€æ–°çš„120æ¡æ•°æ®ï¼Œé¿å…æ•°æ®è†¨èƒ€
                            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
                            saved_count = 0
                            for line in klines:
                                cols = line.split(',')
                                if len(cols) >= 5:  # ç¡®ä¿æ•°æ®å®Œæ•´
                                    h = HistoricalData(
                                        stock_code=stock_code,
                                        date=datetime.datetime.strptime(cols[0], "%Y-%m-%d").date(),
                                        open=self._safe_float(cols[1]), 
                                        close=self._safe_float(cols[2]),
                                        high=self._safe_float(cols[3]), 
                                        low=self._safe_float(cols[4])
                                    )
                                    db.add(h)
                                    saved_count += 1
                            db.commit()
                            if self.debug_mode:
                                print(f"      âœ“ Kçº¿æ•°æ®è·å–æˆåŠŸ ({saved_count}æ¡)")
                            return True
                        except Exception as e:
                            if self.debug_mode:
                                print(f"      âš ï¸ Kçº¿æ•°æ®ä¿å­˜å¼‚å¸¸: {str(e)[:50]}")
                            db.rollback()
                        finally:
                            db.close()
            
            if self.debug_mode:
                print(f"      âš ï¸ Kçº¿è·å–å¤±è´¥ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®")
            return True
            
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ Kçº¿è·å–å¼‚å¸¸: {str(e)[:100]}")
            return True

    def _robust_request(self, url, params, timeout=20):
        """å¢å¼ºç‰ˆHTTPè¯·æ±‚ - é‡åˆ°403/429è‡ªåŠ¨é‡è¯•ä¸åçˆ¬ä¼‘çœ """
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # åŠ¨æ€è¿½åŠ é˜²çˆ¬å¤´éƒ¨
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/122.0.0.0 Safari/537.36",
                    "Referer": "https://quote.eastmoney.com/"
                }
                response = self.session.get(url, params=params, headers=headers, timeout=timeout, verify=False)
                
                if response.status_code == 200:
                    return response
                elif response.status_code in [403, 429]:
                    if getattr(self, 'debug_mode', False):
                        print(f"      âš ï¸ è¢«åçˆ¬æ‹¦æˆª (HTTP {response.status_code})ï¼Œä¼‘çœ ä¼ªè£…ä¸­...")
                    time.sleep(random.uniform(5, 12))
                    continue
                elif response.status_code in [500, 502, 503, 504]:
                    time.sleep((attempt + 1) * 2)
                    continue
                else:
                    return None
            except requests.exceptions.RequestException as e:
                time.sleep((attempt + 1) * 3)
                continue
        return None
        
    async def _fetch_kline_local(self, stock_code: str):
        """æœ¬åœ°æ•°æ®è¡¥å……æ–¹æ¡ˆ"""
        db = SessionLocal()
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰éƒ¨åˆ†æ•°æ®
            existing_count = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).count()
            
            if existing_count > 0:
                print(f"      â„¹ï¸ ä½¿ç”¨ç°æœ‰{existing_count}æ¡Kçº¿æ•°æ®")
                return True
            
            # å¦‚æœå®Œå…¨æ²¡æœ‰æ•°æ®ï¼Œç”ŸæˆåŸºç¡€æ•°æ®ç”¨äºåˆ†æ
            market_data = db.query(DailyMarketData).filter(
                DailyMarketData.code == stock_code
            ).first()
            
            if market_data and market_data.latest_price:
                # ç”Ÿæˆä¸€æ¡åŸºç¡€Kçº¿æ•°æ®
                fake_kline = HistoricalData(
                    stock_code=stock_code,
                    date=datetime.date.today(),
                    open=market_data.latest_price,
                    close=market_data.latest_price,
                    high=market_data.latest_price * 1.02,
                    low=market_data.latest_price * 0.98
                )
                db.add(fake_kline)
                db.commit()
                print(f"      â„¹ï¸ ç”ŸæˆåŸºç¡€Kçº¿æ•°æ®ç”¨äºåˆ†æ")
                return True
                
        except Exception as e:
            print(f"      âš ï¸ æœ¬åœ°æ•°æ®è¡¥å……å¤±è´¥: {str(e)[:50]}")
        finally:
            db.close()
        
        return False
    
    async def _save_kline_data(self, stock_code: str, df):
        """ä¿å­˜Kçº¿æ•°æ®çš„é€šç”¨æ–¹æ³•"""
        db = SessionLocal()
        try:
            # æ¸…ç†æ—§æ•°æ®
            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
            
            # ä¿å­˜æ–°æ•°æ®
            for _, row in df.iterrows():
                h = HistoricalData(
                    stock_code=stock_code,
                    date=pd.to_datetime(row['date'] if 'date' in row else row.index).date(),
                    open=self._safe_float(row.get('open', 0)),
                    close=self._safe_float(row.get('close', 0)),
                    high=self._safe_float(row.get('high', 0)),
                    low=self._safe_float(row.get('low', 0))
                )
                db.add(h)
            
            db.commit()
        finally:
            db.close()

    async def fetch_stock_dividend_history(self, stock_code: str):
        """åŒæ­¥å†å²åˆ†çº¢è®°å½•"""
        db = SessionLocal()
        try:
            df = await asyncio.to_thread(ak.stock_history_dividend_detail, symbol=stock_code, indicator="åˆ†çº¢")  # æ·»åŠ  indicator å‚æ•°
            if df is None or df.empty: return
            
            for _, row in df.iterrows():
                ex_date_raw = row.get('é™¤æƒé™¤æ¯æ—¥')
                if pd.isna(ex_date_raw) or str(ex_date_raw) in ['NaT', 'nan', '']: continue
                
                ex_date = pd.to_datetime(ex_date_raw).date()
                div_val = row.get('æ´¾æ¯(æ¯10è‚¡æ´¾,ç¨å‰)', 0)
                if not div_val: continue
                
                div = DividendData(
                    stock_code=stock_code,
                    stock_name=row.get('åç§°', 'æœªçŸ¥'),
                    ex_dividend_date=ex_date,
                    dividend=f"10æ´¾{div_val}",
                    report_period=str(row.get('åˆ†çº¢å¹´åº¦', ''))
                )
                db.merge(div)
            db.commit()
        except Exception as e:
            print(f"   âš ï¸ {stock_code} åˆ†çº¢æŠ“å–å¤±è´¥: {e}")
        finally:
            db.close()

    async def fetch_financial_metrics(self, stock_code: str):
        """è·å–è´¢åŠ¡æŒ‡æ ‡ - ä¿®å¤ç‰ˆ"""
        # ç¼“å­˜æ£€æŸ¥
        cache_key = f"financial_{stock_code}"
        if cache_key in self.financial_cache:
            if time.time() < self.cache_expiry[cache_key]:
                cached_data = self.financial_cache[cache_key]
                if self.debug_mode:
                    print(f"      â„¹ï¸ ä½¿ç”¨ç¼“å­˜è´¢åŠ¡æ•°æ®: ROE={cached_data[0]:.2f}%, Growth={cached_data[1]:.2f}%")
                return cached_data
        
        roe, growth = 0.0, 0.0
        attempts = []
        success_source = "none"
        
        try:
            # 1. é¦–é€‰ï¼šefinance è´¢åŠ¡æ•°æ®
            attempts.append("efinance")
            df = await asyncio.to_thread(ef.stock.get_base_info, stock_code)
            
            if df is not None and not df.empty:
                # ç»Ÿä¸€æ•°æ®æ ¼å¼å¤„ç†
                if isinstance(df, pd.DataFrame):
                    if len(df) > 0:
                        data = df.iloc[0].to_dict()
                    else:
                        data = {}
                elif isinstance(df, pd.Series):
                    data = df.to_dict()
                else:
                    data = {}
                
                # å¤šç§å­—æ®µååŒ¹é…
                roe_fields = ['å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'ROE(%)', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'roe', 'ROE']
                growth_fields = ['å‡€åˆ©æ¶¦åŒæ¯”(%)', 'å‡€åˆ©æ¶¦å¢é•¿ç‡(%)', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿', 'net_profit_growth', 'profit_growth']
                
                # æå– ROE
                for field in roe_fields:
                    if field in data and data[field] is not None:
                        roe_val = self._safe_float(data[field])
                        if roe_val != 0:
                            roe = roe_val
                            break
                
                # æå–åˆ©æ¶¦å¢é•¿ç‡
                for field in growth_fields:
                    if field in data and data[field] is not None:
                        growth_val = self._safe_float(data[field])
                        if growth_val != 0:
                            growth = growth_val
                            break
                
                if roe != 0 or growth != 0:
                    if self.debug_mode:
                        print(f"      âœ“ é€šè¿‡ efinance è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "efinance"
                    # ç¼“å­˜ç»“æœ
                    self.financial_cache[cache_key] = (float(roe), float(growth))
                    self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                    return float(roe), float(growth)
                    
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ efinance å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 2. å¤‡é€‰ï¼šakshare è´¢åŠ¡æŠ¥è¡¨ (ä¿®å¤æ¥å£è°ƒç”¨)
            attempts.append("akshare_financial")
            formatted_code = self._format_stock_code_for_akshare(stock_code)
            
            # ä½¿ç”¨æ­£ç¡®çš„akshareæ¥å£
            try:
                df_fin = await asyncio.to_thread(ak.stock_financial_abstract_ths, symbol=stock_code)
            except AttributeError:
                # å¦‚æœä¸Šé¢æ¥å£ä¸å­˜åœ¨ï¼Œå°è¯•å…¶ä»–æ¥å£
                try:
                    df_fin = await asyncio.to_thread(ak.stock_financial_report_sina, symbol=formatted_code)
                except:
                    df_fin = None
            
            if df_fin is not None and not df_fin.empty and len(df_fin) > 0:
                data_fin = df_fin.iloc[0].to_dict()
                
                # akshare å­—æ®µå
                roe = self._safe_float(data_fin.get('å‡€èµ„äº§æ”¶ç›Šç‡') or 
                                    data_fin.get('ROE') or 
                                    data_fin.get('å‡€èµ„äº§æ”¶ç›Šç‡(%)') or 0)
                growth = self._safe_float(data_fin.get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿') or 
                                        data_fin.get('å‡€åˆ©æ¶¦å¢é•¿ç‡') or 
                                        data_fin.get('å‡€åˆ©æ¶¦åŒæ¯”(%)') or 0)
                
                if roe != 0 or growth != 0:
                    if self.debug_mode:
                        print(f"      âœ“ é€šè¿‡ akshare è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "akshare_financial"
                    self.financial_cache[cache_key] = (float(roe), float(growth))
                    self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                    return float(roe), float(growth)
                    
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ akshare financial å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 3. å†å¤‡é€‰ï¼šakshare ä¸»è¦æŒ‡æ ‡ (ä¿®å¤æ¥å£åç§°)
            attempts.append("akshare_indicator")
            formatted_code = self._format_stock_code_for_akshare(stock_code)
            
            # å°è¯•å¤šç§akshareæŒ‡æ ‡æ¥å£
            df_ind = None
            indicator_functions = [
                'stock_a_indicator_lg',  # æ­£ç¡®çš„æ¥å£å
                'stock_a_lg_indicator',  # å¤‡é€‰æ¥å£å
                'stock_individual_info', # å…¶ä»–å¯èƒ½çš„æ¥å£
            ]
            
            for func_name in indicator_functions:
                try:
                    if hasattr(ak, func_name):
                        df_ind = await asyncio.to_thread(getattr(ak, func_name), symbol=stock_code)
                        if df_ind is not None and not df_ind.empty:
                            break
                except:
                    continue
            
            if df_ind is not None and not df_ind.empty and len(df_ind) > 0:
                data_ind = df_ind.iloc[0].to_dict()
                
                # æŒ‡æ ‡å­—æ®µååŒ¹é…
                roe_fields = ['å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'ROE', 'roe', 'å‡€èµ„äº§æ”¶ç›Šç‡']
                growth_fields = ['å‡€åˆ©æ¶¦åŒæ¯”(%)', 'å‡€åˆ©æ¶¦å¢é•¿ç‡(%)', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿']
                
                for field in roe_fields:
                    if field in data_ind and data_ind[field] is not None:
                        roe_val = self._safe_float(data_ind[field])
                        if roe_val != 0:
                            roe = roe_val
                            break
                
                for field in growth_fields:
                    if field in data_ind and data_ind[field] is not None:
                        growth_val = self._safe_float(data_ind[field])
                        if growth_val != 0:
                            growth = growth_val
                            break
                
                if roe != 0 or growth != 0:
                    if self.debug_mode:
                        print(f"      âœ“ é€šè¿‡ akshare æŒ‡æ ‡è·å–: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "akshare_indicator"
                    self.financial_cache[cache_key] = (float(roe), float(growth))
                    self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                    return float(roe), float(growth)
                    
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ akshare indicator å¤±è´¥: {str(e)[:50]}")
        
        # 4. æœ€åå¤‡é€‰ï¼šä»å¸‚åœºä»·æ ¼æ•°æ®æ¨ç®—
        try:
            attempts.append("market_derived")
            derived_roe, derived_growth = await self._derive_financial_from_market(stock_code)
            if derived_roe != 0 or derived_growth != 0:
                if self.debug_mode:
                    print(f"      âœ“ é€šè¿‡å¸‚åœºæ•°æ®æ¨ç®—: ROE={derived_roe:.2f}%, Growth={derived_growth:.2f}%")
                success_source = "market_derived"
                self.financial_cache[cache_key] = (float(derived_roe), float(derived_growth))
                self.cache_expiry[cache_key] = time.time() + self.CACHE_TTL
                return float(derived_roe), float(derived_growth)
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ å¸‚åœºæ•°æ®æ¨ç®—å¤±è´¥: {str(e)[:50]}")
        
        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if roe == 0 and growth == 0:
            if self.debug_mode:
                print(f"      âŒ {stock_code} è´¢åŠ¡æŒ‡æ ‡è·å–å®Œå…¨å¤±è´¥ (å°è¯•äº†: {', '.join(attempts)})")
        
        return float(roe), float(growth)
    
    def _format_stock_code_for_akshare(self, stock_code: str) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä»¥é€‚é… akshare æ¥å£"""
        if stock_code.startswith(('6', '9')):
            return f"sh{stock_code}"
        elif stock_code.startswith(('0', '3')):
            return f"sz{stock_code}"
        return stock_code
    
    async def _derive_financial_from_market(self, stock_code: str):
        """ä»å¸‚åœºä»·æ ¼æ•°æ®æ¨ç®—åŸºç¡€è´¢åŠ¡æŒ‡æ ‡ - å¢å¼ºç‰ˆ"""
        db = SessionLocal()
        try:
            # è·å–å†å²ä»·æ ¼æ•°æ®æ¨ç®—è¶‹åŠ¿
            hist_data = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).order_by(HistoricalData.date.desc()).limit(252).all()  # ä¸€å¹´æ•°æ®
            
            if len(hist_data) < 30:  # æ•°æ®ä¸è¶³
                return 0.0, 0.0
            
            # è®¡ç®—ä»·æ ¼å¢é•¿ç‡ä½œä¸ºç²—ç•¥çš„æˆé•¿æ€§æŒ‡æ ‡
            prices = [float(h.close) for h in reversed(hist_data)]
            if len(prices) >= 2:
                # å¹´åº¦å¢é•¿ç‡ä¼°ç®—
                annual_growth = ((prices[-1] / prices[0]) ** (252/len(prices)) - 1) * 100
                derived_growth = max(-50, min(50, annual_growth))  # é™åˆ¶èŒƒå›´
            else:
                derived_growth = 0.0
            
            # ROE ç²—ç•¥ä¼°ç®— (å‡è®¾åˆç†çš„èŒƒå›´)
            # å¯¹äºç§‘åˆ›æ¿è‚¡ç¥¨(688å¼€å¤´)ï¼Œä½¿ç”¨ä¸åŒçš„ä¼°ç®—é€»è¾‘
            if stock_code.startswith('688'):
                derived_roe = max(0, min(30, abs(derived_growth) * 0.6))  # ç§‘åˆ›æ¿ä¼°å€¼æ›´é«˜
            else:
                derived_roe = max(0, min(30, abs(derived_growth) * 0.8))  # ä¼ ç»Ÿè‚¡ç¥¨
            
            if self.debug_mode:
                print(f"      â„¹ï¸ å¸‚åœºæ•°æ®æ¨ç®—: ROEâ‰ˆ{derived_roe:.2f}%, Growthâ‰ˆ{derived_growth:.2f}% (åŸºäº{len(prices)}å¤©æ•°æ®)")
            
            return float(derived_roe), float(derived_growth)
            
        except Exception as e:
            if self.debug_mode:
                print(f"      âš ï¸ å¸‚åœºæ•°æ®æ¨ç®—å¼‚å¸¸: {str(e)[:50]}")
            return 0.0, 0.0
        finally:
            db.close()

    def _assess_data_quality(self, roe: float, growth: float, source: str) -> float:
        """è¯„ä¼°æ•°æ®è´¨é‡ (0-1)"""
        quality = 0.0
        
        # æ¥æºæƒé‡
        source_weights = {
            "efinance": 1.0,
            "akshare_financial": 0.8,
            "akshare_indicator": 0.6,
            "market_derived": 0.3
        }
        quality += source_weights.get(source, 0.1)
        
        # æ•°å€¼åˆç†æ€§æ£€æŸ¥
        if -50 <= roe <= 50:  # ROEåˆç†èŒƒå›´
            quality += 0.3
        if -100 <= growth <= 200:  # å¢é•¿ç‡åˆç†èŒƒå›´
            quality += 0.3
            
        # éé›¶å€¼åŠ åˆ†
        if roe != 0:
            quality += 0.2
        if growth != 0:
            quality += 0.2
            
        return min(1.0, quality)

    

    async def analyze_all_watched_stocks(self):
        """ä¸»åˆ†æä»»åŠ¡å¾ªç¯ - ä¿®å¤ç‰ˆ"""
        db = SessionLocal()
        stats = {
            "success": 0, 
            "failed": 0, 
            "financial_failed": 0,
            "network_errors": 0,
            "data_errors": 0,
            "timeout_errors": 0,
            "total_processed": 0  # æ”¹åä¸ºtotal_processedé¿å…æ··æ·†
        }
        semaphore = asyncio.Semaphore(self.settings.CONCURRENT_LIMIT)
        
        try:
            # è·å–å…³æ³¨è‚¡ç¥¨åˆ—è¡¨
            watched_raw = db.query(UserStockWatch.stock_code).distinct().all()
            watched_codes = list(set([w[0] for w in watched_raw if w[0] and len(w[0]) == 6 and w[0].isdigit()]))
            total = len(watched_codes)
            
            print(f"ğŸš€ å¯åŠ¨æ·±åº¦åˆ†æ (å…± {total} åª)...")
            print(f"ğŸ“Š é…ç½®: å¹¶å‘æ•°{self.settings.CONCURRENT_LIMIT}, è¶…æ—¶{self.settings.FINANCIAL_FETCH_TIMEOUT}s")
            
            # è·å–é«˜ä¼˜å…ˆçº§è‚¡ç¥¨
            priority_stocks = await self._get_priority_stocks(db, [(code,) for code in watched_codes])
            print(f"ğŸ¯ ä¼˜å…ˆå¤„ç† {len(priority_stocks)} åªé‡è¦è‚¡ç¥¨...")
            
            # è®°å½•å·²å¤„ç†çš„è‚¡ç¥¨
            processed_stocks = set()
            tasks = []
            
            async def process_stock(stock_index, stock_code):
                # é˜²æ­¢é‡å¤å¤„ç†
                if stock_code in processed_stocks:
                    return
                processed_stocks.add(stock_code)
                
                async with semaphore:
                    try:
                        stats["total_processed"] += 1
                        current_index = stats["total_processed"]
                        
                        # æ™ºèƒ½è·³è¿‡Kçº¿å¤±è´¥çš„è‚¡ç¥¨
                        kline_success = await self.fetch_historical_data(stock_code)
                        if not kline_success and self.debug_mode:
                            print(f"      âš ï¸ Kçº¿è·å–å¤±è´¥ï¼Œä½†ä»ç»§ç»­åˆ†æ...")
                        
                        await self.fetch_stock_dividend_history(stock_code)
                        score = await self.analyze_stock(stock_code, db)
                        
                        if score is not None:
                            stats["success"] += 1
                            # ä¿®å¤æˆåŠŸç‡è®¡ç®—
                            success_rate = (stats["success"] / current_index) * 100 if current_index > 0 else 0
                            print(f"   âœ“ {current_index}/{total} {stock_code} åˆ†æå®Œæˆ (è¯„åˆ†: {score}, æˆåŠŸç‡: {success_rate:.1f}%)")
                        else:
                            stats["failed"] += 1
                            success_rate = (stats["success"] / current_index) * 100 if current_index > 0 else 0
                            print(f"   âŒ {current_index}/{total} {stock_code} åˆ†æå¤±è´¥ (æˆåŠŸç‡: {success_rate:.1f}%)")
                        
                    except Exception as e:
                        stats["failed"] += 1
                        stats["total_processed"] += 1
                        current_index = stats["total_processed"]
                        success_rate = (stats["success"] / current_index) * 100 if current_index > 0 else 0
                        error_msg = str(e).lower()
                        
                        if "connection" in error_msg or "disconnected" in error_msg:
                            stats["network_errors"] += 1
                        elif "timeout" in error_msg:
                            stats["timeout_errors"] += 1
                        elif "data" in error_msg or "format" in error_msg:
                            stats["data_errors"] += 1
                        else:
                            stats["financial_failed"] += 1
                        
                        print(f"   âŒ {current_index}/{total} {stock_code} å¤„ç†å¼‚å¸¸: {str(e)[:50]} (æˆåŠŸç‡: {success_rate:.1f}%)")
                    
                    # å»¶è¿Ÿç­–ç•¥
                    delay = random.uniform(
                        self.settings.FETCH_DELAY_MIN, 
                        self.settings.FETCH_DELAY_MAX
                    )
                    
                    # æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
                    remaining = total - current_index
                    eta_minutes = (remaining * delay) / 60 if remaining > 0 else 0
                    print(f"   ğŸ’¤ ç­‰å¾… {delay:.1f} ç§’... (é¢„è®¡å‰©ä½™: {eta_minutes:.1f}åˆ†é’Ÿ)")
                    await asyncio.sleep(delay)
            
            # å¤„ç†æ‰€æœ‰è‚¡ç¥¨
            all_stocks = priority_stocks + [code for code in watched_codes if code not in priority_stocks]
            for i, code in enumerate(all_stocks, 1):
                tasks.append(process_stock(i, code))
                
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # æœ€ç»ˆç»Ÿè®¡
            final_success_rate = (stats["success"] / total) * 100 if total > 0 else 0
            print(f"\nğŸ åˆ†æå®Œæˆ!")
            print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
            print(f"   æ€»æ•°: {total}")
            print(f"   æˆåŠŸ: {stats['success']} ({final_success_rate:.1f}%)")
            print(f"   å¤±è´¥: {stats['failed']}")
            if stats["network_errors"] > 0:
                print(f"   ç½‘ç»œé”™è¯¯: {stats['network_errors']}")
            if stats["timeout_errors"] > 0:
                print(f"   è¶…æ—¶é”™è¯¯: {stats['timeout_errors']}")
            if stats["data_errors"] > 0:
                print(f"   æ•°æ®é”™è¯¯: {stats['data_errors']}")
            if stats["financial_failed"] > 0:
                print(f"   è´¢åŠ¡æ•°æ®å¤±è´¥: {stats['financial_failed']}")
                
        except Exception as e:
            print(f"ğŸš¨ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            db.close()
    
    async def analyze_stock(self, stock_code: str, db: Session):
        """æ·±åº¦åˆ†æå•åªè‚¡ç¥¨ (ä¼˜åŒ–ç‰ˆ 100 åˆ†è¯„åˆ†æœºåˆ¶)"""
        today = datetime.date.today()
        market = db.query(DailyMarketData).filter(DailyMarketData.code == stock_code).order_by(desc(DailyMarketData.date)).first()
        if not market or not market.latest_price: return None

        # 1. è¶‹åŠ¿ä¸æ³¢åŠ¨ç‡ (20åˆ†)
        v30, v60, vol_score = 0.0, 0.0, 0
        ma60 = 0.0
        hist = db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code, HistoricalData.close.isnot(None)).order_by(desc(HistoricalData.date)).limit(100).all()

        if len(hist) >= 20:
            prices = [float(h.close) for h in reversed(hist)]
            price_series = pd.Series(prices)
            log_returns = np.log(price_series / price_series.shift(1)).dropna()
            
            if len(log_returns) >= 30: v30 = log_returns.tail(30).std() * np.sqrt(252) * 100
            if len(log_returns) >= 60:
                v60 = log_returns.tail(60).std() * np.sqrt(252) * 100
                ma60 = price_series.tail(60).mean() 
            
            vol_sub_score = 10 if 0 < v30 < 25 else (7 if v30 < 35 else (4 if v30 < 45 else 0))
            trend_sub_score = 0
            if ma60 > 0:
                latest_p = market.latest_price
                if latest_p > ma60 * 1.05: trend_sub_score = 10     
                elif latest_p >= ma60: trend_sub_score = 7          
                elif latest_p > ma60 * 0.90: trend_sub_score = 3    
            vol_score = vol_sub_score + trend_sub_score

        # 2. è‚¡æ¯ç‡é˜²å®ˆè®¡ç®— (20åˆ†)
        div_yield, div_score = 0.0, 0
        one_year_ago = today - datetime.timedelta(days=365)
        dividends = db.query(DividendData).filter(DividendData.stock_code == stock_code, DividendData.ex_dividend_date >= one_year_ago).all()
        total_cash_div = 0.0
        if dividends:
            for d in dividends:
                match = re.search(r'æ´¾(\d+\.?\d*)', str(d.dividend))
                if match: total_cash_div += float(match.group(1)) / 10
            
            if total_cash_div > 0 and market.latest_price > 0:
                div_yield = (total_cash_div / market.latest_price) * 100
            
            if div_yield >= 4.0: div_score = 20
            elif div_yield >= 2.5: div_score = 15
            elif div_yield >= 1.0: div_score = 10
            elif div_yield > 0: div_score = 5

        # 3. è´¢åŠ¡ä¸ä¼°å€¼ (60åˆ†)
        roe, profit_growth = await self.fetch_financial_metrics(stock_code)
        
        roe_score = 20 if roe >= 20 else (15 if roe >= 15 else (10 if roe >= 10 else (5 if roe >= 5 else 0)))
        pg_score = 20 if profit_growth >= 30 else (15 if profit_growth >= 15 else (10 if profit_growth > 0 else (5 if profit_growth > -10 else 0)))
        
        pe_score = 0
        pe = market.pe_dynamic
        if 0 < pe <= 15: pe_score = 20        
        elif 15 < pe <= 30: pe_score = 15     
        elif 30 < pe <= 50: pe_score = 10     
        elif 50 < pe <= 100: pe_score = 5     
        
        growth_score = roe_score + pg_score + pe_score
        total_score = int(vol_score + div_score + growth_score)
        
        # åŠ¨æ€è¯„çº§
        if total_score >= 80: suggestion = "å¼ºçƒˆæ¨è"
        elif total_score >= 65: suggestion = "æ¨èä¹°å…¥"
        elif total_score >= 50: suggestion = "è§‚æœ›æŒä»“"
        else: suggestion = "è°¨æ…å›é¿"

        analysis_res = StockAnalysisResult(
            stock_code=stock_code, stock_name=market.name, analysis_date=today,
            latest_price=market.latest_price, pe_ratio=market.pe_dynamic, pb_ratio=market.pb,
            volatility_30d=round(v30, 2) if v30 > 0 else 0.0,
            volatility_60d=round(v60, 2) if v60 > 0 else 0.0,
            dividend_yield=round(div_yield, 2) if div_yield > 0 else 0.0,
            roe=round(roe, 2) if roe > 0 else 0.0,
            profit_growth=round(profit_growth, 2) if profit_growth else 0.0,
            volatility_score=int(vol_score), dividend_score=int(div_score), growth_score=int(growth_score),
            total_score=total_score, suggestion=suggestion, data_source="automated_v4" 
        )

        try:
            db.merge(analysis_res)
            db.commit()
            return analysis_res.total_score
        except Exception as e:
            db.rollback()
            print(f"   âŒ {stock_code} ç»“æœå…¥åº“å¤±è´¥: {e}")
            return None

    async def _check_update_needed(self, db: Session, watched_stocks):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°"""
        # æ£€æŸ¥æœ€æ–°åˆ†ææ—¥æœŸ
        latest_analysis = db.query(StockAnalysisResult).order_by(
            desc(StockAnalysisResult.analysis_date)
        ).first()
        
        if not latest_analysis:
            return True
            
        # å¦‚æœä»Šå¤©å·²ç»åˆ†æè¿‡ï¼Œä¸”è‚¡ç¥¨æ•°é‡æ²¡å˜ï¼Œåˆ™ä¸éœ€è¦æ›´æ–°
        today_count = db.query(StockAnalysisResult).filter(
            StockAnalysisResult.analysis_date == datetime.date.today()
        ).count()
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å…³æ³¨çš„è‚¡ç¥¨éƒ½æœ‰ä»Šå¤©çš„åˆ†æç»“æœ
        watched_codes = set([row[0] for row in watched_stocks])
        today_analyzed_codes = set([
            result.stock_code for result in 
            db.query(StockAnalysisResult.stock_code).filter(
                StockAnalysisResult.analysis_date == datetime.date.today()
            ).all()
        ])
        
        return not watched_codes.issubset(today_analyzed_codes)
    
    async def _get_priority_stocks(self, db: Session, all_stocks):
        """è·å–é«˜ä¼˜å…ˆçº§è‚¡ç¥¨ï¼ˆæŒä»“æˆ–é«˜è¯„åˆ†ï¼‰"""
        # è·å–æŒä»“è‚¡ç¥¨
        holdings = db.query(UserStockHolding.stock_code).filter(
            UserStockHolding.is_active == True
        ).distinct().all()
        
        # è·å–é«˜è¯„åˆ†è‚¡ç¥¨ï¼ˆä¸Šæ¬¡è¯„åˆ†>80ï¼‰
        high_score = db.query(StockAnalysisResult.stock_code).filter(
            StockAnalysisResult.total_score > 80
        ).distinct().all()
        
        priority_set = set([h[0] for h in holdings] + [s[0] for s in high_score])
        all_codes = set([row[0] for row in all_stocks])
        
        return list(priority_set.intersection(all_codes))
    
    async def _check_network_health(self):
        """æ£€æŸ¥ç½‘ç»œè¿æ¥å¥åº·åº¦"""
        try:
            response = await asyncio.to_thread(
                requests.get, "https://httpbin.org/get", timeout=5
            )
            return response.status_code == 200
        except:
            return False
    
    async def _adaptive_delay(self, network_healthy: bool):
        """è‡ªé€‚åº”å»¶è¿Ÿè°ƒæ•´"""
        if network_healthy:
            return random.uniform(
                self.settings.FETCH_DELAY_MIN,
                self.settings.FETCH_DELAY_MAX
            )
        else:
            # ç½‘ç»œä¸ä½³æ—¶å¢åŠ å»¶è¿Ÿ
            return random.uniform(
                self.settings.FETCH_DELAY_MAX,
                self.settings.FETCH_DELAY_MAX * 2
            )
    async def clean_abnormal_pe_data(self):
        """æ¸…ç†å¼‚å¸¸çš„PEæ•°æ®"""
        db = SessionLocal()
        try:
            # æŸ¥æ‰¾å¼‚å¸¸PEå€¼çš„è®°å½•
            abnormal_records = db.query(StockAnalysisResult).filter(
                StockAnalysisResult.pe_ratio > 1000000
            ).all()
            
            if abnormal_records:
                print(f"ğŸ” å‘ç° {len(abnormal_records)} æ¡å¼‚å¸¸PEæ•°æ®è®°å½•")
                for record in abnormal_records:
                    print(f"   {record.stock_code} - {record.analysis_date}: PE={record.pe_ratio}")
                    # ä¿®æ­£ä¸º0æˆ–é‡æ–°è®¡ç®—
                    record.pe_ratio = 0.0
                    
                db.commit()
                print("âœ… å¼‚å¸¸PEæ•°æ®å·²æ¸…ç†")
            else:
                print("âœ… æœªå‘ç°å¼‚å¸¸PEæ•°æ®")
                
        except Exception as e:
            print(f"âŒ æ¸…ç†å¼‚å¸¸æ•°æ®å¤±è´¥: {e}")
        finally:
            db.close()

    async def validate_analysis_data(self):
        """éªŒè¯åˆ†ææ•°æ®çš„åˆç†æ€§"""
        db = SessionLocal()
        try:
            # æ£€æŸ¥æœ€è¿‘ä¸€å‘¨çš„åˆ†ææ•°æ®
            one_week_ago = datetime.date.today() - datetime.timedelta(days=7)
            
            suspicious_records = db.query(StockAnalysisResult).filter(
                StockAnalysisResult.analysis_date >= one_week_ago,
                (StockAnalysisResult.pe_ratio > 1000000) | 
                (StockAnalysisResult.pe_ratio < 0) |
                (StockAnalysisResult.total_score > 100) |
                (StockAnalysisResult.total_score < 0)
            ).all()
            
            if suspicious_records:
                print(f"âš ï¸ å‘ç° {len(suspicious_records)} æ¡å¯ç–‘æ•°æ®:")
                for record in suspicious_records:
                    issues = []
                    if record.pe_ratio > 1000000 or record.pe_ratio < 0:
                        issues.append(f"PEå¼‚å¸¸({record.pe_ratio})")
                    if record.total_score > 100 or record.total_score < 0:
                        issues.append(f"è¯„åˆ†å¼‚å¸¸({record.total_score})")
                    
                    print(f"   {record.stock_code} {record.analysis_date}: {', '.join(issues)}")
            else:
                print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
                
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        finally:
            db.close()

stock_service = StockDataService()
