import os
import re
import time
import json
import random
import asyncio
import datetime
import pandas as pd
import numpy as np
import requests
import efinance as ef
import akshare as ak
from sqlalchemy.orm import Session
from sqlalchemy import desc, func

from core.database import SessionLocal
from core.config import settings  # ç¡®ä¿è¿™è¡Œå­˜åœ¨
from models.stock import DailyMarketData, HistoricalData, DividendData, StockAnalysisResult, UserStockWatch
from models.holdings import UserStockHolding  # æ·»åŠ è¿™è¡Œå¯¼å…¥
from crud.stock import save_market_data_batch, save_analysis_result

class StockDataService:
    def __init__(self):
        self.settings = settings
        self.debug_mode = os.getenv('DEBUG_MODE', 'false').lower() == 'true'
        
        # æ·»åŠ ç¼“å­˜å±‚
        self.financial_cache = {}  # è´¢åŠ¡æ•°æ®ç¼“å­˜
        self.cache_expiry = {}     # ç¼“å­˜è¿‡æœŸæ—¶é—´
        self.CACHE_TTL = 3600      # ç¼“å­˜æœ‰æ•ˆæœŸ1å°æ—¶
        
        # è¯·æ±‚ä¼šè¯é…ç½®
        self.session = requests.Session()
        self.session.trust_env = False
        self.session.proxies = {"http": None, "https": None}
        self.headers = {
            # ä½¿ç”¨ä½ URLä¸­æš—ç¤ºçš„ç§»åŠ¨è®¾å¤‡User-Agent
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Referer": "https://quote.eastmoney.com/center/gridlist.html",
            "X-Requested-With": "XMLHttpRequest"  # AJAXè¯·æ±‚æ ‡è¯†
        }
        self.session.headers.update(self.headers)
        
        # ç›®æ ‡å‚æ•° (ä¸œæ–¹è´¢å¯Œ) - ä½¿ç”¨ä½ æä¾›çš„å‚æ•°
        self.target_ut = "bd1d9ddb04089700cf9c27f6f7426281"  # ä½ æä¾›çš„utå€¼
        self.target_cookies = {
            "ut": self.target_ut,
            # å¯ä»¥æ·»åŠ æ›´å¤šcookieå¦‚æœéœ€è¦
        }
        
        # APIå­—æ®µæ˜ å°„ - åŒ¹é…ä½ æä¾›çš„fieldså‚æ•°
        self.em_fields_map = {
            "f12": "code", "f14": "name", "f2": "latest_price", 
            "f3": "change_pct", "f4": "change_amount", "f15": "high",
            "f16": "low", "f17": "open", "f18": "prev_close",
            "f5": "volume", "f6": "amount", "f20": "pe_dynamic",
            "f23": "pb", "f115": "market_cap", "f116": "circulating_market_cap"
        }

    # --- åŸºç¡€å·¥å…·æ–¹æ³• (è¿˜åŸ) ---

    def _safe_float(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•° - å¢å¼ºç‰ˆ"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return 0.0
            if isinstance(val, str):
                # å¤„ç†ç™¾åˆ†æ¯”
                if '%' in val:
                    return float(val.replace('%', '').strip())
                # å¤„ç†ä¸­æ–‡æ•°å€¼å•ä½
                val = val.strip().replace(',', '')  # ç§»é™¤åƒåˆ†ä½é€—å·
                if val.lower() in ['--', 'null', 'nan', 'none']:
                    return 0.0
        
            result = float(val)
            
            # æ·»åŠ å¼‚å¸¸å€¼æ£€æŸ¥
            if result > 1000000:  # è¶…è¿‡100ä¸‡çš„PEå€¼è§†ä¸ºå¼‚å¸¸
                print(f"      âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸PEå€¼: {result}, å·²ä¿®æ­£ä¸º0")
                return 0.0
            if result < 0:  # è´ŸPEå€¼å¤„ç†
                return 0.0
                
            return result
        except (ValueError, TypeError) as e:
            if hasattr(self, 'debug_mode') and self.debug_mode:
                print(f"      âš ï¸ æ•°å€¼è½¬æ¢è­¦å‘Š: '{val}' -> 0.0 ({str(e)})")
            return 0.0
    
    def _safe_int(self, val):
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•° - å¢å¼ºç‰ˆ"""
        try:
            if pd.isna(val) or val == '-' or val is None or val == '':
                return 0
            if isinstance(val, str):
                val = val.strip().replace(',', '')
                if val.lower() in ['--', 'null', 'nan', 'none']:
                    return 0
            return int(float(val))  # å…ˆè½¬floatå†è½¬inté¿å…ç²¾åº¦é—®é¢˜
        except (ValueError, TypeError):
            return 0

    def refresh_ut(self):
        """è‡ªåŠ¨åˆ·æ–° ut å‚æ•° (è¿˜åŸ)"""
        print("ğŸ”„ æ­£åœ¨åˆ·æ–° ut å‚æ•°...")
        try:
            url = "https://quote.eastmoney.com/center/gridlist.html"
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/121.0 Safari/537.36"}
            response = requests.get(url, headers=headers, timeout=10, verify=False, proxies={"http": None, "https": None})
            total_cash_div = 0.0
            if dividends and market.latest_price:
                for d in dividends:
                    div_str = str(d.dividend)
                    
                    # æ ¼å¼1: "10æ´¾5.2" âœ…
                    match = re.search(r'10æ´¾(\d+\.?\d*)', div_str)
                    if match:
                        total_cash_div += float(match.group(1)) / 10
                        continue
                    
                    # æ ¼å¼2: "æ´¾1.5" âœ…
                    match = re.search(r'æ´¾(\d+\.?\d*)', div_str)
                    if match:
                        total_cash_div += float(match.group(1)) / 10
                
                if total_cash_div > 0:
                    div_yield = float((total_cash_div / market.latest_price) * 100)
                    print(f"      âœ“ è‚¡æ¯ç‡: {div_yield:.2f}% (å¹´åº¦åˆ†çº¢: {total_cash_div:.2f}å…ƒ/è‚¡)")
                return True
        except Exception as e:
            print("âŒ åˆ·æ–° ut å¤±è´¥:", e)
            return False

    # --- æ ¸å¿ƒæŠ“å–é€»è¾‘ (å®Œå…¨è¿˜åŸä½ æä¾›çš„ä»£ç ) ---

    async def fetch_em_data_via_web_api(self, page_size: int = 100) -> pd.DataFrame:
        """å¢å¼ºç‰ˆæ•°æ®æŠ“å– - å®Œå…¨åŒ¹é…ä½ æä¾›çš„APIæ ¼å¼"""
        all_dfs = []
        current_page = 1
        total_pages = 999
        url = "https://push2.eastmoney.com/api/qt/clist/get"

        headers = {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Connection": "keep-alive",
            "Referer": "https://quote.eastmoney.com/center/gridlist.html",
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1"
        }

        print(f"\nğŸŒ å¯åŠ¨å¢å¼ºç‰ˆæ•°æ®æŠ“å– (æ¯é¡µ {page_size} æ¡)")
        
        session = requests.Session()
        session.trust_env = False
        session.proxies = {"http": None, "https": None}
        session.cookies.update(self.target_cookies)

        while current_page <= total_pages:
            # å®Œå…¨åŒ¹é…ä½ æä¾›çš„å‚æ•°æ ¼å¼
            params = {
                "cb": f"jQuery341015241163678647807_{int(time.time()*1000)}",
                "pn": str(current_page),
                "np": "1",
                "ut": self.target_ut,
                "fltt": "2",
                "invt": "2",
                "fs": "m:0+t:6+f:!2,m:0+t:13+f:!2,m:0+t:80+f:!2,m:1+t:2+f:!2,m:1+t:23+f:!2,m:0+t:81+s:2048",
                "fields": "f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f19,f20,f21,f23,f24,f25,f22,f11,f62,f111,f128,f136,f115,f148,f152",
                "wbp2u": "|0|0|0|wap",
                "fid": "f3",
                "po": "1",
                "pz": str(page_size),
                "_": str(int(time.time() * 1000))
            }

            try:
                print(f"   â¤ æŠ“å–ç¬¬ {current_page}/{total_pages if total_pages != 999 else '?'} é¡µ...")
                response = await asyncio.to_thread(session.get, url, params=params, headers=headers, timeout=20, verify=False)
                
                if response.status_code != 200: break

                raw_text = response.text
                json_match = re.search(r'jQuery.*?\((.*)\)', raw_text)
                if not json_match: break

                res_json = json.loads(json_match.group(1))
                if not res_json or not res_json.get("data"):
                    if self.refresh_ut():
                        params["ut"] = self.target_ut
                        # é‡è¯•é€»è¾‘...
                        continue
                    else: break

                if current_page == 1:
                    total_records = res_json["data"]["total"]
                    total_pages = (total_records + page_size - 1) // page_size
                    print(f"   ğŸ“Š å…¨å¸‚åœºå…± {total_records} åªè‚¡ç¥¨ï¼Œé¢„è®¡ {total_pages} é¡µ")

                batch_df = pd.DataFrame(res_json["data"]["diff"])
                all_dfs.append(batch_df)

                if current_page >= total_pages: break

                # âœ… è¿˜åŸä½ åŸæ¥çš„é«˜éšæœºç­‰å¾…æ—¶é—´ (10-50ç§’)ï¼Œè¿™æ˜¯ä¸æ‰çº¿çš„å…³é”®
                wait_time = random.uniform(10, 50)
                print(f"   ğŸ’¤ éšæœºç­‰å¾… {wait_time:.1f} ç§’...")
                await asyncio.sleep(wait_time)
                current_page += 1

            except Exception as e:
                print(f"   âŒ ç¬¬ {current_page} é¡µå¤±è´¥: {str(e)[:100]}")
                break

        session.close()
        if not all_dfs: return pd.DataFrame()

        final_df = pd.concat(all_dfs, ignore_index=True)
        final_df = final_df.rename(columns=self.em_fields_map)

        # âœ… è¿˜åŸå­—æ®µå®Œæ•´æ€§ç»Ÿè®¡æ˜¾ç¤º
        print(f"\nâœ… æ€»è®¡è·å– {len(final_df)} æ¡æ•°æ®")
        print(f"\nğŸ“Š å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡:")
        for col in ['code', 'name', 'latest_price', 'pe_dynamic', 'pb']:
            if col in final_df.columns:
                non_null = final_df[col].notna().sum()
                pct = (non_null / len(final_df)) * 100
                print(f"   [{'âœ…' if pct > 90 else 'âš ï¸'}] {col:20s}: {non_null:5d}/{len(final_df)} ({pct:5.1f}%)")

        return final_df


    async def fetch_daily_market_data(self, force: bool = False):
        """å…¥åº“é€»è¾‘æ•´åˆ"""
        db = SessionLocal()
        today = datetime.date.today()
        
        if not force and db.query(DailyMarketData).filter(DailyMarketData.date == today).first():
            db.close()
            return {"status": "skip", "message": "ä»Šæ—¥æ•°æ®å·²å­˜åœ¨"}

        df = await self.fetch_em_data_via_web_api()
        if df.empty:
            db.close()
            return {"status": "error", "message": "æŠ“å–æ•°æ®ä¸ºç©º"}

        # åˆ é™¤æ—§æ•°æ®å¹¶å…¥åº“
        db.query(DailyMarketData).filter(DailyMarketData.date == today).delete()
        
        batch = []
        for _, row in df.iterrows():
            m = DailyMarketData(
                date=today,
                code=str(row.get('code', '')),
                name=str(row.get('name', '')),
                latest_price=self._safe_float(row.get('latest_price')),
                change_pct=self._safe_float(row.get('change_pct')),
                pe_dynamic=self._safe_float(row.get('pe_dynamic')),
                pb=self._safe_float(row.get('pb')),
                volume=self._safe_float(row.get('volume')),
                amount=self._safe_float(row.get('amount')),
                updated_at=datetime.datetime.now()
            )
            batch.append(m)
        
        db.bulk_save_objects(batch)
        db.commit()
        db.close()
        return {"status": "success", "count": len(batch)}
   
    async def fetch_dividend_data(self, stock_code: str = None):
        """åŒæ­¥åˆ†çº¢æ•°æ® (åŸºäºAkshare)"""
        db = SessionLocal()
        try:
            # æ­¤å¤„ç¤ºä¾‹ä¸ºè·å–æœ€æ–°åˆ†çº¢å…¬å‘Šï¼Œå®é™…ç”Ÿäº§ç¯å¢ƒå»ºè®®å®šæ—¶åŒæ­¥å…¨é‡
            df = ak.news_trade_notify_dividend_baidu(date=datetime.date.today().strftime('%Y%m%d'))
            if df.empty: return
            
            for _, row in df.iterrows():
                div = DividendData(
                    stock_code=row['è‚¡ç¥¨ä»£ç '],
                    stock_name=row['è‚¡ç¥¨ç®€ç§°'],
                    ex_dividend_date=pd.to_datetime(row['é™¤æƒæ—¥']).date(),
                    dividend=row['åˆ†çº¢'],
                    report_period=row['æŠ¥å‘ŠæœŸ']
                )
                db.merge(div)
            db.commit()
        except: pass
        finally: db.close()

    async def _request_with_retry(self, url, params, max_retries=3):
        """å¢å¼ºç‰ˆé‡è¯•è¯·æ±‚åŒ…è£…å™¨"""
        for i in range(max_retries):
            try:
                # åœ¨çº¿ç¨‹ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
                response = await asyncio.to_thread(
                    self.session.get, url, params=params, timeout=15, verify=False
                )
                if response.status_code == 200:
                    return response.json()
            except (requests.exceptions.ConnectionError, requests.exceptions.ChunkedEncodingError, requests.exceptions.RemoteDisconnected) as e:
                wait_time = (i + 1) * 3  # å¢åŠ ç­‰å¾…æ—¶é—´
                if i < max_retries - 1:
                    print(f"      âš ï¸ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... ({i+1}/{max_retries})")
                    await asyncio.sleep(wait_time)
                    continue
                raise e
            except requests.exceptions.Timeout as e:
                if i < max_retries - 1:
                    print(f"      âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯•ä¸­... ({i+1}/{max_retries})")
                    continue
                raise e
        return None
    
    async def fetch_historical_data(self, stock_code: str):
        """åŒæ­¥å†å²Kçº¿ - ä¼˜åŒ–ç‰ˆ"""
        # é¦–å…ˆæ£€æŸ¥æœ¬åœ°æ•°æ®
        db = SessionLocal()
        try:
            existing_count = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).count()
            
            # ä¼˜åŒ–ï¼šå¦‚æœå·²æœ‰è¶³å¤Ÿæ•°æ®ï¼ˆæ¯”å¦‚100æ¡ä»¥ä¸Šï¼‰ï¼Œå°±ä¸é‡å¤è·å–
            if existing_count >= 100:
                print(f"      â„¹ï¸ å·²æœ‰{existing_count}æ¡Kçº¿æ•°æ®ï¼Œè·³è¿‡è·å–")
                return True
        finally:
            db.close()
        
        # è®¾ç½®å®Œæ•´çš„è¯·æ±‚å¤´
        headers = {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Referer": "https://quote.eastmoney.com/center/gridlist.html",
            "X-Requested-With": "XMLHttpRequest"
        }
        
        try:
            market = "1" if stock_code.startswith(('6', '9', '11')) else "0"
            url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
            params = {
                "cb": f"jQuery_{int(time.time()*1000)}",
                "secid": f"{market}.{stock_code}",
                "ut": self.target_ut,
                "fields1": "f1,f2,f3,f4,f5,f6",
                "fields2": "f51,f52,f53,f54,f55,f56",
                "klt": "101", "fqt": "1", "beg": "0", "end": "20500101", 
                "lmt": "120", "_": str(int(time.time() * 1000))  # é™åˆ¶è·å–120æ¡æ•°æ®
            }
            
            # ä½¿ç”¨å¸¦æœ‰å®Œæ•´è¯·æ±‚å¤´çš„ä¼šè¯
            response = await asyncio.to_thread(
                self.session.get, url, params=params,
                headers=headers, timeout=20, verify=False
            )
            
            if response.status_code == 200:
                match = re.search(r'\(({.*})\)', response.text)
                if match:
                    res = json.loads(match.group(1))
                    klines = res.get("data", {}).get("klines", [])
                    if klines:
                        db = SessionLocal()
                        try:
                            # åªä¿ç•™æœ€æ–°çš„120æ¡æ•°æ®ï¼Œé¿å…æ•°æ®è†¨èƒ€
                            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
                            for line in klines:
                                cols = line.split(',')
                                h = HistoricalData(
                                    stock_code=stock_code,
                                    date=datetime.datetime.strptime(cols[0], "%Y-%m-%d").date(),
                                    open=self._safe_float(cols[1]), close=self._safe_float(cols[2]),
                                    high=self._safe_float(cols[3]), low=self._safe_float(cols[4])
                                )
                                db.add(h)
                            db.commit()
                            print(f"      âœ“ Kçº¿æ•°æ®è·å–æˆåŠŸ ({len(klines)}æ¡)")
                            return True
                        finally:
                            db.close()
            print(f"      âš ï¸ Kçº¿è·å–å¤±è´¥ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®")
            return True
            
        except Exception as e:
            print(f"      âš ï¸ Kçº¿è·å–å¼‚å¸¸: {str(e)[:50]}")
            return True
        
    async def _fetch_kline_local(self, stock_code: str):
        """æœ¬åœ°æ•°æ®è¡¥å……æ–¹æ¡ˆ"""
        db = SessionLocal()
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰éƒ¨åˆ†æ•°æ®
            existing_count = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).count()
            
            if existing_count > 0:
                print(f"      â„¹ï¸ ä½¿ç”¨ç°æœ‰{existing_count}æ¡Kçº¿æ•°æ®")
                return True
            
            # å¦‚æœå®Œå…¨æ²¡æœ‰æ•°æ®ï¼Œç”ŸæˆåŸºç¡€æ•°æ®ç”¨äºåˆ†æ
            market_data = db.query(DailyMarketData).filter(
                DailyMarketData.code == stock_code
            ).first()
            
            if market_data and market_data.latest_price:
                # ç”Ÿæˆä¸€æ¡åŸºç¡€Kçº¿æ•°æ®
                fake_kline = HistoricalData(
                    stock_code=stock_code,
                    date=datetime.date.today(),
                    open=market_data.latest_price,
                    close=market_data.latest_price,
                    high=market_data.latest_price * 1.02,
                    low=market_data.latest_price * 0.98
                )
                db.add(fake_kline)
                db.commit()
                print(f"      â„¹ï¸ ç”ŸæˆåŸºç¡€Kçº¿æ•°æ®ç”¨äºåˆ†æ")
                return True
                
        except Exception as e:
            print(f"      âš ï¸ æœ¬åœ°æ•°æ®è¡¥å……å¤±è´¥: {str(e)[:50]}")
        finally:
            db.close()
        
        return False
    
    async def _save_kline_data(self, stock_code: str, df):
        """ä¿å­˜Kçº¿æ•°æ®çš„é€šç”¨æ–¹æ³•"""
        db = SessionLocal()
        try:
            # æ¸…ç†æ—§æ•°æ®
            db.query(HistoricalData).filter(HistoricalData.stock_code == stock_code).delete()
            
            # ä¿å­˜æ–°æ•°æ®
            for _, row in df.iterrows():
                h = HistoricalData(
                    stock_code=stock_code,
                    date=pd.to_datetime(row['date'] if 'date' in row else row.index).date(),
                    open=self._safe_float(row.get('open', 0)),
                    close=self._safe_float(row.get('close', 0)),
                    high=self._safe_float(row.get('high', 0)),
                    low=self._safe_float(row.get('low', 0))
                )
                db.add(h)
            
            db.commit()
        finally:
            db.close()

    async def fetch_stock_dividend_history(self, stock_code: str):
        """åŒæ­¥å†å²åˆ†çº¢è®°å½•"""
        db = SessionLocal()
        try:
            df = await asyncio.to_thread(ak.stock_history_dividend_detail, symbol=stock_code, indicator="åˆ†çº¢")  # æ·»åŠ  indicator å‚æ•°
            if df is None or df.empty: return
            
            for _, row in df.iterrows():
                ex_date_raw = row.get('é™¤æƒé™¤æ¯æ—¥')
                if pd.isna(ex_date_raw) or str(ex_date_raw) in ['NaT', 'nan', '']: continue
                
                ex_date = pd.to_datetime(ex_date_raw).date()
                div_val = row.get('æ´¾æ¯(æ¯10è‚¡æ´¾,ç¨å‰)', 0)
                if not div_val: continue
                
                div = DividendData(
                    stock_code=stock_code,
                    stock_name=row.get('åç§°', 'æœªçŸ¥'),
                    ex_dividend_date=ex_date,
                    dividend=f"10æ´¾{div_val}",
                    report_period=str(row.get('åˆ†çº¢å¹´åº¦', ''))
                )
                db.merge(div)
            db.commit()
        except Exception as e:
            print(f"   âš ï¸ {stock_code} åˆ†çº¢æŠ“å–å¤±è´¥: {e}")
        finally:
            db.close()

    async def fetch_financial_metrics(self, stock_code: str):
        """
        è·å–è´¢åŠ¡æŒ‡æ ‡ - æ™ºèƒ½ç¼“å­˜å¢å¼ºç‰ˆ
        æ”¯æŒç¼“å­˜ã€å¤šæºã€æ™ºèƒ½é™çº§ç­–ç•¥
        è¿”å›: (ROE, åˆ©æ¶¦å¢é•¿ç‡)
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"financial_{stock_code}"
        current_time = time.time()
        
        if (cache_key in self.financial_cache and 
            cache_key in self.cache_expiry and 
            current_time < self.cache_expiry[cache_key]):
            cached_data = self.financial_cache[cache_key]
            if self.debug_mode:
                print(f"      ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ®: ROE={cached_data[0]:.2f}%, Growth={cached_data[1]:.2f}%")
            return cached_data
        
        # åˆå§‹åŒ–é»˜è®¤å€¼
        roe, growth = 0.0, 0.0
        attempts = []
        success_source = None
        
        try:
            # 1. å°è¯•ä½¿ç”¨ efinance (ä¸»æ•°æ®æº)
            attempts.append("efinance")
            df = await asyncio.to_thread(ef.stock.get_base_info, stock_code)  # ç§»é™¤ timeout å‚æ•°
            
            if df is not None and not df.empty:
                # ç»Ÿä¸€æ•°æ®æ ¼å¼å¤„ç†
                if isinstance(df, pd.DataFrame):
                    if len(df) > 0:
                        data = df.iloc[0].to_dict()
                    else:
                        data = {}
                elif isinstance(df, pd.Series):
                    data = df.to_dict()
                else:
                    data = {}
                
                # å¤šç§å­—æ®µååŒ¹é…
                roe_fields = ['å‡€èµ„äº§æ”¶ç›Šç‡(%)', 'ROE(%)', 'å‡€èµ„äº§æ”¶ç›Šç‡', 'roe', 'ROE']
                growth_fields = ['å‡€åˆ©æ¶¦åŒæ¯”(%)', 'å‡€åˆ©æ¶¦å¢é•¿ç‡(%)', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿', 'net_profit_growth', 'profit_growth']
                
                # æå– ROE
                for field in roe_fields:
                    if field in data and data[field] is not None:
                        roe_val = self._safe_float(data[field])
                        if roe_val != 0:
                            roe = roe_val
                            break
                
                # æå–åˆ©æ¶¦å¢é•¿ç‡
                for field in growth_fields:
                    if field in data and data[field] is not None:
                        growth_val = self._safe_float(data[field])
                        if growth_val != 0:
                            growth = growth_val
                            break
                
                if roe != 0 or growth != 0:
                    print(f"      âœ“ é€šè¿‡ efinance è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "efinance"
                    return float(roe), float(growth)
                    
        except Exception as e:
            print(f"      âš ï¸ efinance å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 2. å°è¯• akshare è´¢åŠ¡æŠ¥è¡¨ (å¤‡ç”¨æ•°æ®æº1)
            attempts.append("akshare_financial")
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼
            formatted_code = self._format_stock_code_for_akshare(stock_code)
            df_fin = await asyncio.to_thread(ak.stock_financial_report_sina, symbol=formatted_code)  # ç§»é™¤ timeout å‚æ•°
            
            if df_fin is not None and not df_fin.empty and len(df_fin) > 0:
                data_fin = df_fin.iloc[0].to_dict()
                
                # akshare å­—æ®µå
                roe = self._safe_float(data_fin.get('å‡€èµ„äº§æ”¶ç›Šç‡') or 
                                     data_fin.get('ROE') or 0)
                growth = self._safe_float(data_fin.get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿') or 
                                        data_fin.get('å‡€åˆ©æ¶¦å¢é•¿ç‡') or 0)
                
                if roe != 0 or growth != 0:
                    print(f"      âœ“ é€šè¿‡ akshare è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "akshare_financial"
                    return float(roe), float(growth)
                    
        except Exception as e:
            print(f"      âš ï¸ akshare financial å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 3. å°è¯• akshare ä¸»è¦æŒ‡æ ‡ (å¤‡ç”¨æ•°æ®æº2)
            attempts.append("akshare_indicator")
            formatted_code = self._format_stock_code_for_akshare(stock_code)
            df_ind = await asyncio.to_thread(ak.stock_a_lg_indicator, symbol=formatted_code)  # ä½¿ç”¨æ­£ç¡®çš„å‡½æ•°å
            
            if df_ind is not None and not df_ind.empty and len(df_ind) > 0:
                data_ind = df_ind.iloc[0].to_dict()
                
                # ä¸»è¦æŒ‡æ ‡å­—æ®µå
                roe = self._safe_float(data_ind.get('å‡€èµ„äº§æ”¶ç›Šç‡(%)') or 
                                     data_ind.get('ROE') or 0)
                growth = self._safe_float(data_ind.get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿(%)') or 
                                        data_ind.get('å‡€åˆ©æ¶¦å¢é•¿ç‡(%)') or 0)
                
                if roe != 0 or growth != 0:
                    print(f"      âœ“ é€šè¿‡ akshare indicator è·å–è´¢åŠ¡æ•°æ®: ROE={roe:.2f}%, Growth={growth:.2f}%")
                    success_source = "akshare_indicator"
                    return float(roe), float(growth)
                    
        except Exception as e:
            print(f"      âš ï¸ akshare indicator å¤±è´¥: {str(e)[:50]}")
        
        try:
            # 4. å°è¯•ä»å¸‚åœºæ•°æ®æ¨ç®—åŸºç¡€æŒ‡æ ‡ (æœ€ç»ˆå¤‡ç”¨)
            attempts.append("market_derived")
            derived_roe, derived_growth = await self._derive_financial_from_market(stock_code)
            if derived_roe != 0 or derived_growth != 0:
                print(f"      âœ“ é€šè¿‡å¸‚åœºæ•°æ®æ¨ç®—: ROE={derived_roe:.2f}%, Growth={derived_growth:.2f}%")
                return derived_roe, derived_growth
                
        except Exception as e:
            print(f"      âš ï¸ å¸‚åœºæ•°æ®æ¨ç®—å¤±è´¥: {str(e)[:50]}")
        
        # æ•°æ®è´¨é‡è¯„ä¼°å’Œç¼“å­˜
        data_quality = self._assess_data_quality(roe, growth, success_source)
        
        if data_quality >= 0.7:  # é«˜è´¨é‡æ•°æ®æ‰ç¼“å­˜
            self.financial_cache[cache_key] = (float(roe), float(growth))
            self.cache_expiry[cache_key] = current_time + self.CACHE_TTL
            if self.debug_mode:
                print(f"      ğŸ’¾ ç¼“å­˜é«˜è´¨é‡æ•°æ® (è´¨é‡: {data_quality:.2f})")
        
        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if roe == 0 and growth == 0:
            print(f"      âŒ {stock_code} è´¢åŠ¡æŒ‡æ ‡è·å–å®Œå…¨å¤±è´¥ (å°è¯•äº†: {', '.join(attempts)})")
        
        return float(roe), float(growth)
    
    def _format_stock_code_for_akshare(self, stock_code: str) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä»¥é€‚é… akshare æ¥å£"""
        if stock_code.startswith(('6', '9')):
            return f"sh{stock_code}"
        elif stock_code.startswith(('0', '3')):
            return f"sz{stock_code}"
        return stock_code
    
    async def _derive_financial_from_market(self, stock_code: str):
        """ä»å¸‚åœºä»·æ ¼æ•°æ®æ¨ç®—åŸºç¡€è´¢åŠ¡æŒ‡æ ‡"""
        db = SessionLocal()
        try:
            # è·å–å†å²ä»·æ ¼æ•°æ®æ¨ç®—è¶‹åŠ¿
            hist_data = db.query(HistoricalData).filter(
                HistoricalData.stock_code == stock_code
            ).order_by(desc(HistoricalData.date)).limit(252).all()  # ä¸€å¹´æ•°æ®
            
            if len(hist_data) < 30:  # æ•°æ®ä¸è¶³
                return 0.0, 0.0
            
            # è®¡ç®—ä»·æ ¼å¢é•¿ç‡ä½œä¸ºç²—ç•¥çš„æˆé•¿æ€§æŒ‡æ ‡
            prices = [float(h.close) for h in reversed(hist_data)]
            if len(prices) >= 2:
                # å¹´åº¦å¢é•¿ç‡ä¼°ç®—
                annual_growth = ((prices[-1] / prices[0]) ** (252/len(prices)) - 1) * 100
                derived_growth = max(-50, min(50, annual_growth))  # é™åˆ¶èŒƒå›´
            else:
                derived_growth = 0.0
            
            # ROE ç²—ç•¥ä¼°ç®— (å‡è®¾åˆç†çš„èŒƒå›´)
            derived_roe = max(0, min(30, abs(derived_growth) * 0.8))  # ç®€å•å…³è”
            
            return float(derived_roe), float(derived_growth)
            
        except Exception as e:
            print(f"      âš ï¸ å¸‚åœºæ•°æ®æ¨ç®—å¼‚å¸¸: {str(e)[:50]}")
            return 0.0, 0.0
        finally:
            db.close()

    def _assess_data_quality(self, roe: float, growth: float, source: str) -> float:
        """è¯„ä¼°æ•°æ®è´¨é‡ (0-1)"""
        quality = 0.0
        
        # æ¥æºæƒé‡
        source_weights = {
            "efinance": 1.0,
            "akshare_financial": 0.8,
            "akshare_indicator": 0.6,
            "market_derived": 0.3
        }
        quality += source_weights.get(source, 0.1)
        
        # æ•°å€¼åˆç†æ€§æ£€æŸ¥
        if -50 <= roe <= 50:  # ROEåˆç†èŒƒå›´
            quality += 0.3
        if -100 <= growth <= 200:  # å¢é•¿ç‡åˆç†èŒƒå›´
            quality += 0.3
            
        # éé›¶å€¼åŠ åˆ†
        if roe != 0:
            quality += 0.2
        if growth != 0:
            quality += 0.2
            
        return min(1.0, quality)

    async def analyze_stock(self, stock_code: str, db: Session):
        """ç»¼åˆåˆ†æè¯„åˆ† - ä¸¥æ ¼æ˜ å°„æ¯ä¸€ä¸ªå­—æ®µ"""
        today = datetime.date.today()
        market = db.query(DailyMarketData).filter(DailyMarketData.code == stock_code).order_by(desc(DailyMarketData.date)).first()
        if not market: return
        
        # 1. æ³¢åŠ¨ç‡æ·±åº¦åˆ†æ (0-40åˆ†)
        v30, v60, vol_score = 0.0, 0.0, 0
        # è·å–120æ¡æ•°æ®ç¡®ä¿è¶³å¤Ÿ
        hist = db.query(HistoricalData).filter(
            HistoricalData.stock_code == stock_code,
            HistoricalData.close.isnot(None)
        ).order_by(desc(HistoricalData.date)).limit(120).all()

        # åè½¬ä¸ºæ­£åº
        prices = [float(h.close) for h in reversed(hist)]
        price_series = pd.Series(prices)
        log_returns = np.log(price_series / price_series.shift(1)).dropna()

        # åˆ†åˆ«è®¡ç®—30æ—¥å’Œ60æ—¥
        if len(log_returns) >= 30:
            v30 = float(log_returns.tail(30).std() * np.sqrt(252) * 100)
            
        if len(log_returns) >= 60:
            v60 = float(log_returns.tail(60).std() * np.sqrt(252) * 100)  # âœ… ä¿®å¤
        
        if v30 < 20: vol_score = 40
        elif v30 < 30: vol_score = 30
        elif v30 < 40: vol_score = 20
        else: vol_score = 10

        # 2. è‚¡æ¯ç‡è®¡ç®— (0-30åˆ†)
        div_yield, div_score = 0.0, 0
        one_year_ago = today - datetime.timedelta(days=365)
        dividends = db.query(DividendData).filter(DividendData.stock_code == stock_code, DividendData.ex_dividend_date >= one_year_ago).all()
        
        total_cash_div = 0.0
        if dividends and market.latest_price:
            for d in dividends:
                div_str = str(d.dividend)
                
                # æ ¼å¼1: "10æ´¾5.2" âœ…
                match = re.search(r'10æ´¾(\d+\.?\d*)', div_str)
                if match:
                    total_cash_div += float(match.group(1)) / 10
                    continue
                
                # æ ¼å¼2: "æ´¾1.5" âœ…
                match = re.search(r'æ´¾(\d+\.?\d*)', div_str)
                if match:
                    total_cash_div += float(match.group(1)) / 10
            
            if total_cash_div > 0:
                div_yield = float((total_cash_div / market.latest_price) * 100)
                print(f"      âœ“ è‚¡æ¯ç‡: {div_yield:.2f}% (å¹´åº¦åˆ†çº¢: {total_cash_div:.2f}å…ƒ/è‚¡)")

            if div_yield >= 5: div_score = 30
            elif div_yield >= 3: div_score = 20
            elif div_yield >= 1.5: div_score = 10

        # 3. è´¢åŠ¡ä¸æˆé•¿æ€§ (0-30åˆ†)
        # âœ… è¿™é‡Œè§£åŒ…å…ƒç»„ï¼Œä¿®å¤ TypeError
        roe, profit_growth = await self.fetch_financial_metrics(stock_code)
        # æˆé•¿æ€§è¯„åˆ†
        growth_score = 0
        if roe > 15:
            growth_score = 30
        elif roe > 12:
            growth_score = 25
        elif roe > 10:
            growth_score = 20
        elif roe > 8:
            growth_score = 15
        elif roe > 5:
            growth_score = 10

        # 4. æ±‡æ€»ä¿å­˜ - æ˜ å°„æ¨¡å‹ä¸­çš„æ‰€æœ‰å­—æ®µ
        res = StockAnalysisResult(
            stock_code=stock_code,
            stock_name=market.name,
            analysis_date=today,
            latest_price=market.latest_price,
            pe_ratio=market.pe_dynamic,
            pb_ratio=market.pb,
            roe=round(roe, 2),
            profit_growth=round(profit_growth, 2),
            volatility_30d=round(v30, 2),
            volatility_60d=round(v60, 2),
            volatility_score=vol_score,
            dividend_yield=round(div_yield, 2),
            dividend_score=div_score,
            growth_score=growth_score,
            total_score=int(vol_score + div_score + growth_score),
            suggestion="å¼ºçƒˆæ¨è" if (vol_score + div_score + growth_score) >= 70 else ("æ¨è" if (vol_score + div_score + growth_score) >= 55 else "è§‚æœ›"),
            data_source="automated_v3"
        )
        db.merge(res)
        db.commit()
        return res.total_score

    async def analyze_stock(self, stock_code: str, db: Session):
        """
        æ·±åº¦åˆ†æå•åªè‚¡ç¥¨
        ç›®æ ‡ï¼šä¸¥æ ¼å¯¹ç…§æ¨¡å‹å­—æ®µï¼Œç¡®ä¿ dividend_yield, volatility_60d, roe ç­‰ä¸å†ä¸º NULL
        """
        today = datetime.date.today()
        
        # 1. åŸºç¡€è¡Œæƒ…æ ¡éªŒ (DailyMarketData)
        market = db.query(DailyMarketData).filter(
            DailyMarketData.code == stock_code
        ).order_by(desc(DailyMarketData.date)).first()
        
        if not market or not market.latest_price:
            print(f"   âš ï¸ {stock_code} ç¼ºå¤±å®æ—¶è¡Œæƒ…ï¼Œæ— æ³•åˆ†æ")
            return None

        # ---------------------------------------------------------
        # 2. æ³¢åŠ¨ç‡è®¡ç®— (HistoricalData)
        # ---------------------------------------------------------
        v30, v60, vol_score = 0.0, 0.0, 0
        
        # æ ¸å¿ƒä¿®å¤ï¼šæŸ¥è¯¢æœ€è¿‘120æ¡ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ç®—60æ—¥æ³¢åŠ¨ç‡
        hist = db.query(HistoricalData).filter(
            HistoricalData.stock_code == stock_code
        ).order_by(desc(HistoricalData.date)).limit(100).all()

        if len(hist) >= 20:
            # å¿…é¡»åè½¬ä¸ºæ­£åºï¼ˆä»æ—§åˆ°æ–°ï¼‰è®¡ç®—æ”¶ç›Šç‡
            prices = [h.close for h in reversed(hist)]
            price_series = pd.Series(prices)
            log_returns = np.log(price_series / price_series.shift(1)).dropna()
            
            # è®¡ç®—30æ—¥æ³¢åŠ¨ç‡
            if len(log_returns) >= 30:
                v30 = log_returns.tail(30).std() * np.sqrt(252) * 100
                
            # è®¡ç®—60æ—¥æ³¢åŠ¨ç‡
            if len(log_returns) >= 60:
                v60 = log_returns.tail(60).std() * np.sqrt(252) * 100
            
            # æ³¢åŠ¨ç‡è¯„åˆ† (æŒ‰ç…§30æ—¥æ ‡å‡†)
            if v30 > 0:
                if v30 < 20: vol_score = 40
                elif v30 < 30: vol_score = 30
                elif v30 < 40: vol_score = 20
                else: vol_score = 10

        # ---------------------------------------------------------
        # 3. è‚¡æ¯ç‡è®¡ç®— (DividendData)
        # ---------------------------------------------------------
        div_yield, div_score = 0.0, 0
        one_year_ago = today - datetime.timedelta(days=365)
        
        # æ ¸å¿ƒä¿®å¤ï¼šæŸ¥è¯¢è¿‡å»ä¸€å¹´å†…çš„æ‰€æœ‰åˆ†çº¢è®°å½•
        dividends = db.query(DividendData).filter(
            DividendData.stock_code == stock_code,
            DividendData.ex_dividend_date >= one_year_ago
        ).all()
        
        total_cash_div = 0.0
        if dividends:
            for d in dividends:
                # å…¼å®¹ "10æ´¾5", "10æ´¾5.2", "æ´¾1.5" ç­‰å„ç§å­—ç¬¦ä¸²æ ¼å¼
                match = re.search(r'æ´¾(\d+\.?\d*)', str(d.dividend))
                if match:
                    # æ¢ç®—æˆæ¯è‚¡åˆ†çº¢é¢
                    total_cash_div += float(match.group(1)) / 10
            
            # è®¡ç®—è‚¡æ¯ç‡ï¼šå¹´åº¦æ€»åˆ†çº¢ / å½“å‰è‚¡ä»· * 100
            div_yield = (total_cash_div / market.latest_price) * 100
            
            # è‚¡æ¯ç‡è¯„åˆ†
            if div_yield >= 5: div_score = 30
            elif div_yield >= 3: div_score = 20
            elif div_yield >= 1.5: div_score = 10

        # ---------------------------------------------------------
        # 4. è´¢åŠ¡æ•°æ®è·å– (ROE & Growth)
        # ---------------------------------------------------------
        roe, profit_growth = await self.fetch_financial_metrics(stock_code)
        
        # æˆé•¿æ€§è¯„åˆ†
        growth_score = 0
        if roe > 15: growth_score = 30
        elif roe > 10: growth_score = 20
        elif roe > 5: growth_score = 10

        # ---------------------------------------------------------
        # 5. ç»“æœæŒä¹…åŒ– (æ˜ å°„åˆ° StockAnalysisResult æ¨¡å‹)
        # ---------------------------------------------------------
        analysis_res = StockAnalysisResult(
            stock_code=stock_code,
            stock_name=market.name,
            analysis_date=today,
            
            # åŸºç¡€æ•°æ®
            latest_price=market.latest_price,
            pe_ratio=market.pe_dynamic,
            pb_ratio=market.pb,
            
            # æ³¢åŠ¨ç‡æŒ‡æ ‡ (æ˜¾å¼æ˜ å°„)
            volatility_30d=round(v30, 2) if v30 > 0 else 0.0,
            volatility_60d=round(v60, 2) if v60 > 0 else 0.0,
            
            # è´¢åŠ¡æŒ‡æ ‡ (æ˜¾å¼æ˜ å°„)
            dividend_yield=round(div_yield, 2) if div_yield > 0 else 0.0,  # âœ…
            roe=round(roe, 2) if roe > 0 else 0.0,  # âœ…
            profit_growth=round(profit_growth, 2) if profit_growth else 0.0,  # âœ…
            
            
            # è¯„åˆ†è¯¦æƒ… (æ˜¾å¼æ˜ å°„)
            volatility_score=int(vol_score),
            dividend_score=int(div_score),
            growth_score=int(growth_score),
            total_score=int(vol_score + div_score + growth_score),
            
            suggestion="æ¨è" if (vol_score + div_score + growth_score) >= 60 else "è§‚æœ›",
            data_source="automated_v3"
        )

        try:
            db.merge(analysis_res)
            db.commit()
            return analysis_res.total_score
        except Exception as e:
            db.rollback()
            print(f"   âŒ {stock_code} ç»“æœå…¥åº“å¤±è´¥: {e}")
            return None

    async def analyze_all_watched_stocks(self):
        """ä¸»åˆ†æä»»åŠ¡å¾ªç¯ - æ™ºèƒ½å¢é‡æ›´æ–°ç‰ˆ"""
        db = SessionLocal()
        stats = {
            "success": 0, 
            "failed": 0, 
            "financial_failed": 0,
            "network_errors": 0,
            "data_errors": 0,
            "timeout_errors": 0
        }
        semaphore = asyncio.Semaphore(self.settings.CONCURRENT_LIMIT)
        
        try:
            # ä¿®å¤ï¼šå»é‡å¹¶éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
            watched_raw = db.query(UserStockWatch.stock_code).distinct().all()
            watched_codes = list(set([w[0] for w in watched_raw if w[0] and len(w[0]) == 6 and w[0].isdigit()]))
            total = len(watched_codes)
            
            # æ·»åŠ é‡å¤æ£€æŸ¥æ—¥å¿—
            if len(watched_raw) != len(watched_codes):
                print(f"âš ï¸ å‘ç°é‡å¤è‚¡ç¥¨ä»£ç ï¼ŒåŸå§‹:{len(watched_raw)} å»é‡å:{len(watched_codes)}")
            
            # æ™ºèƒ½å¢é‡æ›´æ–°æ£€æŸ¥
            update_needed = await self._check_update_needed(db, [(code,) for code in watched_codes])
            if not update_needed:
                print("ğŸ’¡ æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè·³è¿‡æ›´æ–°")
                return
            
            print(f"ğŸš€ å¯åŠ¨æ·±åº¦åˆ†æ (å…± {total} åª)...")
            print(f"ğŸ“Š é…ç½®: å¹¶å‘æ•°{self.settings.CONCURRENT_LIMIT}, è¶…æ—¶{self.settings.FINANCIAL_FETCH_TIMEOUT}s")
            
            # è·å–é«˜ä¼˜å…ˆçº§è‚¡ç¥¨
            priority_stocks = await self._get_priority_stocks(db, [(code,) for code in watched_codes])
            
            # è®°å½•å·²å¤„ç†çš„è‚¡ç¥¨ï¼Œé˜²æ­¢é‡å¤
            processed_stocks = set()
            tasks = []
            
            async def process_stock(i, stock_code):
                # é˜²æ­¢é‡å¤å¤„ç†
                if stock_code in processed_stocks:
                    print(f"   âš ï¸ {stock_code} å·²åœ¨å¤„ç†é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡")
                    return
                processed_stocks.add(stock_code)
                
                async with semaphore:
                    try:
                        # æ™ºèƒ½è·³è¿‡Kçº¿å¤±è´¥çš„è‚¡ç¥¨
                        if not await self.fetch_historical_data(stock_code):
                            print(f"      âš ï¸ Kçº¿è·å–å¤±è´¥ï¼Œä½†ä»ç»§ç»­åˆ†æ...")
                        await self.fetch_stock_dividend_history(stock_code)
                        score = await self.analyze_stock(stock_code, db)
                        
                        if score is not None:
                            stats["success"] += 1
                            print(f"   âœ“ {i}/{total} {stock_code} åˆ†æå®Œæˆ (è¯„åˆ†: {score})")
                        else:
                            stats["failed"] += 1
                            print(f"   âŒ {i}/{total} {stock_code} åˆ†æå¤±è´¥")
                        
                    except Exception as e:
                        stats["failed"] += 1
                        error_msg = str(e).lower()
                        
                        if "connection" in error_msg or "timeout" in error_msg:
                            stats["network_errors"] += 1
                        elif "timeout" in error_msg:
                            stats["timeout_errors"] += 1
                        elif "data" in error_msg or "format" in error_msg:
                            stats["data_errors"] += 1
                        else:
                            stats["financial_failed"] += 1
                        
                        print(f"   âŒ {i}/{total} {stock_code} å¤„ç†å¼‚å¸¸: {str(e)[:50]}")
                    
                    # æ™ºèƒ½å»¶è¿Ÿ + è¿›åº¦æ˜¾ç¤º
                    delay = random.uniform(
                        self.settings.FETCH_DELAY_MIN, 
                        self.settings.FETCH_DELAY_MAX
                    )
                    
                    # æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
                    success_rate = (stats["success"] / i * 100) if i > 0 else 0
                    eta_minutes = ((total - i) * (self.settings.FETCH_DELAY_MAX + self.settings.FETCH_DELAY_MIN) / 2) / 60
                    
                    print(f"   ğŸ’¤ ç­‰å¾… {delay:.1f} ç§’... (æˆåŠŸç‡: {success_rate:.1f}%, é¢„è®¡å‰©ä½™: {eta_minutes:.1f}åˆ†é’Ÿ)")
                    await asyncio.sleep(delay)
            
            # å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§è‚¡ç¥¨
            print(f"ğŸ¯ ä¼˜å…ˆå¤„ç† {len(priority_stocks)} åªé‡è¦è‚¡ç¥¨...")
            for i, code in enumerate(priority_stocks, 1):
                tasks.append(process_stock(i, code))
            
            # å†å¤„ç†å…¶ä»–è‚¡ç¥¨
            remaining_stocks = [code for code in watched_codes if code not in priority_stocks]
            print(f"ğŸ“‹ å¤„ç†å‰©ä½™ {len(remaining_stocks)} åªè‚¡ç¥¨...")
            for i, code in enumerate(remaining_stocks, len(priority_stocks) + 1):
                tasks.append(process_stock(i, code))
                
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # æœ€ç»ˆç»Ÿè®¡
            final_success_rate = (stats["success"] / total) * 100 if total > 0 else 0
            print(f"\nğŸ åˆ†æå®Œæˆ!")
            print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
            print(f"   æ€»æ•°: {total}")
            print(f"   æˆåŠŸ: {stats['success']} ({final_success_rate:.1f}%)")
            print(f"   å¤±è´¥: {stats['failed']}")
            
        except Exception as e:
            print(f"ğŸš¨ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            db.close()
    
    async def _check_update_needed(self, db: Session, watched_stocks):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°"""
        # æ£€æŸ¥æœ€æ–°åˆ†ææ—¥æœŸ
        latest_analysis = db.query(StockAnalysisResult).order_by(
            desc(StockAnalysisResult.analysis_date)
        ).first()
        
        if not latest_analysis:
            return True
            
        # å¦‚æœä»Šå¤©å·²ç»åˆ†æè¿‡ï¼Œä¸”è‚¡ç¥¨æ•°é‡æ²¡å˜ï¼Œåˆ™ä¸éœ€è¦æ›´æ–°
        today_count = db.query(StockAnalysisResult).filter(
            StockAnalysisResult.analysis_date == datetime.date.today()
        ).count()
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å…³æ³¨çš„è‚¡ç¥¨éƒ½æœ‰ä»Šå¤©çš„åˆ†æç»“æœ
        watched_codes = set([row[0] for row in watched_stocks])
        today_analyzed_codes = set([
            result.stock_code for result in 
            db.query(StockAnalysisResult.stock_code).filter(
                StockAnalysisResult.analysis_date == datetime.date.today()
            ).all()
        ])
        
        return not watched_codes.issubset(today_analyzed_codes)
    
    async def _get_priority_stocks(self, db: Session, all_stocks):
        """è·å–é«˜ä¼˜å…ˆçº§è‚¡ç¥¨ï¼ˆæŒä»“æˆ–é«˜è¯„åˆ†ï¼‰"""
        # è·å–æŒä»“è‚¡ç¥¨
        holdings = db.query(UserStockHolding.stock_code).filter(
            UserStockHolding.is_active == True
        ).distinct().all()
        
        # è·å–é«˜è¯„åˆ†è‚¡ç¥¨ï¼ˆä¸Šæ¬¡è¯„åˆ†>80ï¼‰
        high_score = db.query(StockAnalysisResult.stock_code).filter(
            StockAnalysisResult.total_score > 80
        ).distinct().all()
        
        priority_set = set([h[0] for h in holdings] + [s[0] for s in high_score])
        all_codes = set([row[0] for row in all_stocks])
        
        return list(priority_set.intersection(all_codes))
    
    async def _check_network_health(self):
        """æ£€æŸ¥ç½‘ç»œè¿æ¥å¥åº·åº¦"""
        try:
            response = await asyncio.to_thread(
                requests.get, "https://httpbin.org/get", timeout=5
            )
            return response.status_code == 200
        except:
            return False
    
    async def _adaptive_delay(self, network_healthy: bool):
        """è‡ªé€‚åº”å»¶è¿Ÿè°ƒæ•´"""
        if network_healthy:
            return random.uniform(
                self.settings.FETCH_DELAY_MIN,
                self.settings.FETCH_DELAY_MAX
            )
        else:
            # ç½‘ç»œä¸ä½³æ—¶å¢åŠ å»¶è¿Ÿ
            return random.uniform(
                self.settings.FETCH_DELAY_MAX,
                self.settings.FETCH_DELAY_MAX * 2
            )
    async def clean_abnormal_pe_data(self):
        """æ¸…ç†å¼‚å¸¸çš„PEæ•°æ®"""
        db = SessionLocal()
        try:
            # æŸ¥æ‰¾å¼‚å¸¸PEå€¼çš„è®°å½•
            abnormal_records = db.query(StockAnalysisResult).filter(
                StockAnalysisResult.pe_ratio > 1000000
            ).all()
            
            if abnormal_records:
                print(f"ğŸ” å‘ç° {len(abnormal_records)} æ¡å¼‚å¸¸PEæ•°æ®è®°å½•")
                for record in abnormal_records:
                    print(f"   {record.stock_code} - {record.analysis_date}: PE={record.pe_ratio}")
                    # ä¿®æ­£ä¸º0æˆ–é‡æ–°è®¡ç®—
                    record.pe_ratio = 0.0
                    
                db.commit()
                print("âœ… å¼‚å¸¸PEæ•°æ®å·²æ¸…ç†")
            else:
                print("âœ… æœªå‘ç°å¼‚å¸¸PEæ•°æ®")
                
        except Exception as e:
            print(f"âŒ æ¸…ç†å¼‚å¸¸æ•°æ®å¤±è´¥: {e}")
        finally:
            db.close()

    async def validate_analysis_data(self):
        """éªŒè¯åˆ†ææ•°æ®çš„åˆç†æ€§"""
        db = SessionLocal()
        try:
            # æ£€æŸ¥æœ€è¿‘ä¸€å‘¨çš„åˆ†ææ•°æ®
            one_week_ago = datetime.date.today() - datetime.timedelta(days=7)
            
            suspicious_records = db.query(StockAnalysisResult).filter(
                StockAnalysisResult.analysis_date >= one_week_ago,
                (StockAnalysisResult.pe_ratio > 1000000) | 
                (StockAnalysisResult.pe_ratio < 0) |
                (StockAnalysisResult.total_score > 100) |
                (StockAnalysisResult.total_score < 0)
            ).all()
            
            if suspicious_records:
                print(f"âš ï¸ å‘ç° {len(suspicious_records)} æ¡å¯ç–‘æ•°æ®:")
                for record in suspicious_records:
                    issues = []
                    if record.pe_ratio > 1000000 or record.pe_ratio < 0:
                        issues.append(f"PEå¼‚å¸¸({record.pe_ratio})")
                    if record.total_score > 100 or record.total_score < 0:
                        issues.append(f"è¯„åˆ†å¼‚å¸¸({record.total_score})")
                    
                    print(f"   {record.stock_code} {record.analysis_date}: {', '.join(issues)}")
            else:
                print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
                
        except Exception as e:
            print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
        finally:
            db.close()

stock_service = StockDataService()
