# scheduler_manager.py - å¢å¼ºç‰ˆ
import asyncio
import logging
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

class EnhancedSchedulerManager:
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.logger = self.setup_logger()
        self.task_stats = {}  # ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡
        
    def setup_logger(self):
        """è®¾ç½®ä¸“ç”¨æ—¥å¿—"""
        logger = logging.getLogger('scheduler_manager')
        logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler('log/scheduler_detailed.log', encoding='utf-8')
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        ))
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter(
            '%(levelname)s - %(message)s'
        ))
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        return logger
    
    def setup_production_tasks(self):
        """ç”Ÿäº§ç¯å¢ƒä»»åŠ¡é…ç½®"""
        self.logger.info("ğŸ”§ é…ç½®ç”Ÿäº§ä»»åŠ¡...")
        
        # ç”Ÿäº§ä»»åŠ¡ - ä¸main.pyä¸­çš„ä»»åŠ¡äº’è¡¥
        tasks = [
            {
                'func': self.health_check,
                'trigger': CronTrigger(minute="*/30"),  # æ¯30åˆ†é’Ÿå¥åº·æ£€æŸ¥
                'id': 'health_check',
                'name': 'ç³»ç»Ÿå¥åº·æ£€æŸ¥'
            },
            {
                'func': self.backup_database,
                'trigger': CronTrigger(hour=1, minute=0),  # å‡Œæ™¨1ç‚¹å¤‡ä»½
                'id': 'db_backup',
                'name': 'æ•°æ®åº“å¤‡ä»½'
            },
            {
                'func': self.cleanup_logs,
                'trigger': CronTrigger(day_of_week='sun', hour=3, minute=0),  # å‘¨æ—¥å‡Œæ™¨æ¸…ç†
                'id': 'log_cleanup',
                'name': 'æ—¥å¿—æ¸…ç†'
            }
        ]
        
        for task in tasks:
            self.scheduler.add_job(
                task['func'],
                task['trigger'],
                id=task['id'],
                name=task['name'],
                misfire_grace_time=1800
            )
    
    def setup_monitoring_tasks(self):
        """ç›‘æ§ä»»åŠ¡é…ç½®"""
        self.logger.info("ğŸ” é…ç½®ç›‘æ§ä»»åŠ¡...")
        
        # ç›‘æ§ä¸»è°ƒåº¦å™¨çŠ¶æ€
        self.scheduler.add_job(
            self.monitor_main_scheduler,
            IntervalTrigger(minutes=5),
            id='monitor_main',
            name='ä¸»è°ƒåº¦å™¨ç›‘æ§'
        )
        
        # ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡
        self.scheduler.add_job(
            self.report_task_statistics,
            CronTrigger(minute=0),  # æ¯å°æ—¶æŠ¥å‘Š
            id='task_stats',
            name='ä»»åŠ¡ç»Ÿè®¡æŠ¥å‘Š'
        )
    
    async def health_check(self):
        """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        try:
            self.logger.info("ğŸ¥ æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
            
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            from core.database import engine
            with engine.connect() as conn:
                conn.execute("SELECT 1")
            
            # æ£€æŸ¥å…³é”®æœåŠ¡
            from services.stock_service import stock_service
            if hasattr(stock_service, 'session'):
                response = await stock_service.session.get('https://httpbin.org/get', timeout=5)
                if response.status_code != 200:
                    raise Exception("ç½‘ç»œæœåŠ¡å¼‚å¸¸")
            
            self.logger.info("âœ… ç³»ç»Ÿå¥åº·æ£€æŸ¥é€šè¿‡")
            self.update_task_stats('health_check', 'success')
            
        except Exception as e:
            self.logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            self.update_task_stats('health_check', 'failed')
    
    def monitor_main_scheduler(self):
        """ç›‘æ§ä¸»è°ƒåº¦å™¨"""
        try:
            # è¿™é‡Œå¯ä»¥è®¿é—®ä¸»è°ƒåº¦å™¨çŠ¶æ€
            # é€šè¿‡æŸç§æ–¹å¼è·å–app_schedulerçš„çŠ¶æ€
            self.logger.info("ğŸ” ç›‘æ§ä¸»è°ƒåº¦å™¨è¿è¡ŒçŠ¶æ€")
            
            # æ£€æŸ¥å…³é”®ä»»åŠ¡æ˜¯å¦å­˜åœ¨
            critical_tasks = ['sync_market_data', 'analyze_stocks']
            # å®ç°æ£€æŸ¥é€»è¾‘...
            
        except Exception as e:
            self.logger.error(f"âŒ ç›‘æ§ä»»åŠ¡å¤±è´¥: {e}")
    
    def report_task_statistics(self):
        """æŠ¥å‘Šä»»åŠ¡ç»Ÿè®¡"""
        self.logger.info("ğŸ“Š ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡æŠ¥å‘Š:")
        for task_id, stats in self.task_stats.items():
            total = stats.get('success', 0) + stats.get('failed', 0)
            success_rate = (stats.get('success', 0) / total * 100) if total > 0 else 0
            self.logger.info(f"  {task_id}: æ€»è®¡{total}æ¬¡, æˆåŠŸç‡{success_rate:.1f}%")
    
    def update_task_stats(self, task_id, status):
        """æ›´æ–°ä»»åŠ¡ç»Ÿè®¡"""
        if task_id not in self.task_stats:
            self.task_stats[task_id] = {'success': 0, 'failed': 0}
        
        self.task_stats[task_id][status] += 1
    
    async def backup_database(self):
        """æ•°æ®åº“å¤‡ä»½"""
        try:
            self.logger.info("ğŸ’¾ å¼€å§‹æ•°æ®åº“å¤‡ä»½...")
            # å®ç°å¤‡ä»½é€»è¾‘
            self.logger.info("âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ")
            self.update_task_stats('db_backup', 'success')
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            self.update_task_stats('db_backup', 'failed')
    
    async def cleanup_logs(self):
        """æ—¥å¿—æ¸…ç†"""
        try:
            self.logger.info("ğŸ§¹ å¼€å§‹æ—¥å¿—æ¸…ç†...")
            import os
            import glob
            from datetime import datetime, timedelta
            
            # æ¸…ç†7å¤©å‰çš„æ—¥å¿—
            cutoff_date = datetime.now() - timedelta(days=7)
            log_files = glob.glob("*.log")
            
            for log_file in log_files:
                if os.path.getmtime(log_file) < cutoff_date.timestamp():
                    os.remove(log_file)
                    self.logger.info(f"  å·²åˆ é™¤: {log_file}")
            
            self.logger.info("âœ… æ—¥å¿—æ¸…ç†å®Œæˆ")
            self.update_task_stats('log_cleanup', 'success')
        except Exception as e:
            self.logger.error(f"âŒ æ—¥å¿—æ¸…ç†å¤±è´¥: {e}")
            self.update_task_stats('log_cleanup', 'failed')
    
    def start(self):
        """å¯åŠ¨å¢å¼ºè°ƒåº¦å™¨"""
        self.setup_production_tasks()
        self.setup_monitoring_tasks()
        self.scheduler.start()
        self.logger.info("âœ… å¢å¼ºè°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨"""
        if self.scheduler.running:
            self.scheduler.shutdown()
            self.logger.info("ğŸ›‘ å¢å¼ºè°ƒåº¦å™¨å·²å…³é—­")

# å…¨å±€å®ä¾‹
scheduler_manager = EnhancedSchedulerManager()